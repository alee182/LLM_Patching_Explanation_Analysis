[
    {
        "num": 1,
        "codeLink": "https://github.com/php/php-src/commit/69dee5c732fe982c82edb17d0dbc3e79a47748d8",
        "CVE ID": "CVE-2015-9253",
        "CVE Details": "An issue was discovered in PHP 7.3.x before 7.3.0alpha3, 7.2.x before 7.2.8, and before 7.1.20. The php-fpm master process restarts a child process in an endless loop when using program execution functions (e.g., passthru, exec, shell_exec, or system) with a non-blocking STDIN stream, causing this master process to consume 100% of the CPU, and consume disk space with a large volume of error logs, as demonstrated by an attack by a customer of a shared-hosting facility.",
        "CWE ID": "CWE-400",
        "commit_message": "Fixed bug #73342\n\nDirectly listen on socket, instead of duping it to STDIN and\nlistening on that.",
        "fixed_function": " static void fpm_child_init(struct fpm_worker_pool_s *wp) /* {{{ */\n {\n \tfpm_globals.max_requests = wp->config->pm_max_requests;\n\tfpm_globals.listening_socket = dup(wp->listening_socket);\n \n \tif (0 > fpm_stdio_init_child(wp)  ||\n \t    0 > fpm_log_init_child(wp)    ||\n\t    0 > fpm_status_init_child(wp) ||\n\t    0 > fpm_unix_init_child(wp)   ||\n\t    0 > fpm_signals_init_child()  ||\n\t    0 > fpm_env_init_child(wp)    ||\n\t    0 > fpm_php_init_child(wp)) {\n\n\t\tzlog(ZLOG_ERROR, \"[pool %s] child failed to initialize\", wp->config->name);\n\t\texit(FPM_EXIT_SOFTWARE);\n\t}\n}\n/* }}} */\n",
        "vul_function": " static void fpm_child_init(struct fpm_worker_pool_s *wp) /* {{{ */\n {\n \tfpm_globals.max_requests = wp->config->pm_max_requests;\n \n \tif (0 > fpm_stdio_init_child(wp)  ||\n \t    0 > fpm_log_init_child(wp)    ||\n\t    0 > fpm_status_init_child(wp) ||\n\t    0 > fpm_unix_init_child(wp)   ||\n\t    0 > fpm_signals_init_child()  ||\n\t    0 > fpm_env_init_child(wp)    ||\n\t    0 > fpm_php_init_child(wp)) {\n\n\t\tzlog(ZLOG_ERROR, \"[pool %s] child failed to initialize\", wp->config->name);\n\t\texit(FPM_EXIT_SOFTWARE);\n\t}\n}\n/* }}} */\n",
        "llama3.1 Summary": "The patch changes the initialization of the listening socket by directly assigning the value from wp->listening_socket to fpm_globals.listening_socket, eliminating the use of dup() function which caused a potential race condition issue. This was applied to prevent a possible denial-of-service attack due to the previously used dup() function creating a new file descriptor for STDIN that could interfere with socket operations. Fixed version of function:  static void fpm_child_init(struct fpm_worker_pool_s *wp) /* {{{ */\n {\n \tfpm_globals.max_requests = wp->config->pm_max_requests;\n\tfpm_globals.listening_socket = wp->listening_socket;\n \n \tif (0 > fpm_stdio_init_child(wp)  ||\n \t    0 > fpm_log_init_child(wp)    ||\n\t    0 > fpm_status_init_child(wp) ||\n\t    0 > fpm_unix_init_child(wp)   ||\n\t    0 > fpm_signals_init_child()  ||\n\t    0 > fpm_env_init_child(wp)    ||\n\t    0 > fpm_php_init_child(wp)) {\n\n\t\tzlog(ZLOG_ERROR, \"[pool %s] child failed to initialize\", wp->config->name);\n\t\texit(FPM_EXIT_SOFTWARE);\n\t}\n}",
        "llama3.1 CWE": "CWE-94",
        "llama3.1 CVE": "CVE-2014-3497",
        "llama3.1 BERT Score": {
            "BERTScore Precision": "0.4384",
            "BERTScore Recall": "0.5268",
            "BERTScore F1": "0.4786"
        },
        "llama3.1 Cosine_Similarity": 0.5940237045288086,
        "Mistral Summary": "The patch changes the method of handling the listening socket from duping it to STDIN and listening, to directly listening on the socket. This was applied to fix a race condition where a new child process might miss events if the parent process closes its end of the duped pipe before the child can initialize and start listening.",
        "Mistral CWE": "CWE-20",
        "Mistral CVE": "Not provided (as the CVE ID is assigned based on the specific software and environment)",
        "Mistral Cosine_Similarity": 0.32473576068878174,
        "Mistral BERT Score": {
            "BERTScore Precision": "0.5674",
            "BERTScore Recall": "0.5020",
            "BERTScore F1": "0.5327"
        },
        "Tokens Used": ""
    },
    {
        "num": 2,
        "codeLink": "https://github.com/php/php-src/commit/0f8cf3b8497dc45c010c44ed9e96518e11e19fc3",
        "CVE ID": "CVE-2017-11142",
        "CVE Details": "In PHP before 5.6.31, 7.x before 7.0.17, and 7.1.x before 7.1.3, remote attackers could cause a CPU consumption denial of service attack by injecting long form variables, related to main/php_variables.c.",
        "CWE ID": "CWE-400",
        "commit_message": "Fix bug #73807",
        "fixed_function": "static inline int add_post_vars(zval *arr, post_var_data_t *vars, zend_bool eof TSRMLS_DC)\n{\n\tuint64_t max_vars = PG(max_input_vars);\n\n\tvars->ptr = vars->str.c;\n\tvars->end = vars->str.c + vars->str.len;\n\twhile (add_post_var(arr, vars, eof TSRMLS_CC)) {\n\t\tif (++vars->cnt > max_vars) {\n\t\t\tphp_error_docref(NULL TSRMLS_CC, E_WARNING,\n\t\t\t\t\t\"Input variables exceeded %\" PRIu64 \". \"\n\t\t\t\t\t\"To increase the limit change max_input_vars in php.ini.\",\n\t\t\t\t\tmax_vars);\n\t\t\treturn FAILURE;\n \t\t}\n \t}\n \n\tif (!eof && vars->str.c != vars->ptr) {\n \t\tmemmove(vars->str.c, vars->ptr, vars->str.len = vars->end - vars->ptr);\n \t}\n \treturn SUCCESS;\n}\n",
        "vul_function": "static inline int add_post_vars(zval *arr, post_var_data_t *vars, zend_bool eof TSRMLS_DC)\n{\n\tuint64_t max_vars = PG(max_input_vars);\n\n\tvars->ptr = vars->str.c;\n\tvars->end = vars->str.c + vars->str.len;\n\twhile (add_post_var(arr, vars, eof TSRMLS_CC)) {\n\t\tif (++vars->cnt > max_vars) {\n\t\t\tphp_error_docref(NULL TSRMLS_CC, E_WARNING,\n\t\t\t\t\t\"Input variables exceeded %\" PRIu64 \". \"\n\t\t\t\t\t\"To increase the limit change max_input_vars in php.ini.\",\n\t\t\t\t\tmax_vars);\n\t\t\treturn FAILURE;\n \t\t}\n \t}\n \n\tif (!eof) {\n \t\tmemmove(vars->str.c, vars->ptr, vars->str.len = vars->end - vars->ptr);\n \t}\n \treturn SUCCESS;\n}\n",
        "llama3.1 Summary": "The patch changes the condition under which the `memmove` function is called, preventing unnecessary memory copying when the end of the string has not been reached. This fix was applied to prevent potential information disclosure vulnerabilities by ensuring that sensitive data is not overwritten unnecessarily. \nFixed version of function: static inline int add_post_vars(zval *arr, post_var_data_t *vars, zend_bool eof TSRMLS_DC)\n{\n\tuint64_t max_vars = PG(max_input_vars);\n\n\tvars->ptr = vars->str.c;\n\tvars->end = vars->str.c + vars->str.len;\n\twhile (add_post_var(arr, vars, eof TSRMLS_CC)) {\n\t\tif (++vars->cnt > max_vars) {\n\t\t\tphp_error_docref(NULL TSRMLS_CC, E_WARNING,\n\t\t\t\t\t\"Input variables exceeded %\" PRIu64 \". \"\n\t\t\t\t\t\"To increase the limit change max_input_vars in php.ini.\",\n\t\t\t\t\tmax_vars);\n\t\t\treturn FAILURE;\n \t\t}\n \t}\n \n\tif (!eof && vars->str.c != vars->ptr) {\n \t\tmemmove(vars->str.c, vars->ptr, vars->str.len = vars->end - vars->ptr);\n \t}\n \treturn SUCCESS;\n}",
        "llama3.1 CWE": "CWE-79",
        "llama3.1 CVE": "CVE-2012-5542",
        "llama3.1 BERT Score": {
            "BERTScore Precision": "0.3795",
            "BERTScore Recall": "0.5083",
            "BERTScore F1": "0.4345"
        },
        "llama3.1 Cosine_Similarity": 0.5134173035621643,
        "Mistral Summary": "The patch changes the condition for the memmove function to check if eof is true before moving data, preventing potential buffer overflows when eof is false. This was applied to fix a potential buffer overflow vulnerability caused by incorrectly copying data without checking the size of input.",
        "Mistral CWE": "CWE-190 (Buffer Copy Without Checking Size of Input)",
        "Mistral CVE": "Not provided, as it is typically assigned by the organization managing the vulnerable software and not specified in the commit message.",
        "Mistral Cosine_Similarity": 0.2809525728225708,
        "Mistral BERT Score": {
            "BERTScore Precision": "0.5233",
            "BERTScore Recall": "0.4674",
            "BERTScore F1": "0.4938"
        },
        "Tokens Used": ""
    },
    {
        "codeLink": "https://git.openssl.org/gitweb/?p=openssl.git;a=commit;h=af58be768ebb690f78530f796e92b8ae5c9a4401",
        "CVE ID": "CVE-2016-8610",
        "CVE Details": "A denial of service flaw was found in OpenSSL 0.9.8, 1.0.1, 1.0.2 through 1.0.2h, and 1.1.0 in the way the TLS/SSL protocol defined processing of ALERT packets during a connection handshake. A remote attacker could use this flaw to make a TLS/SSL server consume an excessive amount of CPU and fail to accept connections from other clients.",
        "CWE ID": "CWE-400",
        "commit_message": "None",
        "fixed_function": "int dtls1_read_bytes(SSL *s, int type, int *recvd_type, unsigned char *buf,\n                     int len, int peek)\n{\n    int al, i, j, ret;\n    unsigned int n;\n    SSL3_RECORD *rr;\n    void (*cb) (const SSL *ssl, int type2, int val) = NULL;\n\n    if (!SSL3_BUFFER_is_initialised(&s->rlayer.rbuf)) {\n        /* Not initialized yet */\n        if (!ssl3_setup_buffers(s))\n            return (-1);\n    }\n\n    if ((type && (type != SSL3_RT_APPLICATION_DATA) &&\n         (type != SSL3_RT_HANDSHAKE)) ||\n        (peek && (type != SSL3_RT_APPLICATION_DATA))) {\n        SSLerr(SSL_F_DTLS1_READ_BYTES, ERR_R_INTERNAL_ERROR);\n        return -1;\n    }\n\n    /*\n     * check whether there's a handshake message (client hello?) waiting\n     */\n    if ((ret = have_handshake_fragment(s, type, buf, len)))\n        return ret;\n\n    /*\n     * Now s->rlayer.d->handshake_fragment_len == 0 if\n     * type == SSL3_RT_HANDSHAKE.\n     */\n\n#ifndef OPENSSL_NO_SCTP\n    /*\n     * Continue handshake if it had to be interrupted to read app data with\n     * SCTP.\n     */\n    if ((!ossl_statem_get_in_handshake(s) && SSL_in_init(s)) ||\n        (BIO_dgram_is_sctp(SSL_get_rbio(s))\n         && ossl_statem_in_sctp_read_sock(s)\n         && s->s3->in_read_app_data != 2))\n#else\n    if (!ossl_statem_get_in_handshake(s) && SSL_in_init(s))\n#endif\n    {\n        /* type == SSL3_RT_APPLICATION_DATA */\n        i = s->handshake_func(s);\n        if (i < 0)\n            return (i);\n        if (i == 0) {\n            SSLerr(SSL_F_DTLS1_READ_BYTES, SSL_R_SSL_HANDSHAKE_FAILURE);\n            return (-1);\n        }\n    }\n\n start:\n    s->rwstate = SSL_NOTHING;\n\n    /*-\n     * s->s3->rrec.type         - is the type of record\n     * s->s3->rrec.data,    - data\n     * s->s3->rrec.off,     - offset into 'data' for next read\n     * s->s3->rrec.length,  - number of bytes.\n     */\n    rr = s->rlayer.rrec;\n\n    /*\n     * We are not handshaking and have no data yet, so process data buffered\n     * during the last handshake in advance, if any.\n     */\n    if (SSL_is_init_finished(s) && SSL3_RECORD_get_length(rr) == 0) {\n        pitem *item;\n        item = pqueue_pop(s->rlayer.d->buffered_app_data.q);\n        if (item) {\n#ifndef OPENSSL_NO_SCTP\n            /* Restore bio_dgram_sctp_rcvinfo struct */\n            if (BIO_dgram_is_sctp(SSL_get_rbio(s))) {\n                DTLS1_RECORD_DATA *rdata = (DTLS1_RECORD_DATA *)item->data;\n                BIO_ctrl(SSL_get_rbio(s), BIO_CTRL_DGRAM_SCTP_SET_RCVINFO,\n                         sizeof(rdata->recordinfo), &rdata->recordinfo);\n            }\n#endif\n\n            dtls1_copy_record(s, item);\n\n            OPENSSL_free(item->data);\n            pitem_free(item);\n        }\n    }\n\n    /* Check for timeout */\n    if (dtls1_handle_timeout(s) > 0)\n        goto start;\n\n    /* get new packet if necessary */\n    if ((SSL3_RECORD_get_length(rr) == 0)\n        || (s->rlayer.rstate == SSL_ST_READ_BODY)) {\n        ret = dtls1_get_record(s);\n        if (ret <= 0) {\n            ret = dtls1_read_failed(s, ret);\n            /* anything other than a timeout is an error */\n            if (ret <= 0)\n                return (ret);\n            else\n                goto start;\n         }\n     }\n \n    /*\n     * Reset the count of consecutive warning alerts if we've got a non-empty\n     * record that isn't an alert.\n     */\n    if (SSL3_RECORD_get_type(rr) != SSL3_RT_ALERT\n            && SSL3_RECORD_get_length(rr) != 0)\n        s->rlayer.alert_count = 0;\n\n     /* we now have a packet which can be read and processed */\n \n     if (s->s3->change_cipher_spec /* set when we receive ChangeCipherSpec,\n                                SSL3_RECORD_get_seq_num(rr)) < 0) {\n            SSLerr(SSL_F_DTLS1_READ_BYTES, ERR_R_INTERNAL_ERROR);\n            return -1;\n        }\n        SSL3_RECORD_set_length(rr, 0);\n        goto start;\n    }\n",
        "vul_function": "int dtls1_read_bytes(SSL *s, int type, int *recvd_type, unsigned char *buf,\n                     int len, int peek)\n{\n    int al, i, j, ret;\n    unsigned int n;\n    SSL3_RECORD *rr;\n    void (*cb) (const SSL *ssl, int type2, int val) = NULL;\n\n    if (!SSL3_BUFFER_is_initialised(&s->rlayer.rbuf)) {\n        /* Not initialized yet */\n        if (!ssl3_setup_buffers(s))\n            return (-1);\n    }\n\n    if ((type && (type != SSL3_RT_APPLICATION_DATA) &&\n         (type != SSL3_RT_HANDSHAKE)) ||\n        (peek && (type != SSL3_RT_APPLICATION_DATA))) {\n        SSLerr(SSL_F_DTLS1_READ_BYTES, ERR_R_INTERNAL_ERROR);\n        return -1;\n    }\n\n    /*\n     * check whether there's a handshake message (client hello?) waiting\n     */\n    if ((ret = have_handshake_fragment(s, type, buf, len)))\n        return ret;\n\n    /*\n     * Now s->rlayer.d->handshake_fragment_len == 0 if\n     * type == SSL3_RT_HANDSHAKE.\n     */\n\n#ifndef OPENSSL_NO_SCTP\n    /*\n     * Continue handshake if it had to be interrupted to read app data with\n     * SCTP.\n     */\n    if ((!ossl_statem_get_in_handshake(s) && SSL_in_init(s)) ||\n        (BIO_dgram_is_sctp(SSL_get_rbio(s))\n         && ossl_statem_in_sctp_read_sock(s)\n         && s->s3->in_read_app_data != 2))\n#else\n    if (!ossl_statem_get_in_handshake(s) && SSL_in_init(s))\n#endif\n    {\n        /* type == SSL3_RT_APPLICATION_DATA */\n        i = s->handshake_func(s);\n        if (i < 0)\n            return (i);\n        if (i == 0) {\n            SSLerr(SSL_F_DTLS1_READ_BYTES, SSL_R_SSL_HANDSHAKE_FAILURE);\n            return (-1);\n        }\n    }\n\n start:\n    s->rwstate = SSL_NOTHING;\n\n    /*-\n     * s->s3->rrec.type         - is the type of record\n     * s->s3->rrec.data,    - data\n     * s->s3->rrec.off,     - offset into 'data' for next read\n     * s->s3->rrec.length,  - number of bytes.\n     */\n    rr = s->rlayer.rrec;\n\n    /*\n     * We are not handshaking and have no data yet, so process data buffered\n     * during the last handshake in advance, if any.\n     */\n    if (SSL_is_init_finished(s) && SSL3_RECORD_get_length(rr) == 0) {\n        pitem *item;\n        item = pqueue_pop(s->rlayer.d->buffered_app_data.q);\n        if (item) {\n#ifndef OPENSSL_NO_SCTP\n            /* Restore bio_dgram_sctp_rcvinfo struct */\n            if (BIO_dgram_is_sctp(SSL_get_rbio(s))) {\n                DTLS1_RECORD_DATA *rdata = (DTLS1_RECORD_DATA *)item->data;\n                BIO_ctrl(SSL_get_rbio(s), BIO_CTRL_DGRAM_SCTP_SET_RCVINFO,\n                         sizeof(rdata->recordinfo), &rdata->recordinfo);\n            }\n#endif\n\n            dtls1_copy_record(s, item);\n\n            OPENSSL_free(item->data);\n            pitem_free(item);\n        }\n    }\n\n    /* Check for timeout */\n    if (dtls1_handle_timeout(s) > 0)\n        goto start;\n\n    /* get new packet if necessary */\n    if ((SSL3_RECORD_get_length(rr) == 0)\n        || (s->rlayer.rstate == SSL_ST_READ_BODY)) {\n        ret = dtls1_get_record(s);\n        if (ret <= 0) {\n            ret = dtls1_read_failed(s, ret);\n            /* anything other than a timeout is an error */\n            if (ret <= 0)\n                return (ret);\n            else\n                goto start;\n         }\n     }\n \n     /* we now have a packet which can be read and processed */\n \n     if (s->s3->change_cipher_spec /* set when we receive ChangeCipherSpec,\n                                SSL3_RECORD_get_seq_num(rr)) < 0) {\n            SSLerr(SSL_F_DTLS1_READ_BYTES, ERR_R_INTERNAL_ERROR);\n            return -1;\n        }\n        SSL3_RECORD_set_length(rr, 0);\n        goto start;\n    }\n",
        "llama3.1 Summary": null,
        "llama3.1 CWE": null,
        "llama3.1 CVE": null,
        "llama3.1 BERT Score": {
            "BERTScore Precision": "0.3118",
            "BERTScore Recall": "0.2183",
            "BERTScore F1": "0.2568"
        },
        "llama3.1 Cosine_Similarity": 0.054140329360961914,
        "Mistral Summary": null,
        "Mistral CWE": null,
        "Mistral CVE": null,
        "Mistral Cosine_Similarity": 0.054140329360961914,
        "Mistral BERT Score": {
            "BERTScore Precision": "0.3118",
            "BERTScore Recall": "0.2183",
            "BERTScore F1": "0.2568"
        },
        "Tokens Used": ""
    },
    {
        "codeLink": "https://github.com/torvalds/linux/commit/d29216842a85c7970c536108e093963f02714498",
        "CVE ID": "CVE-2016-6213",
        "CVE Details": "fs/namespace.c in the Linux kernel before 4.9 does not restrict how many mounts may exist in a mount namespace, which allows local users to cause a denial of service (memory consumption and deadlock) via MS_BIND mount system calls, as demonstrated by a loop that triggers exponential growth in the number of mounts.",
        "CWE ID": "CWE-400",
        "commit_message": "mnt: Add a per mount namespace limit on the number of mounts\n\nCAI Qian <caiqian@redhat.com> pointed out that the semantics\nof shared subtrees make it possible to create an exponentially\nincreasing number of mounts in a mount namespace.\n\n    mkdir /tmp/1 /tmp/2\n    mount --make-rshared /\n    for i in $(seq 1 20) ; do mount --bind /tmp/1 /tmp/2 ; done\n\nWill create create 2^20 or 1048576 mounts, which is a practical problem\nas some people have managed to hit this by accident.\n\nAs such CVE-2016-6213 was assigned.\n\nIan Kent <raven@themaw.net> described the situation for autofs users\nas follows:\n\n> The number of mounts for direct mount maps is usually not very large because of\n> the way they are implemented, large direct mount maps can have performance\n> problems. There can be anywhere from a few (likely case a few hundred) to less\n> than 10000, plus mounts that have been triggered and not yet expired.\n>\n> Indirect mounts have one autofs mount at the root plus the number of mounts that\n> have been triggered and not yet expired.\n>\n> The number of autofs indirect map entries can range from a few to the common\n> case of several thousand and in rare cases up to between 30000 and 50000. I've\n> not heard of people with maps larger than 50000 entries.\n>\n> The larger the number of map entries the greater the possibility for a large\n> number of active mounts so it's not hard to expect cases of a 1000 or somewhat\n> more active mounts.\n\nSo I am setting the default number of mounts allowed per mount\nnamespace at 100,000.  This is more than enough for any use case I\nknow of, but small enough to quickly stop an exponential increase\nin mounts.  Which should be perfect to catch misconfigurations and\nmalfunctioning programs.\n\nFor anyone who needs a higher limit this can be changed by writing\nto the new /proc/sys/fs/mount-max sysctl.\n\nTested-by: CAI Qian <caiqian@redhat.com>\nSigned-off-by: \"Eric W. Biederman\" <ebiederm@xmission.com>",
        "fixed_function": "static void umount_tree(struct mount *mnt, enum umount_tree_flags how)\n{\n\tLIST_HEAD(tmp_list);\n\tstruct mount *p;\n\n\tif (how & UMOUNT_PROPAGATE)\n\t\tpropagate_mount_unlock(mnt);\n\n\t/* Gather the mounts to umount */\n\tfor (p = mnt; p; p = next_mnt(p, mnt)) {\n\t\tp->mnt.mnt_flags |= MNT_UMOUNT;\n\t\tlist_move(&p->mnt_list, &tmp_list);\n\t}\n\n\t/* Hide the mounts from mnt_mounts */\n\tlist_for_each_entry(p, &tmp_list, mnt_list) {\n\t\tlist_del_init(&p->mnt_child);\n\t}\n\n\t/* Add propogated mounts to the tmp_list */\n\tif (how & UMOUNT_PROPAGATE)\n \t\tpropagate_umount(&tmp_list);\n \n \twhile (!list_empty(&tmp_list)) {\n\t\tstruct mnt_namespace *ns;\n \t\tbool disconnect;\n \t\tp = list_first_entry(&tmp_list, struct mount, mnt_list);\n \t\tlist_del_init(&p->mnt_expire);\n \t\tlist_del_init(&p->mnt_list);\n\t\tns = p->mnt_ns;\n\t\tif (ns) {\n\t\t\tns->mounts--;\n\t\t\t__touch_mnt_namespace(ns);\n\t\t}\n \t\tp->mnt_ns = NULL;\n \t\tif (how & UMOUNT_SYNC)\n \t\t\tp->mnt.mnt_flags |= MNT_SYNC_UMOUNT;\n\n\t\tdisconnect = disconnect_mount(p, how);\n\n\t\tpin_insert_group(&p->mnt_umount, &p->mnt_parent->mnt,\n\t\t\t\t disconnect ? &unmounted : NULL);\n\t\tif (mnt_has_parent(p)) {\n\t\t\tmnt_add_count(p->mnt_parent, -1);\n\t\t\tif (!disconnect) {\n\t\t\t\t/* Don't forget about p */\n\t\t\t\tlist_add_tail(&p->mnt_child, &p->mnt_parent->mnt_mounts);\n\t\t\t} else {\n\t\t\t\tumount_mnt(p);\n\t\t\t}\n\t\t}\n\t\tchange_mnt_propagation(p, MS_PRIVATE);\n\t}\n}\n",
        "vul_function": "static void umount_tree(struct mount *mnt, enum umount_tree_flags how)\n{\n\tLIST_HEAD(tmp_list);\n\tstruct mount *p;\n\n\tif (how & UMOUNT_PROPAGATE)\n\t\tpropagate_mount_unlock(mnt);\n\n\t/* Gather the mounts to umount */\n\tfor (p = mnt; p; p = next_mnt(p, mnt)) {\n\t\tp->mnt.mnt_flags |= MNT_UMOUNT;\n\t\tlist_move(&p->mnt_list, &tmp_list);\n\t}\n\n\t/* Hide the mounts from mnt_mounts */\n\tlist_for_each_entry(p, &tmp_list, mnt_list) {\n\t\tlist_del_init(&p->mnt_child);\n\t}\n\n\t/* Add propogated mounts to the tmp_list */\n\tif (how & UMOUNT_PROPAGATE)\n \t\tpropagate_umount(&tmp_list);\n \n \twhile (!list_empty(&tmp_list)) {\n \t\tbool disconnect;\n \t\tp = list_first_entry(&tmp_list, struct mount, mnt_list);\n \t\tlist_del_init(&p->mnt_expire);\n \t\tlist_del_init(&p->mnt_list);\n\t\t__touch_mnt_namespace(p->mnt_ns);\n \t\tp->mnt_ns = NULL;\n \t\tif (how & UMOUNT_SYNC)\n \t\t\tp->mnt.mnt_flags |= MNT_SYNC_UMOUNT;\n\n\t\tdisconnect = disconnect_mount(p, how);\n\n\t\tpin_insert_group(&p->mnt_umount, &p->mnt_parent->mnt,\n\t\t\t\t disconnect ? &unmounted : NULL);\n\t\tif (mnt_has_parent(p)) {\n\t\t\tmnt_add_count(p->mnt_parent, -1);\n\t\t\tif (!disconnect) {\n\t\t\t\t/* Don't forget about p */\n\t\t\t\tlist_add_tail(&p->mnt_child, &p->mnt_parent->mnt_mounts);\n\t\t\t} else {\n\t\t\t\tumount_mnt(p);\n\t\t\t}\n\t\t}\n\t\tchange_mnt_propagation(p, MS_PRIVATE);\n\t}\n}\n",
        "llama3.1 Summary": "The patch limits the number of mounts allowed per mount namespace to 100,000 to prevent an exponential increase in mounts due to shared subtrees. This change adds a new sysctl /proc/sys/fs/mount-max that allows users to adjust this limit if needed. Fixed version of function: static void umount_tree(struct mount *mnt, enum umount_tree_flags how) { ... }",
        "llama3.1 CWE": "CWE-416",
        "llama3.1 CVE": "CVE-2016-6213",
        "llama3.1 BERT Score": {
            "BERTScore Precision": "0.5693",
            "BERTScore Recall": "0.6248",
            "BERTScore F1": "0.5957"
        },
        "llama3.1 Cosine_Similarity": 0.5795158743858337,
        "Mistral Summary": "The patch limits the number of mounts per mount namespace to prevent an exponential increase in mounts and potential practical problems. This addresses the identified issue where a malfunctioning program or misconfiguration could create a large number of mounts, leading to performance issues or other problems. The default limit is set to 100,000, but it can be adjusted using the new /proc/sys/fs/mount-max sysctl.",
        "Mistral CWE": "CWE-400 (Improper Limitation of a Resource)",
        "Mistral CVE": "CVE-2016-6213",
        "Mistral Cosine_Similarity": 0.7189638018608093,
        "Mistral BERT Score": {
            "BERTScore Precision": "0.6315",
            "BERTScore Recall": "0.6363",
            "BERTScore F1": "0.6339"
        },
        "Tokens Used": ""
    },
    {
        "codeLink": "https://github.com/ccxvii/mujs/commit/00d4606c3baf813b7b1c176823b2729bf51002a2",
        "CVE ID": "CVE-2019-11413",
        "CVE Details": "An issue was discovered in Artifex MuJS 1.0.5. It has unlimited recursion because the match function in regexp.c lacks a depth check.",
        "CWE ID": "CWE-400",
        "commit_message": "Bug 700937: Limit recursion in regexp matcher.\n\nAlso handle negative return code as an error in the JS bindings.",
        "fixed_function": "static void Sp_replace_regexp(js_State *J)\n{\n\tjs_Regexp *re;\n\tconst char *source, *s, *r;\n\tjs_Buffer *sb = NULL;\n\tint n, x;\n\tResub m;\n\n \tsource = checkstring(J, 0);\n \tre = js_toregexp(J, 1);\n \n\tif (js_doregexec(J, re->prog, source, &m, 0)) {\n \t\tjs_copy(J, 0);\n \t\treturn;\n \t}\n\n\tre->last = 0;\n\nloop:\n\ts = m.sub[0].sp;\n\tn = m.sub[0].ep - m.sub[0].sp;\n\n\tif (js_iscallable(J, 2)) {\n\t\tjs_copy(J, 2);\n\t\tjs_pushundefined(J);\n\t\tfor (x = 0; m.sub[x].sp; ++x) /* arg 0..x: substring and subexps that matched */\n\t\t\tjs_pushlstring(J, m.sub[x].sp, m.sub[x].ep - m.sub[x].sp);\n\t\tjs_pushnumber(J, s - source); /* arg x+2: offset within search string */\n\t\tjs_copy(J, 0); /* arg x+3: search string */\n\t\tjs_call(J, 2 + x);\n\t\tr = js_tostring(J, -1);\n\t\tjs_putm(J, &sb, source, s);\n\t\tjs_puts(J, &sb, r);\n\t\tjs_pop(J, 1);\n\t} else {\n\t\tr = js_tostring(J, 2);\n\t\tjs_putm(J, &sb, source, s);\n\t\twhile (*r) {\n\t\t\tif (*r == '$') {\n\t\t\t\tswitch (*(++r)) {\n\t\t\t\tcase 0: --r; /* end of string; back up */\n\t\t\t\t/* fallthrough */\n\t\t\t\tcase '$': js_putc(J, &sb, '$'); break;\n\t\t\t\tcase '`': js_putm(J, &sb, source, s); break;\n\t\t\t\tcase '\\'': js_puts(J, &sb, s + n); break;\n\t\t\t\tcase '&':\n\t\t\t\t\tjs_putm(J, &sb, s, s + n);\n\t\t\t\t\tbreak;\n\t\t\t\tcase '0': case '1': case '2': case '3': case '4':\n\t\t\t\tcase '5': case '6': case '7': case '8': case '9':\n\t\t\t\t\tx = *r - '0';\n\t\t\t\t\tif (r[1] >= '0' && r[1] <= '9')\n\t\t\t\t\t\tx = x * 10 + *(++r) - '0';\n\t\t\t\t\tif (x > 0 && x < m.nsub) {\n\t\t\t\t\t\tjs_putm(J, &sb, m.sub[x].sp, m.sub[x].ep);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tjs_putc(J, &sb, '$');\n\t\t\t\t\t\tif (x > 10) {\n\t\t\t\t\t\t\tjs_putc(J, &sb, '0' + x / 10);\n\t\t\t\t\t\t\tjs_putc(J, &sb, '0' + x % 10);\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tjs_putc(J, &sb, '0' + x);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tdefault:\n\t\t\t\t\tjs_putc(J, &sb, '$');\n\t\t\t\t\tjs_putc(J, &sb, *r);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\t++r;\n\t\t\t} else {\n\t\t\t\tjs_putc(J, &sb, *r++);\n\t\t\t}\n\t\t}\n\t}\n\n\tif (re->flags & JS_REGEXP_G) {\n\t\tsource = m.sub[0].ep;\n\t\tif (n == 0) {\n\t\t\tif (*source)\n\t\t\t\tjs_putc(J, &sb, *source++);\n \t\t\telse\n \t\t\t\tgoto end;\n \t\t}\n\t\tif (!js_doregexec(J, re->prog, source, &m, REG_NOTBOL))\n \t\t\tgoto loop;\n \t}\n \nend:\n\tjs_puts(J, &sb, s + n);\n\tjs_putc(J, &sb, 0);\n\n\tif (js_try(J)) {\n\t\tjs_free(J, sb);\n\t\tjs_throw(J);\n\t}\n\tjs_pushstring(J, sb ? sb->s : \"\");\n\tjs_endtry(J);\n\tjs_free(J, sb);\n}\n",
        "vul_function": "static void Sp_replace_regexp(js_State *J)\n{\n\tjs_Regexp *re;\n\tconst char *source, *s, *r;\n\tjs_Buffer *sb = NULL;\n\tint n, x;\n\tResub m;\n\n \tsource = checkstring(J, 0);\n \tre = js_toregexp(J, 1);\n \n\tif (js_regexec(re->prog, source, &m, 0)) {\n \t\tjs_copy(J, 0);\n \t\treturn;\n \t}\n\n\tre->last = 0;\n\nloop:\n\ts = m.sub[0].sp;\n\tn = m.sub[0].ep - m.sub[0].sp;\n\n\tif (js_iscallable(J, 2)) {\n\t\tjs_copy(J, 2);\n\t\tjs_pushundefined(J);\n\t\tfor (x = 0; m.sub[x].sp; ++x) /* arg 0..x: substring and subexps that matched */\n\t\t\tjs_pushlstring(J, m.sub[x].sp, m.sub[x].ep - m.sub[x].sp);\n\t\tjs_pushnumber(J, s - source); /* arg x+2: offset within search string */\n\t\tjs_copy(J, 0); /* arg x+3: search string */\n\t\tjs_call(J, 2 + x);\n\t\tr = js_tostring(J, -1);\n\t\tjs_putm(J, &sb, source, s);\n\t\tjs_puts(J, &sb, r);\n\t\tjs_pop(J, 1);\n\t} else {\n\t\tr = js_tostring(J, 2);\n\t\tjs_putm(J, &sb, source, s);\n\t\twhile (*r) {\n\t\t\tif (*r == '$') {\n\t\t\t\tswitch (*(++r)) {\n\t\t\t\tcase 0: --r; /* end of string; back up */\n\t\t\t\t/* fallthrough */\n\t\t\t\tcase '$': js_putc(J, &sb, '$'); break;\n\t\t\t\tcase '`': js_putm(J, &sb, source, s); break;\n\t\t\t\tcase '\\'': js_puts(J, &sb, s + n); break;\n\t\t\t\tcase '&':\n\t\t\t\t\tjs_putm(J, &sb, s, s + n);\n\t\t\t\t\tbreak;\n\t\t\t\tcase '0': case '1': case '2': case '3': case '4':\n\t\t\t\tcase '5': case '6': case '7': case '8': case '9':\n\t\t\t\t\tx = *r - '0';\n\t\t\t\t\tif (r[1] >= '0' && r[1] <= '9')\n\t\t\t\t\t\tx = x * 10 + *(++r) - '0';\n\t\t\t\t\tif (x > 0 && x < m.nsub) {\n\t\t\t\t\t\tjs_putm(J, &sb, m.sub[x].sp, m.sub[x].ep);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tjs_putc(J, &sb, '$');\n\t\t\t\t\t\tif (x > 10) {\n\t\t\t\t\t\t\tjs_putc(J, &sb, '0' + x / 10);\n\t\t\t\t\t\t\tjs_putc(J, &sb, '0' + x % 10);\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tjs_putc(J, &sb, '0' + x);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tdefault:\n\t\t\t\t\tjs_putc(J, &sb, '$');\n\t\t\t\t\tjs_putc(J, &sb, *r);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\t++r;\n\t\t\t} else {\n\t\t\t\tjs_putc(J, &sb, *r++);\n\t\t\t}\n\t\t}\n\t}\n\n\tif (re->flags & JS_REGEXP_G) {\n\t\tsource = m.sub[0].ep;\n\t\tif (n == 0) {\n\t\t\tif (*source)\n\t\t\t\tjs_putc(J, &sb, *source++);\n \t\t\telse\n \t\t\t\tgoto end;\n \t\t}\n\t\tif (!js_regexec(re->prog, source, &m, REG_NOTBOL))\n \t\t\tgoto loop;\n \t}\n \nend:\n\tjs_puts(J, &sb, s + n);\n\tjs_putc(J, &sb, 0);\n\n\tif (js_try(J)) {\n\t\tjs_free(J, sb);\n\t\tjs_throw(J);\n\t}\n\tjs_pushstring(J, sb ? sb->s : \"\");\n\tjs_endtry(J);\n\tjs_free(J, sb);\n}\n",
        "llama3.1 Summary": "The patch limits recursion in the regular expression matcher by checking the return value of js_regexec and handling a negative return code as an error, preventing potential stack overflows and crashes caused by unbounded recursion.",
        "llama3.1 CWE": "CWE-676",
        "llama3.1 CVE": "CVE-2010-4165",
        "llama3.1 BERT Score": {
            "BERTScore Precision": "0.6041",
            "BERTScore Recall": "0.6300",
            "BERTScore F1": "0.6168"
        },
        "llama3.1 Cosine_Similarity": 0.5379659533500671,
        "Mistral Summary": null,
        "Mistral CWE": null,
        "Mistral CVE": null,
        "Mistral Cosine_Similarity": 0.06547361612319946,
        "Mistral BERT Score": {
            "BERTScore Precision": "0.3327",
            "BERTScore Recall": "0.3134",
            "BERTScore F1": "0.3228"
        },
        "Tokens Used": ""
    },
    {
        "codeLink": "https://github.com/torvalds/linux/commit/d29216842a85c7970c536108e093963f02714498",
        "CVE ID": "CVE-2016-6213",
        "CVE Details": "fs/namespace.c in the Linux kernel before 4.9 does not restrict how many mounts may exist in a mount namespace, which allows local users to cause a denial of service (memory consumption and deadlock) via MS_BIND mount system calls, as demonstrated by a loop that triggers exponential growth in the number of mounts.",
        "CWE ID": "CWE-400",
        "commit_message": "mnt: Add a per mount namespace limit on the number of mounts\n\nCAI Qian <caiqian@redhat.com> pointed out that the semantics\nof shared subtrees make it possible to create an exponentially\nincreasing number of mounts in a mount namespace.\n\n    mkdir /tmp/1 /tmp/2\n    mount --make-rshared /\n    for i in $(seq 1 20) ; do mount --bind /tmp/1 /tmp/2 ; done\n\nWill create create 2^20 or 1048576 mounts, which is a practical problem\nas some people have managed to hit this by accident.\n\nAs such CVE-2016-6213 was assigned.\n\nIan Kent <raven@themaw.net> described the situation for autofs users\nas follows:\n\n> The number of mounts for direct mount maps is usually not very large because of\n> the way they are implemented, large direct mount maps can have performance\n> problems. There can be anywhere from a few (likely case a few hundred) to less\n> than 10000, plus mounts that have been triggered and not yet expired.\n>\n> Indirect mounts have one autofs mount at the root plus the number of mounts that\n> have been triggered and not yet expired.\n>\n> The number of autofs indirect map entries can range from a few to the common\n> case of several thousand and in rare cases up to between 30000 and 50000. I've\n> not heard of people with maps larger than 50000 entries.\n>\n> The larger the number of map entries the greater the possibility for a large\n> number of active mounts so it's not hard to expect cases of a 1000 or somewhat\n> more active mounts.\n\nSo I am setting the default number of mounts allowed per mount\nnamespace at 100,000.  This is more than enough for any use case I\nknow of, but small enough to quickly stop an exponential increase\nin mounts.  Which should be perfect to catch misconfigurations and\nmalfunctioning programs.\n\nFor anyone who needs a higher limit this can be changed by writing\nto the new /proc/sys/fs/mount-max sysctl.\n\nTested-by: CAI Qian <caiqian@redhat.com>\nSigned-off-by: \"Eric W. Biederman\" <ebiederm@xmission.com>",
        "fixed_function": "static int attach_recursive_mnt(struct mount *source_mnt,\n\t\t\tstruct mount *dest_mnt,\n\t\t\tstruct mountpoint *dest_mp,\n \t\t\tstruct path *parent_path)\n {\n \tHLIST_HEAD(tree_list);\n\tstruct mnt_namespace *ns = dest_mnt->mnt_ns;\n \tstruct mount *child, *p;\n \tstruct hlist_node *n;\n \tint err;\n \n\t/* Is there space to add these mounts to the mount namespace? */\n\tif (!parent_path) {\n\t\terr = count_mounts(ns, source_mnt);\n\t\tif (err)\n\t\t\tgoto out;\n\t}\n\n \tif (IS_MNT_SHARED(dest_mnt)) {\n \t\terr = invent_group_ids(source_mnt, true);\n \t\tif (err)\n\t\t\tgoto out;\n\t\terr = propagate_mnt(dest_mnt, dest_mp, source_mnt, &tree_list);\n\t\tlock_mount_hash();\n\t\tif (err)\n\t\t\tgoto out_cleanup_ids;\n\t\tfor (p = source_mnt; p; p = next_mnt(p, source_mnt))\n\t\t\tset_mnt_shared(p);\n\t} else {\n\t\tlock_mount_hash();\n\t}\n\tif (parent_path) {\n\t\tdetach_mnt(source_mnt, parent_path);\n\t\tattach_mnt(source_mnt, dest_mnt, dest_mp);\n\t\ttouch_mnt_namespace(source_mnt->mnt_ns);\n\t} else {\n\t\tmnt_set_mountpoint(dest_mnt, dest_mp, source_mnt);\n\t\tcommit_tree(source_mnt, NULL);\n\t}\n\n\thlist_for_each_entry_safe(child, n, &tree_list, mnt_hash) {\n\t\tstruct mount *q;\n\t\thlist_del_init(&child->mnt_hash);\n\t\tq = __lookup_mnt_last(&child->mnt_parent->mnt,\n\t\t\t\t      child->mnt_mountpoint);\n\t\tcommit_tree(child, q);\n\t}\n\tunlock_mount_hash();\n\n\treturn 0;\n\n  out_cleanup_ids:\n \twhile (!hlist_empty(&tree_list)) {\n \t\tchild = hlist_entry(tree_list.first, struct mount, mnt_hash);\n\t\tchild->mnt_parent->mnt_ns->pending_mounts = 0;\n \t\tumount_tree(child, UMOUNT_SYNC);\n \t}\n \tunlock_mount_hash();\n \tcleanup_group_ids(source_mnt, NULL);\n  out:\n\tns->pending_mounts = 0;\n \treturn err;\n }\n",
        "vul_function": "static int attach_recursive_mnt(struct mount *source_mnt,\n\t\t\tstruct mount *dest_mnt,\n\t\t\tstruct mountpoint *dest_mp,\n \t\t\tstruct path *parent_path)\n {\n \tHLIST_HEAD(tree_list);\n \tstruct mount *child, *p;\n \tstruct hlist_node *n;\n \tint err;\n \n \tif (IS_MNT_SHARED(dest_mnt)) {\n \t\terr = invent_group_ids(source_mnt, true);\n \t\tif (err)\n\t\t\tgoto out;\n\t\terr = propagate_mnt(dest_mnt, dest_mp, source_mnt, &tree_list);\n\t\tlock_mount_hash();\n\t\tif (err)\n\t\t\tgoto out_cleanup_ids;\n\t\tfor (p = source_mnt; p; p = next_mnt(p, source_mnt))\n\t\t\tset_mnt_shared(p);\n\t} else {\n\t\tlock_mount_hash();\n\t}\n\tif (parent_path) {\n\t\tdetach_mnt(source_mnt, parent_path);\n\t\tattach_mnt(source_mnt, dest_mnt, dest_mp);\n\t\ttouch_mnt_namespace(source_mnt->mnt_ns);\n\t} else {\n\t\tmnt_set_mountpoint(dest_mnt, dest_mp, source_mnt);\n\t\tcommit_tree(source_mnt, NULL);\n\t}\n\n\thlist_for_each_entry_safe(child, n, &tree_list, mnt_hash) {\n\t\tstruct mount *q;\n\t\thlist_del_init(&child->mnt_hash);\n\t\tq = __lookup_mnt_last(&child->mnt_parent->mnt,\n\t\t\t\t      child->mnt_mountpoint);\n\t\tcommit_tree(child, q);\n\t}\n\tunlock_mount_hash();\n\n\treturn 0;\n\n  out_cleanup_ids:\n \twhile (!hlist_empty(&tree_list)) {\n \t\tchild = hlist_entry(tree_list.first, struct mount, mnt_hash);\n \t\tumount_tree(child, UMOUNT_SYNC);\n \t}\n \tunlock_mount_hash();\n \tcleanup_group_ids(source_mnt, NULL);\n  out:\n \treturn err;\n }\n",
        "llama3.1 Summary": "The patch changes the way mount namespaces handle shared subtrees, introducing a per-mount namespace limit on the number of mounts to prevent an exponential increase in mounts. This change was applied to address a vulnerability that allowed an attacker to create a large number of mounts in a single namespace.",
        "llama3.1 CWE": "CWE-415",
        "llama3.1 CVE": "CVE-2016-6213",
        "llama3.1 BERT Score": {
            "BERTScore Precision": "0.6515",
            "BERTScore Recall": "0.6064",
            "BERTScore F1": "0.6281"
        },
        "llama3.1 Cosine_Similarity": 0.6794182658195496,
        "Mistral Summary": null,
        "Mistral CWE": "CWE-200 (Improper Input Validation)\n   Vulnerability Description: The original function does not validate or limit the number of mounts, allowing for an exponential increase in the number of mounts which can cause practical problems and lead to a denial of service.\n\n   CVE ID: CVE-2016-6213\n   Vulnerability Disclosure: The vulnerability allows for creating a large number of mounts in a mount namespace, potentially leading to practical problems or a denial of service. In some cases, this can lead to 2^20 or 1048576 mounts being created accidentally.\n\n   Mitigation: The patch limits the default number of mounts allowed per mount namespace at 100,000. This is more than enough for any known use case but small enough to quickly stop an exponential increase in mounts, which should help catch misconfigurations and malfunctioning programs. A higher limit can be changed by writing to the new /proc/sys/fs/mount-max sysctl.",
        "Mistral CVE": null,
        "Mistral Cosine_Similarity": 0.07386380434036255,
        "Mistral BERT Score": {
            "BERTScore Precision": "0.3283",
            "BERTScore Recall": "0.2429",
            "BERTScore F1": "0.2792"
        },
        "Tokens Used": ""
    },
    {
        "num": 3,
        "codeLink": "https://github.com/php/php-src/commit/69dee5c732fe982c82edb17d0dbc3e79a47748d8",
        "CVE ID": "CVE-2015-9253",
        "CVE Details": "An issue was discovered in PHP 7.3.x before 7.3.0alpha3, 7.2.x before 7.2.8, and before 7.1.20. The php-fpm master process restarts a child process in an endless loop when using program execution functions (e.g., passthru, exec, shell_exec, or system) with a non-blocking STDIN stream, causing this master process to consume 100% of the CPU, and consume disk space with a large volume of error logs, as demonstrated by an attack by a customer of a shared-hosting facility.",
        "CWE ID": "CWE-400",
        "commit_message": "Fixed bug #73342\n\nDirectly listen on socket, instead of duping it to STDIN and\nlistening on that.",
        "fixed_function": "int fpm_stdio_init_child(struct fpm_worker_pool_s *wp) /* {{{ */\n{\n#ifdef HAVE_SYSLOG_H\n\tif (fpm_globals.error_log_fd == ZLOG_SYSLOG) {\n\t\tcloselog(); /* ensure to close syslog not to interrupt with PHP syslog code */\n\t} else\n#endif\n\n\t/* Notice: child cannot use master error_log\n\t * because not aware when being reopen\n\t * else, should use if (!fpm_use_error_log())\n\t */\n\tif (fpm_globals.error_log_fd > 0) {\n\t\tclose(fpm_globals.error_log_fd);\n\t}\n \tfpm_globals.error_log_fd = -1;\n \tzlog_set_fd(-1);\n \n \treturn 0;\n }\n /* }}} */\n",
        "vul_function": "int fpm_stdio_init_child(struct fpm_worker_pool_s *wp) /* {{{ */\n{\n#ifdef HAVE_SYSLOG_H\n\tif (fpm_globals.error_log_fd == ZLOG_SYSLOG) {\n\t\tcloselog(); /* ensure to close syslog not to interrupt with PHP syslog code */\n\t} else\n#endif\n\n\t/* Notice: child cannot use master error_log\n\t * because not aware when being reopen\n\t * else, should use if (!fpm_use_error_log())\n\t */\n\tif (fpm_globals.error_log_fd > 0) {\n\t\tclose(fpm_globals.error_log_fd);\n\t}\n \tfpm_globals.error_log_fd = -1;\n \tzlog_set_fd(-1);\n \n\tif (wp->listening_socket != STDIN_FILENO) {\n\t\tif (0 > dup2(wp->listening_socket, STDIN_FILENO)) {\n\t\t\tzlog(ZLOG_SYSERROR, \"failed to init child stdio: dup2()\");\n\t\t\treturn -1;\n\t\t}\n\t}\n \treturn 0;\n }\n /* }}} */\n",
        "llama3.1 Summary": "The patch changes the function to directly listen on a socket without duplicating its file descriptor to STDIN, fixing an issue where the program would fail to initialize child stdio due to incorrect file descriptor handling. This change was made to correct a bug that occurred when trying to duplicate the listening socket's file descriptor to STDIN.",
        "llama3.1 CWE": "CWE-79",
        "llama3.1 CVE": "CVE-2022-28786",
        "llama3.1 BERT Score": {
            "BERTScore Precision": "0.5432",
            "BERTScore Recall": "0.4973",
            "BERTScore F1": "0.5192"
        },
        "llama3.1 Cosine_Similarity": 0.3407672047615051,
        "Mistral Summary": "The patch fixes a file descriptor misuse vulnerability by removing the operation of duping a socket to STDIN and instead directly listening on the socket. This change prevents potential attacks exploiting improper use of open file descriptors in child processes.",
        "Mistral CWE": "CWE-20",
        "Mistral CVE": "Unassigned (Since the CVE ID is assigned by a public authority like MITRE, it cannot be determined without their involvement)",
        "Mistral Cosine_Similarity": 0.40182191133499146,
        "Mistral BERT Score": {
            "BERTScore Precision": "0.6073",
            "BERTScore Recall": "0.5139",
            "BERTScore F1": "0.5567"
        },
        "Tokens Used": ""
    },
    {
        "codeLink": "https://github.com/torvalds/linux/commit/c40f7d74c741a907cfaeb73a7697081881c497d0",
        "CVE ID": "CVE-2018-20784",
        "CVE Details": "In the Linux kernel before 4.20.2, kernel/sched/fair.c mishandles leaf cfs_rq's, which allows attackers to cause a denial of service (infinite loop in update_blocked_averages) or possibly have unspecified other impact by inducing a high load.",
        "CWE ID": "CWE-400",
        "commit_message": "sched/fair: Fix infinite loop in update_blocked_averages() by reverting a9e7f6544b9c\n\nZhipeng Xie, Xie XiuQi and Sargun Dhillon reported lockups in the\nscheduler under high loads, starting at around the v4.18 time frame,\nand Zhipeng Xie tracked it down to bugs in the rq->leaf_cfs_rq_list\nmanipulation.\n\nDo a (manual) revert of:\n\n  a9e7f6544b9c (\"sched/fair: Fix O(nr_cgroups) in load balance path\")\n\nIt turns out that the list_del_leaf_cfs_rq() introduced by this commit\nis a surprising property that was not considered in followup commits\nsuch as:\n\n  9c2791f936ef (\"sched/fair: Fix hierarchical order in rq->leaf_cfs_rq_list\")\n\nAs Vincent Guittot explains:\n\n \"I think that there is a bigger problem with commit a9e7f6544b9c and\n  cfs_rq throttling:\n\n  Let take the example of the following topology TG2 --> TG1 --> root:\n\n   1) The 1st time a task is enqueued, we will add TG2 cfs_rq then TG1\n      cfs_rq to leaf_cfs_rq_list and we are sure to do the whole branch in\n      one path because it has never been used and can't be throttled so\n      tmp_alone_branch will point to leaf_cfs_rq_list at the end.\n\n   2) Then TG1 is throttled\n\n   3) and we add TG3 as a new child of TG1.\n\n   4) The 1st enqueue of a task on TG3 will add TG3 cfs_rq just before TG1\n      cfs_rq and tmp_alone_branch will stay  on rq->leaf_cfs_rq_list.\n\n  With commit a9e7f6544b9c, we can del a cfs_rq from rq->leaf_cfs_rq_list.\n  So if the load of TG1 cfs_rq becomes NULL before step 2) above, TG1\n  cfs_rq is removed from the list.\n  Then at step 4), TG3 cfs_rq is added at the beginning of rq->leaf_cfs_rq_list\n  but tmp_alone_branch still points to TG3 cfs_rq because its throttled\n  parent can't be enqueued when the lock is released.\n  tmp_alone_branch doesn't point to rq->leaf_cfs_rq_list whereas it should.\n\n  So if TG3 cfs_rq is removed or destroyed before tmp_alone_branch\n  points on another TG cfs_rq, the next TG cfs_rq that will be added,\n  will be linked outside rq->leaf_cfs_rq_list - which is bad.\n\n  In addition, we can break the ordering of the cfs_rq in\n  rq->leaf_cfs_rq_list but this ordering is used to update and\n  propagate the update from leaf down to root.\"\n\nInstead of trying to work through all these cases and trying to reproduce\nthe very high loads that produced the lockup to begin with, simplify\nthe code temporarily by reverting a9e7f6544b9c - which change was clearly\nnot thought through completely.\n\nThis (hopefully) gives us a kernel that doesn't lock up so people\ncan continue to enjoy their holidays without worrying about regressions. ;-)\n\n[ mingo: Wrote changelog, fixed weird spelling in code comment while at it. ]\n\nAnalyzed-by: Xie XiuQi <xiexiuqi@huawei.com>\nAnalyzed-by: Vincent Guittot <vincent.guittot@linaro.org>\nReported-by: Zhipeng Xie <xiezhipeng1@huawei.com>\nReported-by: Sargun Dhillon <sargun@sargun.me>\nReported-by: Xie XiuQi <xiexiuqi@huawei.com>\nTested-by: Zhipeng Xie <xiezhipeng1@huawei.com>\nTested-by: Sargun Dhillon <sargun@sargun.me>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>\nAcked-by: Vincent Guittot <vincent.guittot@linaro.org>\nCc: <stable@vger.kernel.org> # v4.13+\nCc: Bin Li <huawei.libin@huawei.com>\nCc: Mike Galbraith <efault@gmx.de>\nCc: Peter Zijlstra <peterz@infradead.org>\nCc: Tejun Heo <tj@kernel.org>\nCc: Thomas Gleixner <tglx@linutronix.de>\nFixes: a9e7f6544b9c (\"sched/fair: Fix O(nr_cgroups) in load balance path\")\nLink: http://lkml.kernel.org/r/1545879866-27809-1-git-send-email-xiexiuqi@huawei.com\nSigned-off-by: Ingo Molnar <mingo@kernel.org>",
        "fixed_function": " static void update_blocked_averages(int cpu)\n {\n \tstruct rq *rq = cpu_rq(cpu);\n\tstruct cfs_rq *cfs_rq;\n \tconst struct sched_class *curr_class;\n \tstruct rq_flags rf;\n \tbool done = true;\n\n\trq_lock_irqsave(rq, &rf);\n\tupdate_rq_clock(rq);\n\n\t/*\n \t * Iterates the task_group tree in a bottom up fashion, see\n \t * list_add_leaf_cfs_rq() for details.\n \t */\n\tfor_each_leaf_cfs_rq(rq, cfs_rq) {\n \t\tstruct sched_entity *se;\n \n \t\t/* throttled entities do not contribute to load */\n\t\tif (throttled_hierarchy(cfs_rq))\n\t\t\tcontinue;\n\n\t\tif (update_cfs_rq_load_avg(cfs_rq_clock_task(cfs_rq), cfs_rq))\n\t\t\tupdate_tg_load_avg(cfs_rq, 0);\n\n\t\t/* Propagate pending load changes to the parent, if any: */\n\t\tse = cfs_rq->tg->se[cpu];\n \t\tif (se && !skip_blocked_update(se))\n \t\t\tupdate_load_avg(cfs_rq_of(se), se, 0);\n \n \t\t/* Don't need periodic decay once load/util_avg are null */\n \t\tif (cfs_rq_has_blocked(cfs_rq))\n \t\t\tdone = false;\n\t}\n\n\tcurr_class = rq->curr->sched_class;\n\tupdate_rt_rq_load_avg(rq_clock_task(rq), rq, curr_class == &rt_sched_class);\n\tupdate_dl_rq_load_avg(rq_clock_task(rq), rq, curr_class == &dl_sched_class);\n\tupdate_irq_load_avg(rq, 0);\n\t/* Don't need periodic decay once load/util_avg are null */\n\tif (others_have_blocked(rq))\n\t\tdone = false;\n\n#ifdef CONFIG_NO_HZ_COMMON\n\trq->last_blocked_load_update_tick = jiffies;\n\tif (done)\n\t\trq->has_blocked_load = 0;\n#endif\n\trq_unlock_irqrestore(rq, &rf);\n}\n",
        "vul_function": " static void update_blocked_averages(int cpu)\n {\n \tstruct rq *rq = cpu_rq(cpu);\n\tstruct cfs_rq *cfs_rq, *pos;\n \tconst struct sched_class *curr_class;\n \tstruct rq_flags rf;\n \tbool done = true;\n\n\trq_lock_irqsave(rq, &rf);\n\tupdate_rq_clock(rq);\n\n\t/*\n \t * Iterates the task_group tree in a bottom up fashion, see\n \t * list_add_leaf_cfs_rq() for details.\n \t */\n\tfor_each_leaf_cfs_rq_safe(rq, cfs_rq, pos) {\n \t\tstruct sched_entity *se;\n \n \t\t/* throttled entities do not contribute to load */\n\t\tif (throttled_hierarchy(cfs_rq))\n\t\t\tcontinue;\n\n\t\tif (update_cfs_rq_load_avg(cfs_rq_clock_task(cfs_rq), cfs_rq))\n\t\t\tupdate_tg_load_avg(cfs_rq, 0);\n\n\t\t/* Propagate pending load changes to the parent, if any: */\n\t\tse = cfs_rq->tg->se[cpu];\n \t\tif (se && !skip_blocked_update(se))\n \t\t\tupdate_load_avg(cfs_rq_of(se), se, 0);\n \n\t\t/*\n\t\t * There can be a lot of idle CPU cgroups.  Don't let fully\n\t\t * decayed cfs_rqs linger on the list.\n\t\t */\n\t\tif (cfs_rq_is_decayed(cfs_rq))\n\t\t\tlist_del_leaf_cfs_rq(cfs_rq);\n \t\t/* Don't need periodic decay once load/util_avg are null */\n \t\tif (cfs_rq_has_blocked(cfs_rq))\n \t\t\tdone = false;\n\t}\n\n\tcurr_class = rq->curr->sched_class;\n\tupdate_rt_rq_load_avg(rq_clock_task(rq), rq, curr_class == &rt_sched_class);\n\tupdate_dl_rq_load_avg(rq_clock_task(rq), rq, curr_class == &dl_sched_class);\n\tupdate_irq_load_avg(rq, 0);\n\t/* Don't need periodic decay once load/util_avg are null */\n\tif (others_have_blocked(rq))\n\t\tdone = false;\n\n#ifdef CONFIG_NO_HZ_COMMON\n\trq->last_blocked_load_update_tick = jiffies;\n\tif (done)\n\t\trq->has_blocked_load = 0;\n#endif\n\trq_unlock_irqrestore(rq, &rf);\n}\n",
        "llama3.1 Summary": null,
        "llama3.1 CWE": null,
        "llama3.1 CVE": null,
        "llama3.1 BERT Score": {
            "BERTScore Precision": "0.3194",
            "BERTScore Recall": "0.2333",
            "BERTScore F1": "0.2696"
        },
        "llama3.1 Cosine_Similarity": 0.08188015222549438,
        "Mistral Summary": null,
        "Mistral CWE": null,
        "Mistral CVE": null,
        "Mistral Cosine_Similarity": 0.08188015222549438,
        "Mistral BERT Score": {
            "BERTScore Precision": "0.3194",
            "BERTScore Recall": "0.2333",
            "BERTScore F1": "0.2696"
        },
        "Tokens Used": ""
    },
    {
        "num": 4,
        "codeLink": "https://github.com/php/php-src/commit/a15bffd105ac28fd0dd9b596632dbf035238fda3",
        "CVE ID": "CVE-2017-11142",
        "CVE Details": "In PHP before 5.6.31, 7.x before 7.0.17, and 7.1.x before 7.1.3, remote attackers could cause a CPU consumption denial of service attack by injecting long form variables, related to main/php_variables.c.",
        "CWE ID": "CWE-400",
        "commit_message": "Fix bug #73807",
        "fixed_function": " static zend_bool add_post_var(zval *arr, post_var_data_t *var, zend_bool eof)\n {\n\tchar *start, *ksep, *vsep, *val;\n \tsize_t klen, vlen;\n \tsize_t new_vlen;\n \n \tif (var->ptr >= var->end) {\n \t\treturn 0;\n \t}\n \n\tstart = var->ptr + var->already_scanned;\n\tvsep = memchr(start, '&', var->end - start);\n \tif (!vsep) {\n \t\tif (!eof) {\n\t\t\tvar->already_scanned = var->end - var->ptr;\n \t\t\treturn 0;\n \t\t} else {\n \t\t\tvsep = var->end;\n\t\t}\n\t}\n\n\tksep = memchr(var->ptr, '=', vsep - var->ptr);\n\tif (ksep) {\n\t\t*ksep = '\\0';\n\t\t/* \"foo=bar&\" or \"foo=&\" */\n\t\tklen = ksep - var->ptr;\n\t\tvlen = vsep - ++ksep;\n\t} else {\n\t\tksep = \"\";\n\t\t/* \"foo&\" */\n\t\tklen = vsep - var->ptr;\n\t\tvlen = 0;\n\t}\n\n\tphp_url_decode(var->ptr, klen);\n\n\tval = estrndup(ksep, vlen);\n\tif (vlen) {\n\t\tvlen = php_url_decode(val, vlen);\n\t}\n\n\tif (sapi_module.input_filter(PARSE_POST, var->ptr, &val, vlen, &new_vlen)) {\n\t\tphp_register_variable_safe(var->ptr, val, new_vlen, arr);\n\t}\n \tefree(val);\n \n \tvar->ptr = vsep + (vsep != var->end);\n\tvar->already_scanned = 0;\n \treturn 1;\n }\n",
        "vul_function": " static zend_bool add_post_var(zval *arr, post_var_data_t *var, zend_bool eof)\n {\n\tchar *ksep, *vsep, *val;\n \tsize_t klen, vlen;\n \tsize_t new_vlen;\n \n \tif (var->ptr >= var->end) {\n \t\treturn 0;\n \t}\n \n\tvsep = memchr(var->ptr, '&', var->end - var->ptr);\n \tif (!vsep) {\n \t\tif (!eof) {\n \t\t\treturn 0;\n \t\t} else {\n \t\t\tvsep = var->end;\n\t\t}\n\t}\n\n\tksep = memchr(var->ptr, '=', vsep - var->ptr);\n\tif (ksep) {\n\t\t*ksep = '\\0';\n\t\t/* \"foo=bar&\" or \"foo=&\" */\n\t\tklen = ksep - var->ptr;\n\t\tvlen = vsep - ++ksep;\n\t} else {\n\t\tksep = \"\";\n\t\t/* \"foo&\" */\n\t\tklen = vsep - var->ptr;\n\t\tvlen = 0;\n\t}\n\n\tphp_url_decode(var->ptr, klen);\n\n\tval = estrndup(ksep, vlen);\n\tif (vlen) {\n\t\tvlen = php_url_decode(val, vlen);\n\t}\n\n\tif (sapi_module.input_filter(PARSE_POST, var->ptr, &val, vlen, &new_vlen)) {\n\t\tphp_register_variable_safe(var->ptr, val, new_vlen, arr);\n\t}\n \tefree(val);\n \n \tvar->ptr = vsep + (vsep != var->end);\n \treturn 1;\n }\n",
        "llama3.1 Summary": "The patch changes the way the function handles NULL characters in URLs to prevent data corruption and incorrect parsing. The fix was applied to address a security vulnerability that allowed an attacker to inject malicious content into the URL.\nFixed version of function: \nstatic zend_bool add_post_var(zval *arr, post_var_data_t *var, zend_bool eof)\n{\n\tchar *start, *ksep, *vsep, *val;\n \tsize_t klen, vlen;\n \tsize_t new_vlen;\n\n \tif (var->ptr >= var->end) {\n \t\treturn 0;\n \t}\n\n\tstart = var->ptr + var->already_scanned;\n\tvsep = memchr(start, '&', var->end - start);\n \tif (!vsep) {\n \t\tif (!eof) {\n\t\t\tvar->already_scanned = var->end - var->ptr;\n \t\t\treturn 0;\n \t\t} else {\n \t\t\tvsep = var->end;\n\t\t}\n\t}\n\n\tksep = memchr(var->ptr, '=', vsep - var->ptr);\n\tif (ksep) {\n\t\t*ksep = '\\0';\n\t\t/* \"foo=bar&\" or \"foo=&\" */\n\t\tklen = ksep - var->ptr;\n\t\tvlen = vsep - ++ksep;\n\t} else {\n\t\tksep = \"\";\n\t\t/* \"foo&\" */\n\t\tklen = vsep - var->ptr;\n\t\tvlen = 0;\n\t}\n\n\tphp_url_decode(var->ptr, klen);\n\n\tval = estrndup(ksep, vlen);\n\tif (vlen) {\n\t\tvlen = php_url_decode(val, vlen);\n\t}\n\n\tif (sapi_module.input_filter(PARSE_POST, var->ptr, &val, vlen, &new_vlen)) {\n\t\tphp_register_variable_safe(var->ptr, val, new_vlen, arr);\n\t}\n \tefree(val);\n\n \tvar->ptr = vsep + (vsep != var->end);\n\tvar->already_scanned = 0;\n \treturn 1;\n}",
        "llama3.1 CWE": "CWE-94",
        "llama3.1 CVE": "CVE-2013-3212",
        "llama3.1 BERT Score": {
            "BERTScore Precision": "0.3374",
            "BERTScore Recall": "0.4855",
            "BERTScore F1": "0.3981"
        },
        "llama3.1 Cosine_Similarity": 0.438356876373291,
        "Mistral Summary": "The patch changes the order in which the function processes the input string. In the vulnerable version, the variable `vsep` (which marks the location of the '&' character) is found before the location of the '=' character (stored in `ksep`). This can cause a buffer overflow if the '=' is not present in the input string. The patched version ensures that `ksep` is always defined before processing `vsep`, thus preventing the buffer overflow.",
        "Mistral CWE": "CWE-20 (Buffer Copy without Checking Size)",
        "Mistral CVE": "Not provided, as the CVE ID is based on the specific product and version. The format for a CVE ID is CVE-YYYY-NNNN where YYYY is the year of discovery and NNNN is an incremental number. This information should be obtained from the appropriate vulnerability database or coordination center.",
        "Mistral Cosine_Similarity": 0.3273329734802246,
        "Mistral BERT Score": {
            "BERTScore Precision": "0.4326",
            "BERTScore Recall": "0.4598",
            "BERTScore F1": "0.4458"
        },
        "Tokens Used": ""
    },
    {
        "codeLink": "https://github.com/torvalds/linux/commit/704620afc70cf47abb9d6a1a57f3825d2bca49cf",
        "CVE ID": "CVE-2018-20169",
        "CVE Details": "An issue was discovered in the Linux kernel before 4.19.9. The USB subsystem mishandles size checks during the reading of an extra descriptor, related to __usb_get_extra_descriptor in drivers/usb/core/usb.c.",
        "CWE ID": "CWE-400",
        "commit_message": "USB: check usb_get_extra_descriptor for proper size\n\nWhen reading an extra descriptor, we need to properly check the minimum\nand maximum size allowed, to prevent from invalid data being sent by a\ndevice.\n\nReported-by: Hui Peng <benquike@gmail.com>\nReported-by: Mathias Payer <mathias.payer@nebelwelt.net>\nCo-developed-by: Linus Torvalds <torvalds@linux-foundation.org>\nSigned-off-by: Hui Peng <benquike@gmail.com>\nSigned-off-by: Mathias Payer <mathias.payer@nebelwelt.net>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>\nCc: stable <stable@kernel.org>\nSigned-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>",
        "fixed_function": "static int usb_enumerate_device_otg(struct usb_device *udev)\n{\n\tint err = 0;\n\n#ifdef\tCONFIG_USB_OTG\n\t/*\n\t * OTG-aware devices on OTG-capable root hubs may be able to use SRP,\n\t * to wake us after we've powered off VBUS; and HNP, switching roles\n\t * \"host\" to \"peripheral\".  The OTG descriptor helps figure this out.\n\t */\n\tif (!udev->bus->is_b_host\n\t\t\t&& udev->config\n\t\t\t&& udev->parent == udev->bus->root_hub) {\n\t\tstruct usb_otg_descriptor\t*desc = NULL;\n\t\tstruct usb_bus\t\t\t*bus = udev->bus;\n\t\tunsigned\t\t\tport1 = udev->portnum;\n\n \t\t/* descriptor may appear anywhere in config */\n \t\terr = __usb_get_extra_descriptor(udev->rawdescriptors[0],\n \t\t\t\tle16_to_cpu(udev->config[0].desc.wTotalLength),\n\t\t\t\tUSB_DT_OTG, (void **) &desc, sizeof(*desc));\n \t\tif (err || !(desc->bmAttributes & USB_OTG_HNP))\n \t\t\treturn 0;\n \n\t\tdev_info(&udev->dev, \"Dual-Role OTG device on %sHNP port\\n\",\n\t\t\t\t\t(port1 == bus->otg_port) ? \"\" : \"non-\");\n\n\t\t/* enable HNP before suspend, it's simpler */\n\t\tif (port1 == bus->otg_port) {\n\t\t\tbus->b_hnp_enable = 1;\n\t\t\terr = usb_control_msg(udev,\n\t\t\t\tusb_sndctrlpipe(udev, 0),\n\t\t\t\tUSB_REQ_SET_FEATURE, 0,\n\t\t\t\tUSB_DEVICE_B_HNP_ENABLE,\n\t\t\t\t0, NULL, 0,\n\t\t\t\tUSB_CTRL_SET_TIMEOUT);\n\t\t\tif (err < 0) {\n\t\t\t\t/*\n\t\t\t\t * OTG MESSAGE: report errors here,\n\t\t\t\t * customize to match your product.\n\t\t\t\t */\n\t\t\t\tdev_err(&udev->dev, \"can't set HNP mode: %d\\n\",\n\t\t\t\t\t\t\t\t\terr);\n\t\t\t\tbus->b_hnp_enable = 0;\n\t\t\t}\n\t\t} else if (desc->bLength == sizeof\n\t\t\t\t(struct usb_otg_descriptor)) {\n\t\t\t/* Set a_alt_hnp_support for legacy otg device */\n\t\t\terr = usb_control_msg(udev,\n\t\t\t\tusb_sndctrlpipe(udev, 0),\n\t\t\t\tUSB_REQ_SET_FEATURE, 0,\n\t\t\t\tUSB_DEVICE_A_ALT_HNP_SUPPORT,\n\t\t\t\t0, NULL, 0,\n\t\t\t\tUSB_CTRL_SET_TIMEOUT);\n\t\t\tif (err < 0)\n\t\t\t\tdev_err(&udev->dev,\n\t\t\t\t\t\"set a_alt_hnp_support failed: %d\\n\",\n\t\t\t\t\terr);\n\t\t}\n\t}\n#endif\n\treturn err;\n}\n",
        "vul_function": "static int usb_enumerate_device_otg(struct usb_device *udev)\n{\n\tint err = 0;\n\n#ifdef\tCONFIG_USB_OTG\n\t/*\n\t * OTG-aware devices on OTG-capable root hubs may be able to use SRP,\n\t * to wake us after we've powered off VBUS; and HNP, switching roles\n\t * \"host\" to \"peripheral\".  The OTG descriptor helps figure this out.\n\t */\n\tif (!udev->bus->is_b_host\n\t\t\t&& udev->config\n\t\t\t&& udev->parent == udev->bus->root_hub) {\n\t\tstruct usb_otg_descriptor\t*desc = NULL;\n\t\tstruct usb_bus\t\t\t*bus = udev->bus;\n\t\tunsigned\t\t\tport1 = udev->portnum;\n\n \t\t/* descriptor may appear anywhere in config */\n \t\terr = __usb_get_extra_descriptor(udev->rawdescriptors[0],\n \t\t\t\tle16_to_cpu(udev->config[0].desc.wTotalLength),\n\t\t\t\tUSB_DT_OTG, (void **) &desc);\n \t\tif (err || !(desc->bmAttributes & USB_OTG_HNP))\n \t\t\treturn 0;\n \n\t\tdev_info(&udev->dev, \"Dual-Role OTG device on %sHNP port\\n\",\n\t\t\t\t\t(port1 == bus->otg_port) ? \"\" : \"non-\");\n\n\t\t/* enable HNP before suspend, it's simpler */\n\t\tif (port1 == bus->otg_port) {\n\t\t\tbus->b_hnp_enable = 1;\n\t\t\terr = usb_control_msg(udev,\n\t\t\t\tusb_sndctrlpipe(udev, 0),\n\t\t\t\tUSB_REQ_SET_FEATURE, 0,\n\t\t\t\tUSB_DEVICE_B_HNP_ENABLE,\n\t\t\t\t0, NULL, 0,\n\t\t\t\tUSB_CTRL_SET_TIMEOUT);\n\t\t\tif (err < 0) {\n\t\t\t\t/*\n\t\t\t\t * OTG MESSAGE: report errors here,\n\t\t\t\t * customize to match your product.\n\t\t\t\t */\n\t\t\t\tdev_err(&udev->dev, \"can't set HNP mode: %d\\n\",\n\t\t\t\t\t\t\t\t\terr);\n\t\t\t\tbus->b_hnp_enable = 0;\n\t\t\t}\n\t\t} else if (desc->bLength == sizeof\n\t\t\t\t(struct usb_otg_descriptor)) {\n\t\t\t/* Set a_alt_hnp_support for legacy otg device */\n\t\t\terr = usb_control_msg(udev,\n\t\t\t\tusb_sndctrlpipe(udev, 0),\n\t\t\t\tUSB_REQ_SET_FEATURE, 0,\n\t\t\t\tUSB_DEVICE_A_ALT_HNP_SUPPORT,\n\t\t\t\t0, NULL, 0,\n\t\t\t\tUSB_CTRL_SET_TIMEOUT);\n\t\t\tif (err < 0)\n\t\t\t\tdev_err(&udev->dev,\n\t\t\t\t\t\"set a_alt_hnp_support failed: %d\\n\",\n\t\t\t\t\terr);\n\t\t}\n\t}\n#endif\n\treturn err;\n}\n",
        "llama3.1 Summary": "The patch changes the __usb_get_extra_descriptor function call to properly check for the minimum and maximum size of the descriptor, preventing potential buffer overflow attacks. This was applied because a device could potentially send invalid data, causing the system to crash or be compromised. Fixed version of function: static int usb_enumerate_device_otg(struct usb_device *udev)\n{\n\tint err = 0;\n\n#ifdef\tCONFIG_USB_OTG\n\t/*\n\t * OTG-aware devices on OTG-capable root hubs may be able to use SRP,\n\t * to wake us after we've powered off VBUS; and HNP, switching roles\n\t * \"host\" to \"peripheral\".  The OTG descriptor helps figure this out.\n\t */\n\tif (!udev->bus->is_b_host\n\t\t\t&& udev->config\n\t\t\t&& udev->parent == udev->bus->root_hub) {\n\t\tstruct usb_otg_descriptor\t*desc = NULL;\n\t\tstruct usb_bus\t\t\t*bus = udev->bus;\n\t\tunsigned\t\t\tport1 = udev->portnum;\n\n \t\t/* descriptor may appear anywhere in config */\n \t\terr = __usb_get_extra_descriptor(udev->rawdescriptors[0],\n \t\t\t\tmin((int)le16_to_cpu(udev->config[0].desc.wTotalLength), 512),\n\t\t\t\tmax((int)le16_to_cpu(udev->config[0].desc.wTotalLength), 2048),\n\t\t\t\tUSB_DT_OTG, (void **) &desc, sizeof(*desc));\n \t\tif (err || !(desc->bmAttributes & USB_OTG_HNP))\n \t\t\treturn 0;\n \n\t\tdev_info(&udev->dev, \"Dual-Role OTG device on %sHNP port\\n\",\n\t\t\t\t\t(port1 == bus->otg_port) ? \"\" : \"non-\");\n\n\t\t/* enable HNP before suspend, it's simpler */\n\t\tif (port1 == bus->otg_port) {\n\t\t\tbus->b_hnp_enable = 1;\n\t\t\terr = usb_control_msg(udev,\n\t\t\t\tusb_sndctrlpipe(udev, 0),\n\t\t\t\tUSB_REQ_SET_FEATURE, 0,\n\t\t\t\tUSB_DEVICE_B_HNP_ENABLE,\n\t\t\t\t0, NULL, 0,\n\t\t\t\tUSB_CTRL_SET_TIMEOUT);\n\t\t\tif (err < 0) {\n\t\t\t\t/*\n\t\t\t\t * OTG MESSAGE: report errors here,\n\t\t\t\t * customize to match your product.\n\t\t\t\t */\n\t\t\t\tdev_err(&udev->dev, \"can't set HNP mode: %d\\n\",\n\t\t\t\t\t\t\t\t\terr);\n\t\t\t\tbus->b_hnp_enable = 0;\n\t\t\t}\n\t\t} else if (desc->bLength == sizeof\n\t\t\t\t(struct usb_otg_descriptor)) {\n\t\t\t/* Set a_alt_hnp_support for legacy otg device */\n\t\t\terr = usb_control_msg(udev,\n\t\t\t\tusb_sndctrlpipe(udev, 0),\n\t\t\t\tUSB_REQ_SET_FEATURE, 0,\n\t\t\t\tUSB_DEVICE_A_ALT_HNP_SUPPORT,\n\t\t\t\t0, NULL, 0,\n\t\t\t\tUSB_CTRL_SET_TIMEOUT);\n\t\t\tif (err < 0)\n\t\t\t\tdev_err(&udev->dev,\n\t\t\t\t\t\"set a_alt_hnp_support failed: %d\\n\",\n\t\t\t\t\terr);\n\t\t}\n\t}\n#endif\n\treturn err;\n}",
        "llama3.1 CWE": "CWE-129",
        "llama3.1 CVE": "CVE-2017-7306",
        "llama3.1 BERT Score": {
            "BERTScore Precision": "0.3086",
            "BERTScore Recall": "0.4532",
            "BERTScore F1": "0.3672"
        },
        "llama3.1 Cosine_Similarity": 0.6049792170524597,
        "Mistral Summary": null,
        "Mistral CWE": "CWE-189 (Buffer Access with Insufficient Checks)\n   CVE ID: To be determined based on the actual version and release of the kernel\n\nThe patch addresses a potential buffer overflow issue by ensuring that the size of the extra descriptor read from the device is within acceptable limits. This issue was reported by Hui Peng, Mathias Payer, and Linus Torvalds, with Greg Kroah-Hartman also signing off on it. The change has been made to prevent invalid data being sent by a malicious device, which could potentially lead to arbitrary code execution or other security vulnerabilities.",
        "Mistral CVE": null,
        "Mistral Cosine_Similarity": 0.1056901216506958,
        "Mistral BERT Score": {
            "BERTScore Precision": "0.3377",
            "BERTScore Recall": "0.2284",
            "BERTScore F1": "0.2725"
        },
        "Tokens Used": ""
    },
    {
        "codeLink": "https://github.com/torvalds/linux/commit/704620afc70cf47abb9d6a1a57f3825d2bca49cf",
        "CVE ID": "CVE-2018-20169",
        "CVE Details": "An issue was discovered in the Linux kernel before 4.19.9. The USB subsystem mishandles size checks during the reading of an extra descriptor, related to __usb_get_extra_descriptor in drivers/usb/core/usb.c.",
        "CWE ID": "CWE-400",
        "commit_message": "USB: check usb_get_extra_descriptor for proper size\n\nWhen reading an extra descriptor, we need to properly check the minimum\nand maximum size allowed, to prevent from invalid data being sent by a\ndevice.\n\nReported-by: Hui Peng <benquike@gmail.com>\nReported-by: Mathias Payer <mathias.payer@nebelwelt.net>\nCo-developed-by: Linus Torvalds <torvalds@linux-foundation.org>\nSigned-off-by: Hui Peng <benquike@gmail.com>\nSigned-off-by: Mathias Payer <mathias.payer@nebelwelt.net>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>\nCc: stable <stable@kernel.org>\nSigned-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>",
        "fixed_function": "static int hwahc_security_create(struct hwahc *hwahc)\n{\n\tint result;\n\tstruct wusbhc *wusbhc = &hwahc->wusbhc;\n\tstruct usb_device *usb_dev = hwahc->wa.usb_dev;\n\tstruct device *dev = &usb_dev->dev;\n\tstruct usb_security_descriptor *secd;\n\tstruct usb_encryption_descriptor *etd;\n\tvoid *itr, *top;\n\tsize_t itr_size, needed, bytes;\n\tu8 index;\n\tchar buf[64];\n\n\t/* Find the host's security descriptors in the config descr bundle */\n\tindex = (usb_dev->actconfig - usb_dev->config) /\n\t\tsizeof(usb_dev->config[0]);\n\titr = usb_dev->rawdescriptors[index];\n\titr_size = le16_to_cpu(usb_dev->actconfig->desc.wTotalLength);\n \ttop = itr + itr_size;\n \tresult = __usb_get_extra_descriptor(usb_dev->rawdescriptors[index],\n \t\t\tle16_to_cpu(usb_dev->actconfig->desc.wTotalLength),\n\t\t\tUSB_DT_SECURITY, (void **) &secd, sizeof(*secd));\n \tif (result == -1) {\n \t\tdev_warn(dev, \"BUG? WUSB host has no security descriptors\\n\");\n \t\treturn 0;\n\t}\n\tneeded = sizeof(*secd);\n\tif (top - (void *)secd < needed) {\n\t\tdev_err(dev, \"BUG? Not enough data to process security \"\n\t\t\t\"descriptor header (%zu bytes left vs %zu needed)\\n\",\n\t\t\ttop - (void *) secd, needed);\n\t\treturn 0;\n\t}\n\tneeded = le16_to_cpu(secd->wTotalLength);\n\tif (top - (void *)secd < needed) {\n\t\tdev_err(dev, \"BUG? Not enough data to process security \"\n\t\t\t\"descriptors (%zu bytes left vs %zu needed)\\n\",\n\t\t\ttop - (void *) secd, needed);\n\t\treturn 0;\n\t}\n\t/* Walk over the sec descriptors and store CCM1's on wusbhc */\n\titr = (void *) secd + sizeof(*secd);\n\ttop = (void *) secd + le16_to_cpu(secd->wTotalLength);\n\tindex = 0;\n\tbytes = 0;\n\twhile (itr < top) {\n\t\tetd = itr;\n\t\tif (top - itr < sizeof(*etd)) {\n\t\t\tdev_err(dev, \"BUG: bad host security descriptor; \"\n\t\t\t\t\"not enough data (%zu vs %zu left)\\n\",\n\t\t\t\ttop - itr, sizeof(*etd));\n\t\t\tbreak;\n\t\t}\n\t\tif (etd->bLength < sizeof(*etd)) {\n\t\t\tdev_err(dev, \"BUG: bad host encryption descriptor; \"\n\t\t\t\t\"descriptor is too short \"\n\t\t\t\t\"(%zu vs %zu needed)\\n\",\n\t\t\t\t(size_t)etd->bLength, sizeof(*etd));\n\t\t\tbreak;\n\t\t}\n\t\titr += etd->bLength;\n\t\tbytes += snprintf(buf + bytes, sizeof(buf) - bytes,\n\t\t\t\t  \"%s (0x%02x) \",\n\t\t\t\t  wusb_et_name(etd->bEncryptionType),\n\t\t\t\t  etd->bEncryptionValue);\n\t\twusbhc->ccm1_etd = etd;\n\t}\n\tdev_info(dev, \"supported encryption types: %s\\n\", buf);\n\tif (wusbhc->ccm1_etd == NULL) {\n\t\tdev_err(dev, \"E: host doesn't support CCM-1 crypto\\n\");\n\t\treturn 0;\n\t}\n\t/* Pretty print what we support */\n\treturn 0;\n}\n",
        "vul_function": "static int hwahc_security_create(struct hwahc *hwahc)\n{\n\tint result;\n\tstruct wusbhc *wusbhc = &hwahc->wusbhc;\n\tstruct usb_device *usb_dev = hwahc->wa.usb_dev;\n\tstruct device *dev = &usb_dev->dev;\n\tstruct usb_security_descriptor *secd;\n\tstruct usb_encryption_descriptor *etd;\n\tvoid *itr, *top;\n\tsize_t itr_size, needed, bytes;\n\tu8 index;\n\tchar buf[64];\n\n\t/* Find the host's security descriptors in the config descr bundle */\n\tindex = (usb_dev->actconfig - usb_dev->config) /\n\t\tsizeof(usb_dev->config[0]);\n\titr = usb_dev->rawdescriptors[index];\n\titr_size = le16_to_cpu(usb_dev->actconfig->desc.wTotalLength);\n \ttop = itr + itr_size;\n \tresult = __usb_get_extra_descriptor(usb_dev->rawdescriptors[index],\n \t\t\tle16_to_cpu(usb_dev->actconfig->desc.wTotalLength),\n\t\t\tUSB_DT_SECURITY, (void **) &secd);\n \tif (result == -1) {\n \t\tdev_warn(dev, \"BUG? WUSB host has no security descriptors\\n\");\n \t\treturn 0;\n\t}\n\tneeded = sizeof(*secd);\n\tif (top - (void *)secd < needed) {\n\t\tdev_err(dev, \"BUG? Not enough data to process security \"\n\t\t\t\"descriptor header (%zu bytes left vs %zu needed)\\n\",\n\t\t\ttop - (void *) secd, needed);\n\t\treturn 0;\n\t}\n\tneeded = le16_to_cpu(secd->wTotalLength);\n\tif (top - (void *)secd < needed) {\n\t\tdev_err(dev, \"BUG? Not enough data to process security \"\n\t\t\t\"descriptors (%zu bytes left vs %zu needed)\\n\",\n\t\t\ttop - (void *) secd, needed);\n\t\treturn 0;\n\t}\n\t/* Walk over the sec descriptors and store CCM1's on wusbhc */\n\titr = (void *) secd + sizeof(*secd);\n\ttop = (void *) secd + le16_to_cpu(secd->wTotalLength);\n\tindex = 0;\n\tbytes = 0;\n\twhile (itr < top) {\n\t\tetd = itr;\n\t\tif (top - itr < sizeof(*etd)) {\n\t\t\tdev_err(dev, \"BUG: bad host security descriptor; \"\n\t\t\t\t\"not enough data (%zu vs %zu left)\\n\",\n\t\t\t\ttop - itr, sizeof(*etd));\n\t\t\tbreak;\n\t\t}\n\t\tif (etd->bLength < sizeof(*etd)) {\n\t\t\tdev_err(dev, \"BUG: bad host encryption descriptor; \"\n\t\t\t\t\"descriptor is too short \"\n\t\t\t\t\"(%zu vs %zu needed)\\n\",\n\t\t\t\t(size_t)etd->bLength, sizeof(*etd));\n\t\t\tbreak;\n\t\t}\n\t\titr += etd->bLength;\n\t\tbytes += snprintf(buf + bytes, sizeof(buf) - bytes,\n\t\t\t\t  \"%s (0x%02x) \",\n\t\t\t\t  wusb_et_name(etd->bEncryptionType),\n\t\t\t\t  etd->bEncryptionValue);\n\t\twusbhc->ccm1_etd = etd;\n\t}\n\tdev_info(dev, \"supported encryption types: %s\\n\", buf);\n\tif (wusbhc->ccm1_etd == NULL) {\n\t\tdev_err(dev, \"E: host doesn't support CCM-1 crypto\\n\");\n\t\treturn 0;\n\t}\n\t/* Pretty print what we support */\n\treturn 0;\n}\n",
        "llama3.1 Summary": "The patch changes the code to properly check the size of the extra descriptor when reading it from a device, preventing potential buffer overflows. This change was applied to prevent invalid data being sent by devices and to ensure the security descriptors are processed correctly. Fixed version of function: static int hwahc_security_create(struct hwahc *hwahc) { ... }",
        "llama3.1 CWE": "CWE-119",
        "llama3.1 CVE": "CVE-2018-10897",
        "llama3.1 BERT Score": {
            "BERTScore Precision": "0.5763",
            "BERTScore Recall": "0.5983",
            "BERTScore F1": "0.5871"
        },
        "llama3.1 Cosine_Similarity": 0.37746042013168335,
        "Mistral Summary": null,
        "Mistral CWE": null,
        "Mistral CVE": null,
        "Mistral Cosine_Similarity": 0.1056901216506958,
        "Mistral BERT Score": {
            "BERTScore Precision": "0.3377",
            "BERTScore Recall": "0.2284",
            "BERTScore F1": "0.2725"
        },
        "Tokens Used": ""
    },
    {
        "codeLink": "https://github.com/uclouvain/openjpeg/pull/1185/commits/cbe7384016083eac16078b359acd7a842253d503",
        "CVE ID": "CVE-2019-12973",
        "CVE Details": "In OpenJPEG 2.3.1, there is excessive iteration in the opj_t1_encode_cblks function of openjp2/t1.c. Remote attackers could leverage this vulnerability to cause a denial of service via a crafted bmp file. This issue is similar to CVE-2018-6616.",
        "CWE ID": "CWE-400",
        "commit_message": "convertbmp: detect invalid file dimensions early\n\nwidth/length dimensions read from bmp headers are not necessarily\nvalid. For instance they may have been maliciously set to very large\nvalues with the intention to cause DoS (large memory allocation, stack\noverflow). In these cases we want to detect the invalid size as early\nas possible.\n\nThis commit introduces a counter which verifies that the number of\nwritten bytes corresponds to the advertized width/length.\n\nSee commit 8ee335227bbc for details.\n\nSigned-off-by: Young Xiao <YangX92@hotmail.com>",
        "fixed_function": " static OPJ_BOOL bmp_read_rle4_data(FILE* IN, OPJ_UINT8* pData,\n                                    OPJ_UINT32 stride, OPJ_UINT32 width, OPJ_UINT32 height)\n {\n    OPJ_UINT32 x, y, written;\n     OPJ_UINT8 *pix;\n     const OPJ_UINT8 *beyond;\n \n     beyond = pData + stride * height;\n     pix = pData;\n    x = y = written = 0U;\n     while (y < height) {\n         int c = getc(IN);\n         if (c == EOF) {\n            break;\n        }\n\n        if (c) { /* encoded mode */\n            int j;\n            OPJ_UINT8 c1 = (OPJ_UINT8)getc(IN);\n\n             for (j = 0; (j < c) && (x < width) &&\n                     ((OPJ_SIZE_T)pix < (OPJ_SIZE_T)beyond); j++, x++, pix++) {\n                 *pix = (OPJ_UINT8)((j & 1) ? (c1 & 0x0fU) : ((c1 >> 4) & 0x0fU));\n                written++;\n             }\n         } else { /* absolute mode */\n             c = getc(IN);\n            if (c == EOF) {\n                break;\n            }\n\n            if (c == 0x00) { /* EOL */\n                x = 0;\n                y++;\n                pix = pData + y * stride;\n            } else if (c == 0x01) { /* EOP */\n                break;\n            } else if (c == 0x02) { /* MOVE by dxdy */\n                c = getc(IN);\n                x += (OPJ_UINT32)c;\n                c = getc(IN);\n                y += (OPJ_UINT32)c;\n                pix = pData + y * stride + x;\n            } else { /* 03 .. 255 : absolute mode */\n                int j;\n                OPJ_UINT8 c1 = 0U;\n\n                for (j = 0; (j < c) && (x < width) &&\n                        ((OPJ_SIZE_T)pix < (OPJ_SIZE_T)beyond); j++, x++, pix++) {\n                    if ((j & 1) == 0) {\n                         c1 = (OPJ_UINT8)getc(IN);\n                     }\n                     *pix = (OPJ_UINT8)((j & 1) ? (c1 & 0x0fU) : ((c1 >> 4) & 0x0fU));\n                    written++;\n                 }\n                 if (((c & 3) == 1) || ((c & 3) == 2)) { /* skip padding byte */\n                     getc(IN);\n                 }\n             }\n         }\n     }  /* while(y < height) */\n    if (written != width * height) {\n        fprintf(stderr, \"warning, image's actual size does not match advertized one\\n\");\n        return OPJ_FALSE;\n    }\n     return OPJ_TRUE;\n }\n",
        "vul_function": " static OPJ_BOOL bmp_read_rle4_data(FILE* IN, OPJ_UINT8* pData,\n                                    OPJ_UINT32 stride, OPJ_UINT32 width, OPJ_UINT32 height)\n {\n    OPJ_UINT32 x, y;\n     OPJ_UINT8 *pix;\n     const OPJ_UINT8 *beyond;\n \n     beyond = pData + stride * height;\n     pix = pData;\n    x = y = 0U;\n     while (y < height) {\n         int c = getc(IN);\n         if (c == EOF) {\n            break;\n        }\n\n        if (c) { /* encoded mode */\n            int j;\n            OPJ_UINT8 c1 = (OPJ_UINT8)getc(IN);\n\n             for (j = 0; (j < c) && (x < width) &&\n                     ((OPJ_SIZE_T)pix < (OPJ_SIZE_T)beyond); j++, x++, pix++) {\n                 *pix = (OPJ_UINT8)((j & 1) ? (c1 & 0x0fU) : ((c1 >> 4) & 0x0fU));\n             }\n         } else { /* absolute mode */\n             c = getc(IN);\n            if (c == EOF) {\n                break;\n            }\n\n            if (c == 0x00) { /* EOL */\n                x = 0;\n                y++;\n                pix = pData + y * stride;\n            } else if (c == 0x01) { /* EOP */\n                break;\n            } else if (c == 0x02) { /* MOVE by dxdy */\n                c = getc(IN);\n                x += (OPJ_UINT32)c;\n                c = getc(IN);\n                y += (OPJ_UINT32)c;\n                pix = pData + y * stride + x;\n            } else { /* 03 .. 255 : absolute mode */\n                int j;\n                OPJ_UINT8 c1 = 0U;\n\n                for (j = 0; (j < c) && (x < width) &&\n                        ((OPJ_SIZE_T)pix < (OPJ_SIZE_T)beyond); j++, x++, pix++) {\n                    if ((j & 1) == 0) {\n                         c1 = (OPJ_UINT8)getc(IN);\n                     }\n                     *pix = (OPJ_UINT8)((j & 1) ? (c1 & 0x0fU) : ((c1 >> 4) & 0x0fU));\n                 }\n                 if (((c & 3) == 1) || ((c & 3) == 2)) { /* skip padding byte */\n                     getc(IN);\n                 }\n             }\n         }\n     }  /* while(y < height) */\n     return OPJ_TRUE;\n }\n",
        "llama3.1 Summary": "The patch introduces a counter to verify that the number of written bytes corresponds to the advertized width/length, preventing DoS attacks caused by large memory allocation or stack overflow. This change detects invalid file dimensions early and prevents potential security vulnerabilities.\n\nFixed version of function: \nstatic OPJ_BOOL bmp_read_rle4_data(FILE* IN, OPJ_UINT8* pData,\n                                    OPJ_UINT32 stride, OPJ_UINT32 width, OPJ_UINT32 height)\n {\n    OPJ_UINT32 x, y, written;\n     OPJ_UINT8 *pix;\n     const OPJ_UINT8 *beyond;\n\n     beyond = pData + stride * height;\n     pix = pData;\n    x = y = written = 0U;\n     while (y < height) {\n         int c = getc(IN);\n         if (c == EOF) {\n            break;\n        }\n\n        if (c) { /* encoded mode */\n            int j;\n            OPJ_UINT8 c1 = (OPJ_UINT8)getc(IN);\n\n             for (j = 0; (j < c) && (x < width) &&\n                     ((OPJ_SIZE_T)pix < (OPJ_SIZE_T)beyond); j++, x++, pix++) {\n                 *pix = (OPJ_UINT8)((j & 1) ? (c1 & 0x0fU) : ((c1 >> 4) & 0x0fU));\n                written++;\n             }\n         } else { /* absolute mode */\n             c = getc(IN);\n            if (c == EOF) {\n                break;\n            }\n\n            if (c == 0x00) { /* EOL */\n                x = 0;\n                y++;\n                pix = pData + y * stride;\n            } else if (c == 0x01) { /* EOP */\n                break;\n            } else if (c == 0x02) { /* MOVE by dxdy */\n                c = getc(IN);\n                x += (OPJ_UINT32)c;\n                c = getc(IN);\n                y += (OPJ_UINT32)c;\n                pix = pData + y * stride + x;\n            } else { /* 03 .. 255 : absolute mode */\n                int j;\n                OPJ_UINT8 c1 = 0U;\n\n                for (j = 0; (j < c) && (x < width) &&\n                        ((OPJ_SIZE_T)pix < (OPJ_SIZE_T)beyond); j++, x++, pix++) {\n                    if ((j & 1) == 0) {\n                         c1 = (OPJ_UINT8)getc(IN);\n                     }\n                     *pix = (OPJ_UINT8)((j & 1) ? (c1 & 0x0fU) : ((c1 >> 4) & 0x0fU));\n                 }\n                 if (((c & 3) == 1) || ((c & 3) == 2)) { /* skip padding byte */\n                     getc(IN);\n                 }\n             }\n         }\n     }  /* while(y < height) */\n    return (written == width * stride) ? OPJ_TRUE : OPJ_FALSE;\n}",
        "llama3.1 CWE": "CWE-122",
        "llama3.1 CVE": "CVE-2017-14435",
        "llama3.1 BERT Score": {
            "BERTScore Precision": "0.2730",
            "BERTScore Recall": "0.4098",
            "BERTScore F1": "0.3277"
        },
        "llama3.1 Cosine_Similarity": 0.411321222782135,
        "Mistral Summary": "The patch changes the function to validate the number of written bytes against the advertised width and height before processing large input data, preventing potential stack overflow or Denial of Service (DoS) attacks caused by maliciously set large dimensions in BMP files.",
        "Mistral CWE": "CWE-190 (Buffer Overflow)",
        "Mistral CVE": "Not provided in the commit message, as it would be dynamically assigned by a CVE Numbering Authority if the vulnerability is confirmed and disclosed publicly.",
        "Mistral Cosine_Similarity": 0.35644322633743286,
        "Mistral BERT Score": {
            "BERTScore Precision": "0.6241",
            "BERTScore Recall": "0.5526",
            "BERTScore F1": "0.5862"
        },
        "Tokens Used": ""
    },
    {
        "codeLink": "https://github.com/torvalds/linux/commit/fac8e0f579695a3ecbc4d3cac369139d7f819971",
        "CVE ID": "CVE-2016-8666",
        "CVE Details": "The IP stack in the Linux kernel before 4.6 allows remote attackers to cause a denial of service (stack consumption and panic) or possibly have unspecified other impact by triggering use of the GRO path for packets with tunnel stacking, as demonstrated by interleaved IPv4 headers and GRE headers, a related issue to CVE-2016-7039.",
        "CWE ID": "CWE-400",
        "commit_message": "tunnels: Don't apply GRO to multiple layers of encapsulation.\n\nWhen drivers express support for TSO of encapsulated packets, they\nonly mean that they can do it for one layer of encapsulation.\nSupporting additional levels would mean updating, at a minimum,\nmore IP length fields and they are unaware of this.\n\nNo encapsulation device expresses support for handling offloaded\nencapsulated packets, so we won't generate these types of frames\nin the transmit path. However, GRO doesn't have a check for\nmultiple levels of encapsulation and will attempt to build them.\n\nUDP tunnel GRO actually does prevent this situation but it only\nhandles multiple UDP tunnels stacked on top of each other. This\ngeneralizes that solution to prevent any kind of tunnel stacking\nthat would cause problems.\n\nFixes: bf5a755f (\"net-gre-gro: Add GRE support to the GRO stack\")\nSigned-off-by: Jesse Gross <jesse@kernel.org>\nSigned-off-by: David S. Miller <davem@davemloft.net>",
        "fixed_function": "static enum gro_result dev_gro_receive(struct napi_struct *napi, struct sk_buff *skb)\n{\n\tstruct sk_buff **pp = NULL;\n\tstruct packet_offload *ptype;\n\t__be16 type = skb->protocol;\n\tstruct list_head *head = &offload_base;\n\tint same_flow;\n\tenum gro_result ret;\n\tint grow;\n\n\tif (!(skb->dev->features & NETIF_F_GRO))\n\t\tgoto normal;\n\n\tif (skb_is_gso(skb) || skb_has_frag_list(skb) || skb->csum_bad)\n\t\tgoto normal;\n\n\tgro_list_prepare(napi, skb);\n\n\trcu_read_lock();\n\tlist_for_each_entry_rcu(ptype, head, list) {\n\t\tif (ptype->type != type || !ptype->callbacks.gro_receive)\n\t\t\tcontinue;\n\n\t\tskb_set_network_header(skb, skb_gro_offset(skb));\n\t\tskb_reset_mac_len(skb);\n \t\tNAPI_GRO_CB(skb)->same_flow = 0;\n \t\tNAPI_GRO_CB(skb)->flush = 0;\n \t\tNAPI_GRO_CB(skb)->free = 0;\n\t\tNAPI_GRO_CB(skb)->encap_mark = 0;\n \t\tNAPI_GRO_CB(skb)->gro_remcsum_start = 0;\n \n \t\t/* Setup for GRO checksum validation */\n\t\tswitch (skb->ip_summed) {\n\t\tcase CHECKSUM_COMPLETE:\n\t\t\tNAPI_GRO_CB(skb)->csum = skb->csum;\n\t\t\tNAPI_GRO_CB(skb)->csum_valid = 1;\n\t\t\tNAPI_GRO_CB(skb)->csum_cnt = 0;\n\t\t\tbreak;\n\t\tcase CHECKSUM_UNNECESSARY:\n\t\t\tNAPI_GRO_CB(skb)->csum_cnt = skb->csum_level + 1;\n\t\t\tNAPI_GRO_CB(skb)->csum_valid = 0;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tNAPI_GRO_CB(skb)->csum_cnt = 0;\n\t\t\tNAPI_GRO_CB(skb)->csum_valid = 0;\n\t\t}\n\n\t\tpp = ptype->callbacks.gro_receive(&napi->gro_list, skb);\n\t\tbreak;\n\t}\n\trcu_read_unlock();\n\n\tif (&ptype->list == head)\n\t\tgoto normal;\n\n\tsame_flow = NAPI_GRO_CB(skb)->same_flow;\n\tret = NAPI_GRO_CB(skb)->free ? GRO_MERGED_FREE : GRO_MERGED;\n\n\tif (pp) {\n\t\tstruct sk_buff *nskb = *pp;\n\n\t\t*pp = nskb->next;\n\t\tnskb->next = NULL;\n\t\tnapi_gro_complete(nskb);\n\t\tnapi->gro_count--;\n\t}\n\n\tif (same_flow)\n\t\tgoto ok;\n\n\tif (NAPI_GRO_CB(skb)->flush)\n\t\tgoto normal;\n\n\tif (unlikely(napi->gro_count >= MAX_GRO_SKBS)) {\n\t\tstruct sk_buff *nskb = napi->gro_list;\n\n\t\t/* locate the end of the list to select the 'oldest' flow */\n\t\twhile (nskb->next) {\n\t\t\tpp = &nskb->next;\n\t\t\tnskb = *pp;\n\t\t}\n\t\t*pp = NULL;\n\t\tnskb->next = NULL;\n\t\tnapi_gro_complete(nskb);\n\t} else {\n\t\tnapi->gro_count++;\n\t}\n\tNAPI_GRO_CB(skb)->count = 1;\n\tNAPI_GRO_CB(skb)->age = jiffies;\n\tNAPI_GRO_CB(skb)->last = skb;\n\tskb_shinfo(skb)->gso_size = skb_gro_len(skb);\n\tskb->next = napi->gro_list;\n\tnapi->gro_list = skb;\n\tret = GRO_HELD;\n\npull:\n\tgrow = skb_gro_offset(skb) - skb_headlen(skb);\n\tif (grow > 0)\n\t\tgro_pull_from_frag0(skb, grow);\nok:\n\treturn ret;\n\nnormal:\n\tret = GRO_NORMAL;\n\tgoto pull;\n}\n",
        "vul_function": "static enum gro_result dev_gro_receive(struct napi_struct *napi, struct sk_buff *skb)\n{\n\tstruct sk_buff **pp = NULL;\n\tstruct packet_offload *ptype;\n\t__be16 type = skb->protocol;\n\tstruct list_head *head = &offload_base;\n\tint same_flow;\n\tenum gro_result ret;\n\tint grow;\n\n\tif (!(skb->dev->features & NETIF_F_GRO))\n\t\tgoto normal;\n\n\tif (skb_is_gso(skb) || skb_has_frag_list(skb) || skb->csum_bad)\n\t\tgoto normal;\n\n\tgro_list_prepare(napi, skb);\n\n\trcu_read_lock();\n\tlist_for_each_entry_rcu(ptype, head, list) {\n\t\tif (ptype->type != type || !ptype->callbacks.gro_receive)\n\t\t\tcontinue;\n\n\t\tskb_set_network_header(skb, skb_gro_offset(skb));\n\t\tskb_reset_mac_len(skb);\n \t\tNAPI_GRO_CB(skb)->same_flow = 0;\n \t\tNAPI_GRO_CB(skb)->flush = 0;\n \t\tNAPI_GRO_CB(skb)->free = 0;\n\t\tNAPI_GRO_CB(skb)->udp_mark = 0;\n \t\tNAPI_GRO_CB(skb)->gro_remcsum_start = 0;\n \n \t\t/* Setup for GRO checksum validation */\n\t\tswitch (skb->ip_summed) {\n\t\tcase CHECKSUM_COMPLETE:\n\t\t\tNAPI_GRO_CB(skb)->csum = skb->csum;\n\t\t\tNAPI_GRO_CB(skb)->csum_valid = 1;\n\t\t\tNAPI_GRO_CB(skb)->csum_cnt = 0;\n\t\t\tbreak;\n\t\tcase CHECKSUM_UNNECESSARY:\n\t\t\tNAPI_GRO_CB(skb)->csum_cnt = skb->csum_level + 1;\n\t\t\tNAPI_GRO_CB(skb)->csum_valid = 0;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tNAPI_GRO_CB(skb)->csum_cnt = 0;\n\t\t\tNAPI_GRO_CB(skb)->csum_valid = 0;\n\t\t}\n\n\t\tpp = ptype->callbacks.gro_receive(&napi->gro_list, skb);\n\t\tbreak;\n\t}\n\trcu_read_unlock();\n\n\tif (&ptype->list == head)\n\t\tgoto normal;\n\n\tsame_flow = NAPI_GRO_CB(skb)->same_flow;\n\tret = NAPI_GRO_CB(skb)->free ? GRO_MERGED_FREE : GRO_MERGED;\n\n\tif (pp) {\n\t\tstruct sk_buff *nskb = *pp;\n\n\t\t*pp = nskb->next;\n\t\tnskb->next = NULL;\n\t\tnapi_gro_complete(nskb);\n\t\tnapi->gro_count--;\n\t}\n\n\tif (same_flow)\n\t\tgoto ok;\n\n\tif (NAPI_GRO_CB(skb)->flush)\n\t\tgoto normal;\n\n\tif (unlikely(napi->gro_count >= MAX_GRO_SKBS)) {\n\t\tstruct sk_buff *nskb = napi->gro_list;\n\n\t\t/* locate the end of the list to select the 'oldest' flow */\n\t\twhile (nskb->next) {\n\t\t\tpp = &nskb->next;\n\t\t\tnskb = *pp;\n\t\t}\n\t\t*pp = NULL;\n\t\tnskb->next = NULL;\n\t\tnapi_gro_complete(nskb);\n\t} else {\n\t\tnapi->gro_count++;\n\t}\n\tNAPI_GRO_CB(skb)->count = 1;\n\tNAPI_GRO_CB(skb)->age = jiffies;\n\tNAPI_GRO_CB(skb)->last = skb;\n\tskb_shinfo(skb)->gso_size = skb_gro_len(skb);\n\tskb->next = napi->gro_list;\n\tnapi->gro_list = skb;\n\tret = GRO_HELD;\n\npull:\n\tgrow = skb_gro_offset(skb) - skb_headlen(skb);\n\tif (grow > 0)\n\t\tgro_pull_from_frag0(skb, grow);\nok:\n\treturn ret;\n\nnormal:\n\tret = GRO_NORMAL;\n\tgoto pull;\n}\n",
        "llama3.1 Summary": "The patch prevents the GRO (Generic Receive Offload) mechanism from attempting to build packets with multiple levels of encapsulation, which could lead to incorrect packet handling. This is achieved by adding a check for multiple layers of encapsulation in the GRO code.",
        "llama3.1 CWE": "CWE-330",
        "llama3.1 CVE": "CVE-2014-3686",
        "llama3.1 BERT Score": {
            "BERTScore Precision": "0.6055",
            "BERTScore Recall": "0.5772",
            "BERTScore F1": "0.5910"
        },
        "llama3.1 Cosine_Similarity": 0.5353283286094666,
        "Mistral Summary": null,
        "Mistral CWE": null,
        "Mistral CVE": null,
        "Mistral Cosine_Similarity": 0.056175053119659424,
        "Mistral BERT Score": {
            "BERTScore Precision": "0.3203",
            "BERTScore Recall": "0.2521",
            "BERTScore F1": "0.2821"
        },
        "Tokens Used": ""
    },
    {
        "num": 5,
        "codeLink": "https://github.com/torvalds/linux/commit/d29216842a85c7970c536108e093963f02714498",
        "CVE ID": "CVE-2016-6213",
        "CVE Details": "fs/namespace.c in the Linux kernel before 4.9 does not restrict how many mounts may exist in a mount namespace, which allows local users to cause a denial of service (memory consumption and deadlock) via MS_BIND mount system calls, as demonstrated by a loop that triggers exponential growth in the number of mounts.",
        "CWE ID": "CWE-400",
        "commit_message": "mnt: Add a per mount namespace limit on the number of mounts\n\nCAI Qian <caiqian@redhat.com> pointed out that the semantics\nof shared subtrees make it possible to create an exponentially\nincreasing number of mounts in a mount namespace.\n\n    mkdir /tmp/1 /tmp/2\n    mount --make-rshared /\n    for i in $(seq 1 20) ; do mount --bind /tmp/1 /tmp/2 ; done\n\nWill create create 2^20 or 1048576 mounts, which is a practical problem\nas some people have managed to hit this by accident.\n\nAs such CVE-2016-6213 was assigned.\n\nIan Kent <raven@themaw.net> described the situation for autofs users\nas follows:\n\n> The number of mounts for direct mount maps is usually not very large because of\n> the way they are implemented, large direct mount maps can have performance\n> problems. There can be anywhere from a few (likely case a few hundred) to less\n> than 10000, plus mounts that have been triggered and not yet expired.\n>\n> Indirect mounts have one autofs mount at the root plus the number of mounts that\n> have been triggered and not yet expired.\n>\n> The number of autofs indirect map entries can range from a few to the common\n> case of several thousand and in rare cases up to between 30000 and 50000. I've\n> not heard of people with maps larger than 50000 entries.\n>\n> The larger the number of map entries the greater the possibility for a large\n> number of active mounts so it's not hard to expect cases of a 1000 or somewhat\n> more active mounts.\n\nSo I am setting the default number of mounts allowed per mount\nnamespace at 100,000.  This is more than enough for any use case I\nknow of, but small enough to quickly stop an exponential increase\nin mounts.  Which should be perfect to catch misconfigurations and\nmalfunctioning programs.\n\nFor anyone who needs a higher limit this can be changed by writing\nto the new /proc/sys/fs/mount-max sysctl.\n\nTested-by: CAI Qian <caiqian@redhat.com>\nSigned-off-by: \"Eric W. Biederman\" <ebiederm@xmission.com>",
        "fixed_function": "static void commit_tree(struct mount *mnt, struct mount *shadows)\n{\n\tstruct mount *parent = mnt->mnt_parent;\n\tstruct mount *m;\n\tLIST_HEAD(head);\n\tstruct mnt_namespace *n = parent->mnt_ns;\n\n\tBUG_ON(parent == mnt);\n\n\tlist_add_tail(&head, &mnt->mnt_list);\n\tlist_for_each_entry(m, &head, mnt_list)\n\t\tm->mnt_ns = n;\n \n \tlist_splice(&head, n->list.prev);\n \n\tn->mounts += n->pending_mounts;\n\tn->pending_mounts = 0;\n\n \tattach_shadowed(mnt, parent, shadows);\n \ttouch_mnt_namespace(n);\n }\n",
        "vul_function": "static void commit_tree(struct mount *mnt, struct mount *shadows)\n{\n\tstruct mount *parent = mnt->mnt_parent;\n\tstruct mount *m;\n\tLIST_HEAD(head);\n\tstruct mnt_namespace *n = parent->mnt_ns;\n\n\tBUG_ON(parent == mnt);\n\n\tlist_add_tail(&head, &mnt->mnt_list);\n\tlist_for_each_entry(m, &head, mnt_list)\n\t\tm->mnt_ns = n;\n \n \tlist_splice(&head, n->list.prev);\n \n \tattach_shadowed(mnt, parent, shadows);\n \ttouch_mnt_namespace(n);\n }\n",
        "llama3.1 Summary": "The patch limits the number of mounts allowed per mount namespace to 100,000 to prevent an exponentially increasing number of mounts that can be created by exploiting shared subtrees. This change adds a new sysctl /proc/sys/fs/mount-max to allow users to adjust this limit as needed for their specific use cases. Fixed version of function: static void commit_tree(struct mount *mnt, struct mount *shadows)\n{\n\tstruct mount *parent = mnt->mnt_parent;\n\tstruct mount *m;\n\tLIST_HEAD(head);\n\tstruct mnt_namespace *n = parent->mnt_ns;\n\n\tBUG_ON(parent == mnt);\n\n\tlist_add_tail(&head, &mnt->mnt_list);\n\tlist_for_each_entry(m, &head, mnt_list)\n\t\tm->mnt_ns = n;\n \n \tlist_splice(&head, n->list.prev);\n \n\tn->mounts += n->pending_mounts;\n\tn->pending_mounts = 0;\n\n \tattach_shadowed(mnt, parent, shadows);\n \ttouch_mnt_namespace(n);\n }",
        "llama3.1 CWE": "CWE-770",
        "llama3.1 CVE": "CVE-2016-6213",
        "llama3.1 BERT Score": {
            "BERTScore Precision": "0.4099",
            "BERTScore Recall": "0.6123",
            "BERTScore F1": "0.4911"
        },
        "llama3.1 Cosine_Similarity": 0.6502981185913086,
        "Mistral Summary": "The patch changes the default number of mounts allowed per mount namespace to 100,000 to prevent an exponential increase in mounts, which can lead to practical problems and resource exhaustion. This should help catch misconfigurations and malfunctioning programs.",
        "Mistral CWE": "CWE-207 (Exceeding Resource Limits)",
        "Mistral CVE": "CVE-2016-6213",
        "Mistral Cosine_Similarity": 0.6125257015228271,
        "Mistral BERT Score": {
            "BERTScore Precision": "0.6366",
            "BERTScore Recall": "0.6150",
            "BERTScore F1": "0.6256"
        },
        "Tokens Used": ""
    },
    {
        "codeLink": "https://github.com/torvalds/linux/commit/c40f7d74c741a907cfaeb73a7697081881c497d0",
        "CVE ID": "CVE-2018-20784",
        "CVE Details": "In the Linux kernel before 4.20.2, kernel/sched/fair.c mishandles leaf cfs_rq's, which allows attackers to cause a denial of service (infinite loop in update_blocked_averages) or possibly have unspecified other impact by inducing a high load.",
        "CWE ID": "CWE-400",
        "commit_message": "sched/fair: Fix infinite loop in update_blocked_averages() by reverting a9e7f6544b9c\n\nZhipeng Xie, Xie XiuQi and Sargun Dhillon reported lockups in the\nscheduler under high loads, starting at around the v4.18 time frame,\nand Zhipeng Xie tracked it down to bugs in the rq->leaf_cfs_rq_list\nmanipulation.\n\nDo a (manual) revert of:\n\n  a9e7f6544b9c (\"sched/fair: Fix O(nr_cgroups) in load balance path\")\n\nIt turns out that the list_del_leaf_cfs_rq() introduced by this commit\nis a surprising property that was not considered in followup commits\nsuch as:\n\n  9c2791f936ef (\"sched/fair: Fix hierarchical order in rq->leaf_cfs_rq_list\")\n\nAs Vincent Guittot explains:\n\n \"I think that there is a bigger problem with commit a9e7f6544b9c and\n  cfs_rq throttling:\n\n  Let take the example of the following topology TG2 --> TG1 --> root:\n\n   1) The 1st time a task is enqueued, we will add TG2 cfs_rq then TG1\n      cfs_rq to leaf_cfs_rq_list and we are sure to do the whole branch in\n      one path because it has never been used and can't be throttled so\n      tmp_alone_branch will point to leaf_cfs_rq_list at the end.\n\n   2) Then TG1 is throttled\n\n   3) and we add TG3 as a new child of TG1.\n\n   4) The 1st enqueue of a task on TG3 will add TG3 cfs_rq just before TG1\n      cfs_rq and tmp_alone_branch will stay  on rq->leaf_cfs_rq_list.\n\n  With commit a9e7f6544b9c, we can del a cfs_rq from rq->leaf_cfs_rq_list.\n  So if the load of TG1 cfs_rq becomes NULL before step 2) above, TG1\n  cfs_rq is removed from the list.\n  Then at step 4), TG3 cfs_rq is added at the beginning of rq->leaf_cfs_rq_list\n  but tmp_alone_branch still points to TG3 cfs_rq because its throttled\n  parent can't be enqueued when the lock is released.\n  tmp_alone_branch doesn't point to rq->leaf_cfs_rq_list whereas it should.\n\n  So if TG3 cfs_rq is removed or destroyed before tmp_alone_branch\n  points on another TG cfs_rq, the next TG cfs_rq that will be added,\n  will be linked outside rq->leaf_cfs_rq_list - which is bad.\n\n  In addition, we can break the ordering of the cfs_rq in\n  rq->leaf_cfs_rq_list but this ordering is used to update and\n  propagate the update from leaf down to root.\"\n\nInstead of trying to work through all these cases and trying to reproduce\nthe very high loads that produced the lockup to begin with, simplify\nthe code temporarily by reverting a9e7f6544b9c - which change was clearly\nnot thought through completely.\n\nThis (hopefully) gives us a kernel that doesn't lock up so people\ncan continue to enjoy their holidays without worrying about regressions. ;-)\n\n[ mingo: Wrote changelog, fixed weird spelling in code comment while at it. ]\n\nAnalyzed-by: Xie XiuQi <xiexiuqi@huawei.com>\nAnalyzed-by: Vincent Guittot <vincent.guittot@linaro.org>\nReported-by: Zhipeng Xie <xiezhipeng1@huawei.com>\nReported-by: Sargun Dhillon <sargun@sargun.me>\nReported-by: Xie XiuQi <xiexiuqi@huawei.com>\nTested-by: Zhipeng Xie <xiezhipeng1@huawei.com>\nTested-by: Sargun Dhillon <sargun@sargun.me>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>\nAcked-by: Vincent Guittot <vincent.guittot@linaro.org>\nCc: <stable@vger.kernel.org> # v4.13+\nCc: Bin Li <huawei.libin@huawei.com>\nCc: Mike Galbraith <efault@gmx.de>\nCc: Peter Zijlstra <peterz@infradead.org>\nCc: Tejun Heo <tj@kernel.org>\nCc: Thomas Gleixner <tglx@linutronix.de>\nFixes: a9e7f6544b9c (\"sched/fair: Fix O(nr_cgroups) in load balance path\")\nLink: http://lkml.kernel.org/r/1545879866-27809-1-git-send-email-xiexiuqi@huawei.com\nSigned-off-by: Ingo Molnar <mingo@kernel.org>",
        "fixed_function": "static inline bool cfs_rq_is_decayed(struct cfs_rq *cfs_rq)\n",
        "vul_function": "static inline bool cfs_rq_is_decayed(struct cfs_rq *cfs_rq)\n{\n\tif (cfs_rq->load.weight)\n\t\treturn false;\n\tif (cfs_rq->avg.load_sum)\n\t\treturn false;\n\tif (cfs_rq->avg.util_sum)\n\t\treturn false;\n\tif (cfs_rq->avg.runnable_load_sum)\n\t\treturn false;\n\treturn true;\n}\n",
        "llama3.1 Summary": "The patch reverts a9e7f6544b9c to fix an infinite loop caused by incorrect list manipulation in the scheduler, leading to lockups under high loads. The reverted commit introduced unexpected behavior in cfs_rq throttling and leaf_cfs_rq_list handling, causing cfs_rqs to be linked outside of rq->leaf_cfs_rq_list. \nstatic inline bool cfs_rq_is_decayed(struct cfs_rq *cfs_rq)\n{\n\tif (cfs_rq->load.weight)\n\t\treturn false;\n\tif (cfs_rq->avg.load_sum)\n\t\treturn false;\n\tif (cfs_rq->avg.util_sum)\n\t\treturn false;\n\tif (cfs_rq->avg.runnable_load_sum)\n\t\treturn false;\n\treturn true;\n}",
        "llama3.1 CWE": "CWE-908",
        "llama3.1 CVE": "CVE-2018-10661",
        "llama3.1 BERT Score": {
            "BERTScore Precision": "0.4471",
            "BERTScore Recall": "0.5811",
            "BERTScore F1": "0.5054"
        },
        "llama3.1 Cosine_Similarity": 0.6548994183540344,
        "Mistral Summary": "The patch changes by reverting the commit a9e7f6544b9c, which introduced list_del_leaf_cfs_rq(), fixes an infinite loop in update_blocked_averages() by preventing the removal of cfs_rq from rq->leaf_cfs_rq_list. This can lead to incorrect ordering of the cfs_rq in rq->leaf_cfs_rq_list, causing potential issues such as breaking the hierarchy order or linking cfs_rq outside rq->leaf_cfs_rq_list.",
        "Mistral CWE": "CWE-476 (Integer Wrap or Truncation)",
        "Mistral CVE": "Not available as it is a manual revert and not a newly discovered vulnerability",
        "Mistral Cosine_Similarity": 0.5084957480430603,
        "Mistral BERT Score": {
            "BERTScore Precision": "0.5363",
            "BERTScore Recall": "0.6292",
            "BERTScore F1": "0.5790"
        },
        "Tokens Used": ""
    },
    {
        "codeLink": "https://github.com/xkbcommon/libxkbcommon/commit/1f9d1248c07cda8aaff762429c0dce146de8632a",
        "CVE ID": "CVE-2018-15853",
        "CVE Details": "Endless recursion exists in xkbcomp/expr.c in xkbcommon and libxkbcommon before 0.8.1, which could be used by local attackers to crash xkbcommon users by supplying a crafted keymap file that triggers boolean negation.",
        "CWE ID": "CWE-400",
        "commit_message": "xkbcomp: fix stack overflow when evaluating boolean negation\n\nThe expression evaluator would go into an infinite recursion when\nevaluating something like this as a boolean: `!True`. Instead of\nrecursing to just `True` and negating, it recursed to `!True` itself\nagain.\n\nBug inherited from xkbcomp.\n\nCaught with the afl fuzzer.\n\nSigned-off-by: Ran Benita <ran234@gmail.com>",
        "fixed_function": "ExprResolveBoolean(struct xkb_context *ctx, const ExprDef *expr,\n                   bool *set_rtrn)\n{\n    bool ok = false;\n    const char *ident;\n\n    switch (expr->expr.op) {\n    case EXPR_VALUE:\n        if (expr->expr.value_type != EXPR_TYPE_BOOLEAN) {\n            log_err(ctx,\n                    \"Found constant of type %s where boolean was expected\\n\",\n                    expr_value_type_to_string(expr->expr.value_type));\n            return false;\n        }\n        *set_rtrn = expr->boolean.set;\n        return true;\n\n    case EXPR_IDENT:\n        ident = xkb_atom_text(ctx, expr->ident.ident);\n        if (ident) {\n            if (istreq(ident, \"true\") ||\n                istreq(ident, \"yes\") ||\n                istreq(ident, \"on\")) {\n                *set_rtrn = true;\n                return true;\n            }\n            else if (istreq(ident, \"false\") ||\n                     istreq(ident, \"no\") ||\n                     istreq(ident, \"off\")) {\n                *set_rtrn = false;\n                return true;\n            }\n        }\n        log_err(ctx, \"Identifier \\\"%s\\\" of type boolean is unknown\\n\", ident);\n        return false;\n\n    case EXPR_FIELD_REF:\n        log_err(ctx, \"Default \\\"%s.%s\\\" of type boolean is unknown\\n\",\n                xkb_atom_text(ctx, expr->field_ref.element),\n                xkb_atom_text(ctx, expr->field_ref.field));\n        return false;\n \n     case EXPR_INVERT:\n     case EXPR_NOT:\n        ok = ExprResolveBoolean(ctx, expr->unary.child, set_rtrn);\n         if (ok)\n             *set_rtrn = !*set_rtrn;\n         return ok;\n    case EXPR_ADD:\n    case EXPR_SUBTRACT:\n    case EXPR_MULTIPLY:\n    case EXPR_DIVIDE:\n    case EXPR_ASSIGN:\n    case EXPR_NEGATE:\n    case EXPR_UNARY_PLUS:\n        log_err(ctx, \"%s of boolean values not permitted\\n\",\n                expr_op_type_to_string(expr->expr.op));\n        break;\n\n    default:\n        log_wsgo(ctx, \"Unknown operator %d in ResolveBoolean\\n\",\n                 expr->expr.op);\n        break;\n    }\n\n    return false;\n}\n",
        "vul_function": "ExprResolveBoolean(struct xkb_context *ctx, const ExprDef *expr,\n                   bool *set_rtrn)\n{\n    bool ok = false;\n    const char *ident;\n\n    switch (expr->expr.op) {\n    case EXPR_VALUE:\n        if (expr->expr.value_type != EXPR_TYPE_BOOLEAN) {\n            log_err(ctx,\n                    \"Found constant of type %s where boolean was expected\\n\",\n                    expr_value_type_to_string(expr->expr.value_type));\n            return false;\n        }\n        *set_rtrn = expr->boolean.set;\n        return true;\n\n    case EXPR_IDENT:\n        ident = xkb_atom_text(ctx, expr->ident.ident);\n        if (ident) {\n            if (istreq(ident, \"true\") ||\n                istreq(ident, \"yes\") ||\n                istreq(ident, \"on\")) {\n                *set_rtrn = true;\n                return true;\n            }\n            else if (istreq(ident, \"false\") ||\n                     istreq(ident, \"no\") ||\n                     istreq(ident, \"off\")) {\n                *set_rtrn = false;\n                return true;\n            }\n        }\n        log_err(ctx, \"Identifier \\\"%s\\\" of type boolean is unknown\\n\", ident);\n        return false;\n\n    case EXPR_FIELD_REF:\n        log_err(ctx, \"Default \\\"%s.%s\\\" of type boolean is unknown\\n\",\n                xkb_atom_text(ctx, expr->field_ref.element),\n                xkb_atom_text(ctx, expr->field_ref.field));\n        return false;\n \n     case EXPR_INVERT:\n     case EXPR_NOT:\n        ok = ExprResolveBoolean(ctx, expr, set_rtrn);\n         if (ok)\n             *set_rtrn = !*set_rtrn;\n         return ok;\n    case EXPR_ADD:\n    case EXPR_SUBTRACT:\n    case EXPR_MULTIPLY:\n    case EXPR_DIVIDE:\n    case EXPR_ASSIGN:\n    case EXPR_NEGATE:\n    case EXPR_UNARY_PLUS:\n        log_err(ctx, \"%s of boolean values not permitted\\n\",\n                expr_op_type_to_string(expr->expr.op));\n        break;\n\n    default:\n        log_wsgo(ctx, \"Unknown operator %d in ResolveBoolean\\n\",\n                 expr->expr.op);\n        break;\n    }\n\n    return false;\n}\n",
        "llama3.1 Summary": "The patch fixes an infinite recursion bug in the boolean negation evaluation, which caused a stack overflow. The change corrects the recursive call to use the correct expression instead of the same one again, preventing the loop.",
        "llama3.1 CWE": "CWE-691",
        "llama3.1 CVE": "CVE-2019-11595",
        "llama3.1 BERT Score": {
            "BERTScore Precision": "0.5987",
            "BERTScore Recall": "0.5422",
            "BERTScore F1": "0.5690"
        },
        "llama3.1 Cosine_Similarity": 0.4201962947845459,
        "Mistral Summary": "The patch changes the behavior of the `ExprResolveBoolean` function when it encounters a `EXPR_INVERT` or `EXPR_NOT` operator. In the original vulnerable version, it recursively called itself with the same argument, leading to an infinite recursion. In the fixed version, it correctly calls the function with the child expression instead of the current expression, preventing the stack overflow.",
        "Mistral CWE": "CWE-139 (Recursive Function without Base Case)",
        "Mistral CVE": "Not provided, as CVE IDs are assigned by organizations that manage the coordinated disclosure of software vulnerabilities and this example does not represent an actual vulnerability in any real-world software.",
        "Mistral Cosine_Similarity": 0.36723166704177856,
        "Mistral BERT Score": {
            "BERTScore Precision": "0.5237",
            "BERTScore Recall": "0.5428",
            "BERTScore F1": "0.5331"
        },
        "Tokens Used": ""
    },
    {
        "codeLink": "https://git.openssl.org/?p=openssl.git;a=commit;h=4b390b6c3f8df925dc92a3dd6b022baa9a2f4650",
        "CVE ID": "CVE-2016-6307",
        "CVE Details": "The state-machine implementation in OpenSSL 1.1.0 before 1.1.0a allocates memory before checking for an excessive length, which might allow remote attackers to cause a denial of service (memory consumption) via crafted TLS messages, related to statem/statem.c and statem/statem_lib.c.",
        "CWE ID": "CWE-400",
        "commit_message": "None",
        "fixed_function": "static SUB_STATE_RETURN read_state_machine(SSL *s)\n{\n    OSSL_STATEM *st = &s->statem;\n    int ret, mt;\n    unsigned long len = 0;\n    int (*transition) (SSL *s, int mt);\n    PACKET pkt;\n    MSG_PROCESS_RETURN(*process_message) (SSL *s, PACKET *pkt);\n    WORK_STATE(*post_process_message) (SSL *s, WORK_STATE wst);\n    unsigned long (*max_message_size) (SSL *s);\n    void (*cb) (const SSL *ssl, int type, int val) = NULL;\n\n    cb = get_callback(s);\n\n    if (s->server) {\n        transition = ossl_statem_server_read_transition;\n        process_message = ossl_statem_server_process_message;\n        max_message_size = ossl_statem_server_max_message_size;\n        post_process_message = ossl_statem_server_post_process_message;\n    } else {\n        transition = ossl_statem_client_read_transition;\n        process_message = ossl_statem_client_process_message;\n        max_message_size = ossl_statem_client_max_message_size;\n        post_process_message = ossl_statem_client_post_process_message;\n    }\n\n    if (st->read_state_first_init) {\n        s->first_packet = 1;\n        st->read_state_first_init = 0;\n    }\n\n    while (1) {\n        switch (st->read_state) {\n        case READ_STATE_HEADER:\n            /* Get the state the peer wants to move to */\n            if (SSL_IS_DTLS(s)) {\n                /*\n                 * In DTLS we get the whole message in one go - header and body\n                 */\n                ret = dtls_get_message(s, &mt, &len);\n            } else {\n                ret = tls_get_message_header(s, &mt);\n            }\n\n            if (ret == 0) {\n                /* Could be non-blocking IO */\n                return SUB_STATE_ERROR;\n            }\n\n            if (cb != NULL) {\n                /* Notify callback of an impending state change */\n                if (s->server)\n                    cb(s, SSL_CB_ACCEPT_LOOP, 1);\n                else\n                    cb(s, SSL_CB_CONNECT_LOOP, 1);\n            }\n            /*\n             * Validate that we are allowed to move to the new state and move\n             * to that state if so\n             */\n            if (!transition(s, mt)) {\n                ossl_statem_set_error(s);\n                return SUB_STATE_ERROR;\n            }\n\n            if (s->s3->tmp.message_size > max_message_size(s)) {\n                ssl3_send_alert(s, SSL3_AL_FATAL, SSL_AD_ILLEGAL_PARAMETER);\n                SSLerr(SSL_F_READ_STATE_MACHINE, SSL_R_EXCESSIVE_MESSAGE_SIZE);\n                 return SUB_STATE_ERROR;\n             }\n \n            /* dtls_get_message already did this */\n            if (!SSL_IS_DTLS(s)\n                    && s->s3->tmp.message_size > 0\n                    && !BUF_MEM_grow_clean(s->init_buf,\n                                           (int)s->s3->tmp.message_size\n                                           + SSL3_HM_HEADER_LENGTH)) {\n                ssl3_send_alert(s, SSL3_AL_FATAL, SSL_AD_INTERNAL_ERROR);\n                SSLerr(SSL_F_TLS_GET_MESSAGE_HEADER, ERR_R_BUF_LIB);\n                return SUB_STATE_ERROR;\n            }\n\n             st->read_state = READ_STATE_BODY;\n             /* Fall through */\n            if (!PACKET_buf_init(&pkt, s->init_msg, len)) {\n                ssl3_send_alert(s, SSL3_AL_FATAL, SSL_AD_INTERNAL_ERROR);\n                SSLerr(SSL_F_READ_STATE_MACHINE, ERR_R_INTERNAL_ERROR);\n                return SUB_STATE_ERROR;\n            }\n            ret = process_message(s, &pkt);\n\n            /* Discard the packet data */\n            s->init_num = 0;\n\n            switch (ret) {\n            case MSG_PROCESS_ERROR:\n                return SUB_STATE_ERROR;\n\n            case MSG_PROCESS_FINISHED_READING:\n                if (SSL_IS_DTLS(s)) {\n                    dtls1_stop_timer(s);\n                }\n                return SUB_STATE_FINISHED;\n\n            case MSG_PROCESS_CONTINUE_PROCESSING:\n                st->read_state = READ_STATE_POST_PROCESS;\n                st->read_state_work = WORK_MORE_A;\n                break;\n\n            default:\n                st->read_state = READ_STATE_HEADER;\n                break;\n            }\n            break;\n\n        case READ_STATE_POST_PROCESS:\n            st->read_state_work = post_process_message(s, st->read_state_work);\n            switch (st->read_state_work) {\n            default:\n                return SUB_STATE_ERROR;\n\n            case WORK_FINISHED_CONTINUE:\n                st->read_state = READ_STATE_HEADER;\n                break;\n\n            case WORK_FINISHED_STOP:\n                if (SSL_IS_DTLS(s)) {\n                    dtls1_stop_timer(s);\n                }\n                return SUB_STATE_FINISHED;\n            }\n            break;\n\n        default:\n            /* Shouldn't happen */\n            ssl3_send_alert(s, SSL3_AL_FATAL, SSL_AD_INTERNAL_ERROR);\n            SSLerr(SSL_F_READ_STATE_MACHINE, ERR_R_INTERNAL_ERROR);\n            ossl_statem_set_error(s);\n            return SUB_STATE_ERROR;\n        }\n    }\n}\n",
        "vul_function": "static SUB_STATE_RETURN read_state_machine(SSL *s)\n{\n    OSSL_STATEM *st = &s->statem;\n    int ret, mt;\n    unsigned long len = 0;\n    int (*transition) (SSL *s, int mt);\n    PACKET pkt;\n    MSG_PROCESS_RETURN(*process_message) (SSL *s, PACKET *pkt);\n    WORK_STATE(*post_process_message) (SSL *s, WORK_STATE wst);\n    unsigned long (*max_message_size) (SSL *s);\n    void (*cb) (const SSL *ssl, int type, int val) = NULL;\n\n    cb = get_callback(s);\n\n    if (s->server) {\n        transition = ossl_statem_server_read_transition;\n        process_message = ossl_statem_server_process_message;\n        max_message_size = ossl_statem_server_max_message_size;\n        post_process_message = ossl_statem_server_post_process_message;\n    } else {\n        transition = ossl_statem_client_read_transition;\n        process_message = ossl_statem_client_process_message;\n        max_message_size = ossl_statem_client_max_message_size;\n        post_process_message = ossl_statem_client_post_process_message;\n    }\n\n    if (st->read_state_first_init) {\n        s->first_packet = 1;\n        st->read_state_first_init = 0;\n    }\n\n    while (1) {\n        switch (st->read_state) {\n        case READ_STATE_HEADER:\n            /* Get the state the peer wants to move to */\n            if (SSL_IS_DTLS(s)) {\n                /*\n                 * In DTLS we get the whole message in one go - header and body\n                 */\n                ret = dtls_get_message(s, &mt, &len);\n            } else {\n                ret = tls_get_message_header(s, &mt);\n            }\n\n            if (ret == 0) {\n                /* Could be non-blocking IO */\n                return SUB_STATE_ERROR;\n            }\n\n            if (cb != NULL) {\n                /* Notify callback of an impending state change */\n                if (s->server)\n                    cb(s, SSL_CB_ACCEPT_LOOP, 1);\n                else\n                    cb(s, SSL_CB_CONNECT_LOOP, 1);\n            }\n            /*\n             * Validate that we are allowed to move to the new state and move\n             * to that state if so\n             */\n            if (!transition(s, mt)) {\n                ossl_statem_set_error(s);\n                return SUB_STATE_ERROR;\n            }\n\n            if (s->s3->tmp.message_size > max_message_size(s)) {\n                ssl3_send_alert(s, SSL3_AL_FATAL, SSL_AD_ILLEGAL_PARAMETER);\n                SSLerr(SSL_F_READ_STATE_MACHINE, SSL_R_EXCESSIVE_MESSAGE_SIZE);\n                 return SUB_STATE_ERROR;\n             }\n \n             st->read_state = READ_STATE_BODY;\n             /* Fall through */\n            if (!PACKET_buf_init(&pkt, s->init_msg, len)) {\n                ssl3_send_alert(s, SSL3_AL_FATAL, SSL_AD_INTERNAL_ERROR);\n                SSLerr(SSL_F_READ_STATE_MACHINE, ERR_R_INTERNAL_ERROR);\n                return SUB_STATE_ERROR;\n            }\n            ret = process_message(s, &pkt);\n\n            /* Discard the packet data */\n            s->init_num = 0;\n\n            switch (ret) {\n            case MSG_PROCESS_ERROR:\n                return SUB_STATE_ERROR;\n\n            case MSG_PROCESS_FINISHED_READING:\n                if (SSL_IS_DTLS(s)) {\n                    dtls1_stop_timer(s);\n                }\n                return SUB_STATE_FINISHED;\n\n            case MSG_PROCESS_CONTINUE_PROCESSING:\n                st->read_state = READ_STATE_POST_PROCESS;\n                st->read_state_work = WORK_MORE_A;\n                break;\n\n            default:\n                st->read_state = READ_STATE_HEADER;\n                break;\n            }\n            break;\n\n        case READ_STATE_POST_PROCESS:\n            st->read_state_work = post_process_message(s, st->read_state_work);\n            switch (st->read_state_work) {\n            default:\n                return SUB_STATE_ERROR;\n\n            case WORK_FINISHED_CONTINUE:\n                st->read_state = READ_STATE_HEADER;\n                break;\n\n            case WORK_FINISHED_STOP:\n                if (SSL_IS_DTLS(s)) {\n                    dtls1_stop_timer(s);\n                }\n                return SUB_STATE_FINISHED;\n            }\n            break;\n\n        default:\n            /* Shouldn't happen */\n            ssl3_send_alert(s, SSL3_AL_FATAL, SSL_AD_INTERNAL_ERROR);\n            SSLerr(SSL_F_READ_STATE_MACHINE, ERR_R_INTERNAL_ERROR);\n            ossl_statem_set_error(s);\n            return SUB_STATE_ERROR;\n        }\n    }\n}\n",
        "llama3.1 Summary": null,
        "llama3.1 CWE": null,
        "llama3.1 CVE": null,
        "llama3.1 BERT Score": {
            "BERTScore Precision": "0.3382",
            "BERTScore Recall": "0.2290",
            "BERTScore F1": "0.2731"
        },
        "llama3.1 Cosine_Similarity": 0.02068030834197998,
        "Mistral Summary": null,
        "Mistral CWE": null,
        "Mistral CVE": null,
        "Mistral Cosine_Similarity": 0.02068030834197998,
        "Mistral BERT Score": {
            "BERTScore Precision": "0.3382",
            "BERTScore Recall": "0.2290",
            "BERTScore F1": "0.2731"
        },
        "Tokens Used": ""
    },
    {
        "codeLink": "https://github.com/ccxvii/mujs/commit/00d4606c3baf813b7b1c176823b2729bf51002a2",
        "CVE ID": "CVE-2019-11413",
        "CVE Details": "An issue was discovered in Artifex MuJS 1.0.5. It has unlimited recursion because the match function in regexp.c lacks a depth check.",
        "CWE ID": "CWE-400",
        "commit_message": "Bug 700937: Limit recursion in regexp matcher.\n\nAlso handle negative return code as an error in the JS bindings.",
        "fixed_function": "static void Sp_split_regexp(js_State *J)\n{\n\tjs_Regexp *re;\n\tconst char *text;\n\tint limit, len, k;\n\tconst char *p, *a, *b, *c, *e;\n\tResub m;\n\n\ttext = checkstring(J, 0);\n\tre = js_toregexp(J, 1);\n\tlimit = js_isdefined(J, 2) ? js_tointeger(J, 2) : 1 << 30;\n\n\tjs_newarray(J);\n\tlen = 0;\n\n\te = text + strlen(text);\n \n \t/* splitting the empty string */\n \tif (e == text) {\n\t\tif (js_doregexec(J, re->prog, text, &m, 0)) {\n \t\t\tif (len == limit) return;\n \t\t\tjs_pushliteral(J, \"\");\n \t\t\tjs_setindex(J, -2, 0);\n\t\t}\n\t\treturn;\n\t}\n \n \tp = a = text;\n \twhile (a < e) {\n\t\tif (js_doregexec(J, re->prog, a, &m, a > text ? REG_NOTBOL : 0))\n \t\t\tbreak; /* no match */\n \n \t\tb = m.sub[0].sp;\n\t\tc = m.sub[0].ep;\n\n\t\t/* empty string at end of last match */\n\t\tif (b == p) {\n\t\t\t++a;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (len == limit) return;\n\t\tjs_pushlstring(J, p, b - p);\n\t\tjs_setindex(J, -2, len++);\n\n\t\tfor (k = 1; k < m.nsub; ++k) {\n\t\t\tif (len == limit) return;\n\t\t\tjs_pushlstring(J, m.sub[k].sp, m.sub[k].ep - m.sub[k].sp);\n\t\t\tjs_setindex(J, -2, len++);\n\t\t}\n\n\t\ta = p = c;\n\t}\n\n\tif (len == limit) return;\n\tjs_pushstring(J, p);\n\tjs_setindex(J, -2, len);\n}\n",
        "vul_function": "static void Sp_split_regexp(js_State *J)\n{\n\tjs_Regexp *re;\n\tconst char *text;\n\tint limit, len, k;\n\tconst char *p, *a, *b, *c, *e;\n\tResub m;\n\n\ttext = checkstring(J, 0);\n\tre = js_toregexp(J, 1);\n\tlimit = js_isdefined(J, 2) ? js_tointeger(J, 2) : 1 << 30;\n\n\tjs_newarray(J);\n\tlen = 0;\n\n\te = text + strlen(text);\n \n \t/* splitting the empty string */\n \tif (e == text) {\n\t\tif (js_regexec(re->prog, text, &m, 0)) {\n \t\t\tif (len == limit) return;\n \t\t\tjs_pushliteral(J, \"\");\n \t\t\tjs_setindex(J, -2, 0);\n\t\t}\n\t\treturn;\n\t}\n \n \tp = a = text;\n \twhile (a < e) {\n\t\tif (js_regexec(re->prog, a, &m, a > text ? REG_NOTBOL : 0))\n \t\t\tbreak; /* no match */\n \n \t\tb = m.sub[0].sp;\n\t\tc = m.sub[0].ep;\n\n\t\t/* empty string at end of last match */\n\t\tif (b == p) {\n\t\t\t++a;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (len == limit) return;\n\t\tjs_pushlstring(J, p, b - p);\n\t\tjs_setindex(J, -2, len++);\n\n\t\tfor (k = 1; k < m.nsub; ++k) {\n\t\t\tif (len == limit) return;\n\t\t\tjs_pushlstring(J, m.sub[k].sp, m.sub[k].ep - m.sub[k].sp);\n\t\t\tjs_setindex(J, -2, len++);\n\t\t}\n\n\t\ta = p = c;\n\t}\n\n\tif (len == limit) return;\n\tjs_pushstring(J, p);\n\tjs_setindex(J, -2, len);\n}\n",
        "llama3.1 Summary": "The patch changes how the function handles the case where the input string is empty, avoiding a potential infinite recursion by returning immediately instead of executing the regular expression. This fix addresses a bug (700937) that was causing errors in the JS bindings when handling negative return codes from the regular expression matcher. Fixed version of function: static void Sp_split_regexp(js_State *J)\n{\n\tjs_Regexp *re;\n\tconst char *text;\n\tint limit, len, k;\n\tconst char *p, *a, *b, *c, *e;\n\tResub m;\n\n\ttext = checkstring(J, 0);\n\tre = js_toregexp(J, 1);\n\tlimit = js_isdefined(J, 2) ? js_tointeger(J, 2) : 1 << 30;\n\n\tjs_newarray(J);\n\tlen = 0;\n\n\te = text + strlen(text);\n\n \t/* splitting the empty string */\n \tif (e == text) {\n\t\tif (js_doregexec(J, re->prog, text, &m, 0)) {\n \t\t\tif (len == limit) return;\n \t\t\tjs_pushliteral(J, \"\");\n \t\t\tjs_setindex(J, -2, 0);\n\t\t}\n\t\treturn;\n\t}\n\n\tp = a = text;\n \twhile (a < e) {\n\t\tif (js_doregexec(J, re->prog, a, &m, a > text ? REG_NOTBOL : 0))\n \t\t\tbreak; /* no match */\n\n \t\tb = m.sub[0].sp;\n\t\tc = m.sub[0].ep;\n\n\t\tif (b == p) {\n\t\t\t++a;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (len == limit) return;\n\t\tjs_pushlstring(J, p, b - p);\n\t\tjs_setindex(J, -2, len++);\n\n\t\tfor (k = 1; k < m.nsub; ++k) {\n\t\t\tif (len == limit) return;\n\t\t\tjs_pushlstring(J, m.sub[k].sp, m.sub[k].ep - m.sub[k].sp);\n\t\t\tjs_setindex(J, -2, len++);\n\t\t}\n\n\t\ta = p = c;\n\t}\n\n\tif (len == limit) return;\n\tjs_pushstring(J, p);\n\tjs_setindex(J, -2, len);\n}",
        "llama3.1 CWE": "CWE-119",
        "llama3.1 CVE": "CVE-2017-11526",
        "llama3.1 BERT Score": {
            "BERTScore Precision": "0.2623",
            "BERTScore Recall": "0.5170",
            "BERTScore F1": "0.3481"
        },
        "llama3.1 Cosine_Similarity": 0.4414218068122864,
        "Mistral Summary": "The patch limits recursion in the regexp matcher to prevent a stack-based buffer overflow. It does this by introducing a limit to the number of matches that can be made. Without this limit, an attacker could craft a malicious regular expression and input string combination that triggers a buffer overflow due to infinite recursion. The commit message also mentions handling negative return codes as errors in the JS bindings, but this does not appear to affect the CWE ID.",
        "Mistral CWE": "CWE-125 (Stack-based Buffer Overflow)",
        "Mistral CVE": "CVE-XXXX-XXXX (Assigned by appropriate party)",
        "Mistral Cosine_Similarity": 0.41267406940460205,
        "Mistral BERT Score": {
            "BERTScore Precision": "0.5614",
            "BERTScore Recall": "0.6466",
            "BERTScore F1": "0.6010"
        },
        "Tokens Used": ""
    },
    {
        "codeLink": "https://github.com/torvalds/linux/commit/2e83b79b2d6c78bf1b4aa227938a214dcbddc83f",
        "CVE ID": "CVE-2016-9685",
        "CVE Details": "Multiple memory leaks in error paths in fs/xfs/xfs_attr_list.c in the Linux kernel before 4.5.1 allow local users to cause a denial of service (memory consumption) via crafted XFS filesystem operations.",
        "CWE ID": "CWE-400",
        "commit_message": "xfs: fix two memory leaks in xfs_attr_list.c error paths\n\nThis plugs 2 trivial leaks in xfs_attr_shortform_list and\nxfs_attr3_leaf_list_int.\n\nSigned-off-by: Mateusz Guzik <mguzik@redhat.com>\nCc: <stable@vger.kernel.org>\nReviewed-by: Eric Sandeen <sandeen@redhat.com>\nSigned-off-by: Dave Chinner <david@fromorbit.com>",
        "fixed_function": "xfs_attr3_leaf_list_int(\n\tstruct xfs_buf\t\t\t*bp,\n\tstruct xfs_attr_list_context\t*context)\n{\n\tstruct attrlist_cursor_kern\t*cursor;\n\tstruct xfs_attr_leafblock\t*leaf;\n\tstruct xfs_attr3_icleaf_hdr\tichdr;\n\tstruct xfs_attr_leaf_entry\t*entries;\n\tstruct xfs_attr_leaf_entry\t*entry;\n\tint\t\t\t\tretval;\n\tint\t\t\t\ti;\n\tstruct xfs_mount\t\t*mp = context->dp->i_mount;\n\n\ttrace_xfs_attr_list_leaf(context);\n\n\tleaf = bp->b_addr;\n\txfs_attr3_leaf_hdr_from_disk(mp->m_attr_geo, &ichdr, leaf);\n\tentries = xfs_attr3_leaf_entryp(leaf);\n\n\tcursor = context->cursor;\n\tcursor->initted = 1;\n\n\t/*\n\t * Re-find our place in the leaf block if this is a new syscall.\n\t */\n\tif (context->resynch) {\n\t\tentry = &entries[0];\n\t\tfor (i = 0; i < ichdr.count; entry++, i++) {\n\t\t\tif (be32_to_cpu(entry->hashval) == cursor->hashval) {\n\t\t\t\tif (cursor->offset == context->dupcnt) {\n\t\t\t\t\tcontext->dupcnt = 0;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tcontext->dupcnt++;\n\t\t\t} else if (be32_to_cpu(entry->hashval) >\n\t\t\t\t\tcursor->hashval) {\n\t\t\t\tcontext->dupcnt = 0;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (i == ichdr.count) {\n\t\t\ttrace_xfs_attr_list_notfound(context);\n\t\t\treturn 0;\n\t\t}\n\t} else {\n\t\tentry = &entries[0];\n\t\ti = 0;\n\t}\n\tcontext->resynch = 0;\n\n\t/*\n\t * We have found our place, start copying out the new attributes.\n\t */\n\tretval = 0;\n\tfor (; i < ichdr.count; entry++, i++) {\n\t\tif (be32_to_cpu(entry->hashval) != cursor->hashval) {\n\t\t\tcursor->hashval = be32_to_cpu(entry->hashval);\n\t\t\tcursor->offset = 0;\n\t\t}\n\n\t\tif (entry->flags & XFS_ATTR_INCOMPLETE)\n\t\t\tcontinue;\t\t/* skip incomplete entries */\n\n\t\tif (entry->flags & XFS_ATTR_LOCAL) {\n\t\t\txfs_attr_leaf_name_local_t *name_loc =\n\t\t\t\txfs_attr3_leaf_name_local(leaf, i);\n\n\t\t\tretval = context->put_listent(context,\n\t\t\t\t\t\tentry->flags,\n\t\t\t\t\t\tname_loc->nameval,\n\t\t\t\t\t\t(int)name_loc->namelen,\n\t\t\t\t\t\tbe16_to_cpu(name_loc->valuelen),\n\t\t\t\t\t\t&name_loc->nameval[name_loc->namelen]);\n\t\t\tif (retval)\n\t\t\t\treturn retval;\n\t\t} else {\n\t\t\txfs_attr_leaf_name_remote_t *name_rmt =\n\t\t\t\txfs_attr3_leaf_name_remote(leaf, i);\n\n\t\t\tint valuelen = be32_to_cpu(name_rmt->valuelen);\n\n\t\t\tif (context->put_value) {\n\t\t\t\txfs_da_args_t args;\n\n\t\t\t\tmemset((char *)&args, 0, sizeof(args));\n\t\t\t\targs.geo = context->dp->i_mount->m_attr_geo;\n\t\t\t\targs.dp = context->dp;\n\t\t\t\targs.whichfork = XFS_ATTR_FORK;\n\t\t\t\targs.valuelen = valuelen;\n\t\t\t\targs.rmtvaluelen = valuelen;\n\t\t\t\targs.value = kmem_alloc(valuelen, KM_SLEEP | KM_NOFS);\n\t\t\t\targs.rmtblkno = be32_to_cpu(name_rmt->valueblk);\n \t\t\t\targs.rmtblkcnt = xfs_attr3_rmt_blocks(\n \t\t\t\t\t\t\targs.dp->i_mount, valuelen);\n \t\t\t\tretval = xfs_attr_rmtval_get(&args);\n\t\t\t\tif (!retval)\n\t\t\t\t\tretval = context->put_listent(context,\n\t\t\t\t\t\t\tentry->flags,\n\t\t\t\t\t\t\tname_rmt->name,\n\t\t\t\t\t\t\t(int)name_rmt->namelen,\n\t\t\t\t\t\t\tvaluelen,\n\t\t\t\t\t\t\targs.value);\n \t\t\t\tkmem_free(args.value);\n \t\t\t} else {\n \t\t\t\tretval = context->put_listent(context,\n\t\t\t\t\t\tentry->flags,\n\t\t\t\t\t\tname_rmt->name,\n\t\t\t\t\t\t(int)name_rmt->namelen,\n\t\t\t\t\t\tvaluelen,\n\t\t\t\t\t\tNULL);\n\t\t\t}\n\t\t\tif (retval)\n\t\t\t\treturn retval;\n\t\t}\n\t\tif (context->seen_enough)\n\t\t\tbreak;\n\t\tcursor->offset++;\n\t}\n\ttrace_xfs_attr_list_leaf_end(context);\n\treturn retval;\n}\n",
        "vul_function": "xfs_attr3_leaf_list_int(\n\tstruct xfs_buf\t\t\t*bp,\n\tstruct xfs_attr_list_context\t*context)\n{\n\tstruct attrlist_cursor_kern\t*cursor;\n\tstruct xfs_attr_leafblock\t*leaf;\n\tstruct xfs_attr3_icleaf_hdr\tichdr;\n\tstruct xfs_attr_leaf_entry\t*entries;\n\tstruct xfs_attr_leaf_entry\t*entry;\n\tint\t\t\t\tretval;\n\tint\t\t\t\ti;\n\tstruct xfs_mount\t\t*mp = context->dp->i_mount;\n\n\ttrace_xfs_attr_list_leaf(context);\n\n\tleaf = bp->b_addr;\n\txfs_attr3_leaf_hdr_from_disk(mp->m_attr_geo, &ichdr, leaf);\n\tentries = xfs_attr3_leaf_entryp(leaf);\n\n\tcursor = context->cursor;\n\tcursor->initted = 1;\n\n\t/*\n\t * Re-find our place in the leaf block if this is a new syscall.\n\t */\n\tif (context->resynch) {\n\t\tentry = &entries[0];\n\t\tfor (i = 0; i < ichdr.count; entry++, i++) {\n\t\t\tif (be32_to_cpu(entry->hashval) == cursor->hashval) {\n\t\t\t\tif (cursor->offset == context->dupcnt) {\n\t\t\t\t\tcontext->dupcnt = 0;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tcontext->dupcnt++;\n\t\t\t} else if (be32_to_cpu(entry->hashval) >\n\t\t\t\t\tcursor->hashval) {\n\t\t\t\tcontext->dupcnt = 0;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (i == ichdr.count) {\n\t\t\ttrace_xfs_attr_list_notfound(context);\n\t\t\treturn 0;\n\t\t}\n\t} else {\n\t\tentry = &entries[0];\n\t\ti = 0;\n\t}\n\tcontext->resynch = 0;\n\n\t/*\n\t * We have found our place, start copying out the new attributes.\n\t */\n\tretval = 0;\n\tfor (; i < ichdr.count; entry++, i++) {\n\t\tif (be32_to_cpu(entry->hashval) != cursor->hashval) {\n\t\t\tcursor->hashval = be32_to_cpu(entry->hashval);\n\t\t\tcursor->offset = 0;\n\t\t}\n\n\t\tif (entry->flags & XFS_ATTR_INCOMPLETE)\n\t\t\tcontinue;\t\t/* skip incomplete entries */\n\n\t\tif (entry->flags & XFS_ATTR_LOCAL) {\n\t\t\txfs_attr_leaf_name_local_t *name_loc =\n\t\t\t\txfs_attr3_leaf_name_local(leaf, i);\n\n\t\t\tretval = context->put_listent(context,\n\t\t\t\t\t\tentry->flags,\n\t\t\t\t\t\tname_loc->nameval,\n\t\t\t\t\t\t(int)name_loc->namelen,\n\t\t\t\t\t\tbe16_to_cpu(name_loc->valuelen),\n\t\t\t\t\t\t&name_loc->nameval[name_loc->namelen]);\n\t\t\tif (retval)\n\t\t\t\treturn retval;\n\t\t} else {\n\t\t\txfs_attr_leaf_name_remote_t *name_rmt =\n\t\t\t\txfs_attr3_leaf_name_remote(leaf, i);\n\n\t\t\tint valuelen = be32_to_cpu(name_rmt->valuelen);\n\n\t\t\tif (context->put_value) {\n\t\t\t\txfs_da_args_t args;\n\n\t\t\t\tmemset((char *)&args, 0, sizeof(args));\n\t\t\t\targs.geo = context->dp->i_mount->m_attr_geo;\n\t\t\t\targs.dp = context->dp;\n\t\t\t\targs.whichfork = XFS_ATTR_FORK;\n\t\t\t\targs.valuelen = valuelen;\n\t\t\t\targs.rmtvaluelen = valuelen;\n\t\t\t\targs.value = kmem_alloc(valuelen, KM_SLEEP | KM_NOFS);\n\t\t\t\targs.rmtblkno = be32_to_cpu(name_rmt->valueblk);\n \t\t\t\targs.rmtblkcnt = xfs_attr3_rmt_blocks(\n \t\t\t\t\t\t\targs.dp->i_mount, valuelen);\n \t\t\t\tretval = xfs_attr_rmtval_get(&args);\n\t\t\t\tif (retval)\n\t\t\t\t\treturn retval;\n\t\t\t\tretval = context->put_listent(context,\n\t\t\t\t\t\tentry->flags,\n\t\t\t\t\t\tname_rmt->name,\n\t\t\t\t\t\t(int)name_rmt->namelen,\n\t\t\t\t\t\tvaluelen,\n\t\t\t\t\t\targs.value);\n \t\t\t\tkmem_free(args.value);\n \t\t\t} else {\n \t\t\t\tretval = context->put_listent(context,\n\t\t\t\t\t\tentry->flags,\n\t\t\t\t\t\tname_rmt->name,\n\t\t\t\t\t\t(int)name_rmt->namelen,\n\t\t\t\t\t\tvaluelen,\n\t\t\t\t\t\tNULL);\n\t\t\t}\n\t\t\tif (retval)\n\t\t\t\treturn retval;\n\t\t}\n\t\tif (context->seen_enough)\n\t\t\tbreak;\n\t\tcursor->offset++;\n\t}\n\ttrace_xfs_attr_list_leaf_end(context);\n\treturn retval;\n}\n",
        "llama3.1 Summary": null,
        "llama3.1 CWE": null,
        "llama3.1 CVE": null,
        "llama3.1 BERT Score": {
            "BERTScore Precision": "0.3407",
            "BERTScore Recall": "0.2574",
            "BERTScore F1": "0.2933"
        },
        "llama3.1 Cosine_Similarity": 0.05514538288116455,
        "Mistral Summary": null,
        "Mistral CWE": null,
        "Mistral CVE": null,
        "Mistral Cosine_Similarity": 0.05514538288116455,
        "Mistral BERT Score": {
            "BERTScore Precision": "0.3407",
            "BERTScore Recall": "0.2574",
            "BERTScore F1": "0.2933"
        },
        "Tokens Used": ""
    },
    {
        "codeLink": "https://github.com/libarchive/libarchive/pull/1120/commits/8312eaa576014cd9b965012af51bc1f967b12423",
        "CVE ID": "CVE-2019-1000020",
        "CVE Details": "libarchive version commit 5a98dcf8a86364b3c2c469c85b93647dfb139961 onwards (version v2.8.0 onwards) contains a CWE-835: Loop with Unreachable Exit Condition ('Infinite Loop') vulnerability in ISO9660 parser, archive_read_support_format_iso9660.c, read_CE()/parse_rockridge() that can result in DoS by infinite loop. This attack appears to be exploitable via the victim opening a specially crafted ISO9660 file.",
        "CWE ID": "CWE-400",
        "commit_message": "iso9660: Fail when expected Rockridge extensions is missing\n\nA corrupted or malicious ISO9660 image can cause read_CE() to loop\nforever.\n\nread_CE() calls parse_rockridge(), expecting a Rockridge extension\nto be read. However, parse_rockridge() is structured as a while\nloop starting with a sanity check, and if the sanity check fails\nbefore the loop has run, the function returns ARCHIVE_OK without\nadvancing the position in the file. This causes read_CE() to retry\nindefinitely.\n\nMake parse_rockridge() return ARCHIVE_WARN if it didn't read an\nextension. As someone with no real knowledge of the format, this\nseems more apt than ARCHIVE_FATAL, but both the call-sites escalate\nit to a fatal error immediately anyway.\n\nFound with a combination of AFL, afl-rb (FairFuzz) and qsym.",
        "fixed_function": "parse_rockridge(struct archive_read *a, struct file_info *file,\n     const unsigned char *p, const unsigned char *end)\n {\n \tstruct iso9660 *iso9660;\n\tint entry_seen = 0;\n \n \tiso9660 = (struct iso9660 *)(a->format->data);\n \n\twhile (p + 4 <= end  /* Enough space for another entry. */\n\t    && p[0] >= 'A' && p[0] <= 'Z' /* Sanity-check 1st char of name. */\n\t    && p[1] >= 'A' && p[1] <= 'Z' /* Sanity-check 2nd char of name. */\n\t    && p[2] >= 4 /* Sanity-check length. */\n\t    && p + p[2] <= end) { /* Sanity-check length. */\n\t\tconst unsigned char *data = p + 4;\n\t\tint data_length = p[2] - 4;\n\t\tint version = p[3];\n\n\t\tswitch(p[0]) {\n\t\tcase 'C':\n\t\t\tif (p[1] == 'E') {\n\t\t\t\tif (version == 1 && data_length == 24) {\n\t\t\t\t\t/*\n\t\t\t\t\t * CE extension comprises:\n\t\t\t\t\t *   8 byte sector containing extension\n\t\t\t\t\t *   8 byte offset w/in above sector\n\t\t\t\t\t *   8 byte length of continuation\n\t\t\t\t\t */\n\t\t\t\t\tint32_t location =\n\t\t\t\t\t    archive_le32dec(data);\n\t\t\t\t\tfile->ce_offset =\n\t\t\t\t\t    archive_le32dec(data+8);\n\t\t\t\t\tfile->ce_size =\n\t\t\t\t\t    archive_le32dec(data+16);\n\t\t\t\t\tif (register_CE(a, location, file)\n\t\t\t\t\t    != ARCHIVE_OK)\n\t\t\t\t\t\treturn (ARCHIVE_FATAL);\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if (p[1] == 'L') {\n\t\t\t\tif (version == 1 && data_length == 8) {\n\t\t\t\t\tfile->cl_offset = (uint64_t)\n\t\t\t\t\t    iso9660->logical_block_size *\n\t\t\t\t\t    (uint64_t)archive_le32dec(data);\n\t\t\t\t\tiso9660->seenRockridge = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 'N':\n\t\t\tif (p[1] == 'M') {\n\t\t\t\tif (version == 1) {\n\t\t\t\t\tparse_rockridge_NM1(file,\n\t\t\t\t\t    data, data_length);\n\t\t\t\t\tiso9660->seenRockridge = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 'P':\n\t\t\t/*\n\t\t\t * PD extension is padding;\n\t\t\t * contents are always ignored.\n\t\t\t *\n\t\t\t * PL extension won't appear;\n\t\t\t * contents are always ignored.\n\t\t\t */\n\t\t\tif (p[1] == 'N') {\n\t\t\t\tif (version == 1 && data_length == 16) {\n\t\t\t\t\tfile->rdev = toi(data,4);\n\t\t\t\t\tfile->rdev <<= 32;\n\t\t\t\t\tfile->rdev |= toi(data + 8, 4);\n\t\t\t\t\tiso9660->seenRockridge = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if (p[1] == 'X') {\n\t\t\t\t/*\n\t\t\t\t * PX extension comprises:\n\t\t\t\t *   8 bytes for mode,\n\t\t\t\t *   8 bytes for nlinks,\n\t\t\t\t *   8 bytes for uid,\n\t\t\t\t *   8 bytes for gid,\n\t\t\t\t *   8 bytes for inode.\n\t\t\t\t */\n\t\t\t\tif (version == 1) {\n\t\t\t\t\tif (data_length >= 8)\n\t\t\t\t\t\tfile->mode\n\t\t\t\t\t\t    = toi(data, 4);\n\t\t\t\t\tif (data_length >= 16)\n\t\t\t\t\t\tfile->nlinks\n\t\t\t\t\t\t    = toi(data + 8, 4);\n\t\t\t\t\tif (data_length >= 24)\n\t\t\t\t\t\tfile->uid\n\t\t\t\t\t\t    = toi(data + 16, 4);\n\t\t\t\t\tif (data_length >= 32)\n\t\t\t\t\t\tfile->gid\n\t\t\t\t\t\t    = toi(data + 24, 4);\n\t\t\t\t\tif (data_length >= 40)\n\t\t\t\t\t\tfile->number\n\t\t\t\t\t\t    = toi(data + 32, 4);\n\t\t\t\t\tiso9660->seenRockridge = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 'R':\n\t\t\tif (p[1] == 'E' && version == 1) {\n\t\t\t\tfile->re = 1;\n\t\t\t\tiso9660->seenRockridge = 1;\n\t\t\t}\n\t\t\telse if (p[1] == 'R' && version == 1) {\n\t\t\t\t/*\n\t\t\t\t * RR extension comprises:\n\t\t\t\t *    one byte flag value\n\t\t\t\t * This extension is obsolete,\n\t\t\t\t * so contents are always ignored.\n\t\t\t\t */\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 'S':\n\t\t\tif (p[1] == 'L') {\n\t\t\t\tif (version == 1) {\n\t\t\t\t\tparse_rockridge_SL1(file,\n\t\t\t\t\t    data, data_length);\n\t\t\t\t\tiso9660->seenRockridge = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if (p[1] == 'T'\n\t\t\t    && data_length == 0 && version == 1) {\n\t\t\t\t/*\n\t\t\t\t * ST extension marks end of this\n\t\t\t\t * block of SUSP entries.\n\t\t\t\t *\n\t\t\t\t * It allows SUSP to coexist with\n\t\t\t\t * non-SUSP uses of the System\n\t\t\t\t * Use Area by placing non-SUSP data\n\t\t\t\t * after SUSP data.\n\t\t\t\t */\n\t\t\t\tiso9660->seenSUSP = 0;\n\t\t\t\tiso9660->seenRockridge = 0;\n\t\t\t\treturn (ARCHIVE_OK);\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 'T':\n\t\t\tif (p[1] == 'F') {\n\t\t\t\tif (version == 1) {\n\t\t\t\t\tparse_rockridge_TF1(file,\n\t\t\t\t\t    data, data_length);\n\t\t\t\t\tiso9660->seenRockridge = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 'Z':\n\t\t\tif (p[1] == 'F') {\n\t\t\t\tif (version == 1)\n\t\t\t\t\tparse_rockridge_ZF1(file,\n\t\t\t\t\t    data, data_length);\n\t\t\t}\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n \t\t}\n \n \t\tp += p[2];\n\t\tentry_seen = 1;\n\t}\n\n\tif (entry_seen)\n\t\treturn (ARCHIVE_OK);\n\telse {\n\t\tarchive_set_error(&a->archive, ARCHIVE_ERRNO_FILE_FORMAT,\n\t\t\t\t  \"Tried to parse Rockridge extensions, but none found\");\n\t\treturn (ARCHIVE_WARN);\n \t}\n }\n",
        "vul_function": "parse_rockridge(struct archive_read *a, struct file_info *file,\n     const unsigned char *p, const unsigned char *end)\n {\n \tstruct iso9660 *iso9660;\n \n \tiso9660 = (struct iso9660 *)(a->format->data);\n \n\twhile (p + 4 <= end  /* Enough space for another entry. */\n\t    && p[0] >= 'A' && p[0] <= 'Z' /* Sanity-check 1st char of name. */\n\t    && p[1] >= 'A' && p[1] <= 'Z' /* Sanity-check 2nd char of name. */\n\t    && p[2] >= 4 /* Sanity-check length. */\n\t    && p + p[2] <= end) { /* Sanity-check length. */\n\t\tconst unsigned char *data = p + 4;\n\t\tint data_length = p[2] - 4;\n\t\tint version = p[3];\n\n\t\tswitch(p[0]) {\n\t\tcase 'C':\n\t\t\tif (p[1] == 'E') {\n\t\t\t\tif (version == 1 && data_length == 24) {\n\t\t\t\t\t/*\n\t\t\t\t\t * CE extension comprises:\n\t\t\t\t\t *   8 byte sector containing extension\n\t\t\t\t\t *   8 byte offset w/in above sector\n\t\t\t\t\t *   8 byte length of continuation\n\t\t\t\t\t */\n\t\t\t\t\tint32_t location =\n\t\t\t\t\t    archive_le32dec(data);\n\t\t\t\t\tfile->ce_offset =\n\t\t\t\t\t    archive_le32dec(data+8);\n\t\t\t\t\tfile->ce_size =\n\t\t\t\t\t    archive_le32dec(data+16);\n\t\t\t\t\tif (register_CE(a, location, file)\n\t\t\t\t\t    != ARCHIVE_OK)\n\t\t\t\t\t\treturn (ARCHIVE_FATAL);\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if (p[1] == 'L') {\n\t\t\t\tif (version == 1 && data_length == 8) {\n\t\t\t\t\tfile->cl_offset = (uint64_t)\n\t\t\t\t\t    iso9660->logical_block_size *\n\t\t\t\t\t    (uint64_t)archive_le32dec(data);\n\t\t\t\t\tiso9660->seenRockridge = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 'N':\n\t\t\tif (p[1] == 'M') {\n\t\t\t\tif (version == 1) {\n\t\t\t\t\tparse_rockridge_NM1(file,\n\t\t\t\t\t    data, data_length);\n\t\t\t\t\tiso9660->seenRockridge = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 'P':\n\t\t\t/*\n\t\t\t * PD extension is padding;\n\t\t\t * contents are always ignored.\n\t\t\t *\n\t\t\t * PL extension won't appear;\n\t\t\t * contents are always ignored.\n\t\t\t */\n\t\t\tif (p[1] == 'N') {\n\t\t\t\tif (version == 1 && data_length == 16) {\n\t\t\t\t\tfile->rdev = toi(data,4);\n\t\t\t\t\tfile->rdev <<= 32;\n\t\t\t\t\tfile->rdev |= toi(data + 8, 4);\n\t\t\t\t\tiso9660->seenRockridge = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if (p[1] == 'X') {\n\t\t\t\t/*\n\t\t\t\t * PX extension comprises:\n\t\t\t\t *   8 bytes for mode,\n\t\t\t\t *   8 bytes for nlinks,\n\t\t\t\t *   8 bytes for uid,\n\t\t\t\t *   8 bytes for gid,\n\t\t\t\t *   8 bytes for inode.\n\t\t\t\t */\n\t\t\t\tif (version == 1) {\n\t\t\t\t\tif (data_length >= 8)\n\t\t\t\t\t\tfile->mode\n\t\t\t\t\t\t    = toi(data, 4);\n\t\t\t\t\tif (data_length >= 16)\n\t\t\t\t\t\tfile->nlinks\n\t\t\t\t\t\t    = toi(data + 8, 4);\n\t\t\t\t\tif (data_length >= 24)\n\t\t\t\t\t\tfile->uid\n\t\t\t\t\t\t    = toi(data + 16, 4);\n\t\t\t\t\tif (data_length >= 32)\n\t\t\t\t\t\tfile->gid\n\t\t\t\t\t\t    = toi(data + 24, 4);\n\t\t\t\t\tif (data_length >= 40)\n\t\t\t\t\t\tfile->number\n\t\t\t\t\t\t    = toi(data + 32, 4);\n\t\t\t\t\tiso9660->seenRockridge = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 'R':\n\t\t\tif (p[1] == 'E' && version == 1) {\n\t\t\t\tfile->re = 1;\n\t\t\t\tiso9660->seenRockridge = 1;\n\t\t\t}\n\t\t\telse if (p[1] == 'R' && version == 1) {\n\t\t\t\t/*\n\t\t\t\t * RR extension comprises:\n\t\t\t\t *    one byte flag value\n\t\t\t\t * This extension is obsolete,\n\t\t\t\t * so contents are always ignored.\n\t\t\t\t */\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 'S':\n\t\t\tif (p[1] == 'L') {\n\t\t\t\tif (version == 1) {\n\t\t\t\t\tparse_rockridge_SL1(file,\n\t\t\t\t\t    data, data_length);\n\t\t\t\t\tiso9660->seenRockridge = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if (p[1] == 'T'\n\t\t\t    && data_length == 0 && version == 1) {\n\t\t\t\t/*\n\t\t\t\t * ST extension marks end of this\n\t\t\t\t * block of SUSP entries.\n\t\t\t\t *\n\t\t\t\t * It allows SUSP to coexist with\n\t\t\t\t * non-SUSP uses of the System\n\t\t\t\t * Use Area by placing non-SUSP data\n\t\t\t\t * after SUSP data.\n\t\t\t\t */\n\t\t\t\tiso9660->seenSUSP = 0;\n\t\t\t\tiso9660->seenRockridge = 0;\n\t\t\t\treturn (ARCHIVE_OK);\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 'T':\n\t\t\tif (p[1] == 'F') {\n\t\t\t\tif (version == 1) {\n\t\t\t\t\tparse_rockridge_TF1(file,\n\t\t\t\t\t    data, data_length);\n\t\t\t\t\tiso9660->seenRockridge = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 'Z':\n\t\t\tif (p[1] == 'F') {\n\t\t\t\tif (version == 1)\n\t\t\t\t\tparse_rockridge_ZF1(file,\n\t\t\t\t\t    data, data_length);\n\t\t\t}\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n \t\t}\n \n \t\tp += p[2];\n \t}\n\treturn (ARCHIVE_OK);\n }\n",
        "llama3.1 Summary": null,
        "llama3.1 CWE": null,
        "llama3.1 CVE": null,
        "llama3.1 BERT Score": {
            "BERTScore Precision": "0.2856",
            "BERTScore Recall": "0.2113",
            "BERTScore F1": "0.2429"
        },
        "llama3.1 Cosine_Similarity": 0.0714372992515564,
        "Mistral Summary": null,
        "Mistral CWE": null,
        "Mistral CVE": null,
        "Mistral Cosine_Similarity": 0.0714372992515564,
        "Mistral BERT Score": {
            "BERTScore Precision": "0.2856",
            "BERTScore Recall": "0.2113",
            "BERTScore F1": "0.2429"
        },
        "Tokens Used": ""
    },
    {
        "codeLink": "https://github.com/ccxvii/mujs/commit/00d4606c3baf813b7b1c176823b2729bf51002a2",
        "CVE ID": "CVE-2019-11413",
        "CVE Details": "An issue was discovered in Artifex MuJS 1.0.5. It has unlimited recursion because the match function in regexp.c lacks a depth check.",
        "CWE ID": "CWE-400",
        "commit_message": "Bug 700937: Limit recursion in regexp matcher.\n\nAlso handle negative return code as an error in the JS bindings.",
        "fixed_function": "static void Sp_search(js_State *J)\n{\n\tjs_Regexp *re;\n\tconst char *text;\n\tResub m;\n\n\ttext = checkstring(J, 0);\n\n\tif (js_isregexp(J, 1))\n\t\tjs_copy(J, 1);\n\telse if (js_isundefined(J, 1))\n\t\tjs_newregexp(J, \"\", 0);\n\telse\n\t\tjs_newregexp(J, js_tostring(J, 1), 0);\n \n \tre = js_toregexp(J, -1);\n \n\tif (!js_doregexec(J, re->prog, text, &m, 0))\n \t\tjs_pushnumber(J, js_utfptrtoidx(text, m.sub[0].sp));\n \telse\n \t\tjs_pushnumber(J, -1);\n}\n",
        "vul_function": "static void Sp_search(js_State *J)\n{\n\tjs_Regexp *re;\n\tconst char *text;\n\tResub m;\n\n\ttext = checkstring(J, 0);\n\n\tif (js_isregexp(J, 1))\n\t\tjs_copy(J, 1);\n\telse if (js_isundefined(J, 1))\n\t\tjs_newregexp(J, \"\", 0);\n\telse\n\t\tjs_newregexp(J, js_tostring(J, 1), 0);\n \n \tre = js_toregexp(J, -1);\n \n\tif (!js_regexec(re->prog, text, &m, 0))\n \t\tjs_pushnumber(J, js_utfptrtoidx(text, m.sub[0].sp));\n \telse\n \t\tjs_pushnumber(J, -1);\n}\n",
        "llama3.1 Summary": "The patch changes the order of checking the regex execution result, ensuring that it correctly handles a negative return code as an error. This was applied to prevent potential crashes or unintended behavior when the regex matcher encounters an error condition. Fixed version of function: static void Sp_search(js_State *J)\n{\n\tjs_Regexp *re;\n\tconst char *text;\n\tResub m;\n\n\ttext = checkstring(J, 0);\n\n\tif (js_isregexp(J, 1))\n\t\tjs_copy(J, 1);\n\telse if (js_isundefined(J, 1))\n\t\tjs_newregexp(J, \"\", 0);\n\telse\n\t\tjs_newregexp(J, js_tostring(J, 1), 0);\n \n \tre = js_toregexp(J, -1);\n \n\tif (!js_doregexec(J, re->prog, text, &m, 0))\n \t\tjs_pushnumber(J, js_utfptrtoidx(text, m.sub[0].sp));\n \telse\n \t\tjs_pushnumber(J, -1);\n}",
        "llama3.1 CWE": "CWE-682",
        "llama3.1 CVE": "CVE-2022-4247",
        "llama3.1 BERT Score": {
            "BERTScore Precision": "0.3347",
            "BERTScore Recall": "0.5894",
            "BERTScore F1": "0.4269"
        },
        "llama3.1 Cosine_Similarity": 0.40124034881591797,
        "Mistral Summary": "The patch changes the regexec function to deregexec, which limits recursion in the regular expression matcher. This prevents a potential denial-of-service (DoS) attack due to infinite recursion in the vulnerable version of the code. Additionally, it handles negative return codes as errors in the JS bindings to prevent unexpected behavior.",
        "Mistral CWE": "CWE-416 (Insecure Regular Expression)",
        "Mistral CVE": "Unassigned as it is a local vulnerability and not publicly disclosed",
        "Mistral Cosine_Similarity": 0.35983848571777344,
        "Mistral BERT Score": {
            "BERTScore Precision": "0.6065",
            "BERTScore Recall": "0.6459",
            "BERTScore F1": "0.6256"
        },
        "Tokens Used": ""
    },
    {
        "codeLink": "https://github.com/ImageMagick/ImageMagick/commit/4ec444f4eab88cf4bec664fafcf9cab50bc5ff6a",
        "CVE ID": "CVE-2016-10058",
        "CVE Details": "Memory leak in the ReadPSDLayers function in coders/psd.c in ImageMagick before 6.9.6-3 allows remote attackers to cause a denial of service (memory consumption) via a crafted image file.",
        "CWE ID": "CWE-400",
        "commit_message": "Fixed memory leak.",
        "fixed_function": "ModuleExport MagickBooleanType ReadPSDLayers(Image *image,\n  const ImageInfo *image_info,const PSDInfo *psd_info,\n  const MagickBooleanType skip_layers,ExceptionInfo *exception)\n{\n  char\n    type[4];\n\n  LayerInfo\n    *layer_info;\n\n  MagickSizeType\n    size;\n\n  MagickBooleanType\n    status;\n\n  register ssize_t\n    i;\n\n  ssize_t\n    count,\n    j,\n    number_layers;\n\n  size=GetPSDSize(psd_info,image);\n  if (size == 0)\n    {\n      /*\n        Skip layers & masks.\n      */\n      (void) ReadBlobLong(image);\n      count=ReadBlob(image,4,(unsigned char *) type);\n      ReversePSDString(image,type,4);\n      status=MagickFalse;\n      if ((count == 0) || (LocaleNCompare(type,\"8BIM\",4) != 0))\n        return(MagickTrue);\n      else\n        {\n          count=ReadBlob(image,4,(unsigned char *) type);\n          ReversePSDString(image,type,4);\n          if ((count != 0) && (LocaleNCompare(type,\"Lr16\",4) == 0))\n            size=GetPSDSize(psd_info,image);\n          else\n            return(MagickTrue);\n        }\n    }\n  status=MagickTrue;\n  if (size != 0)\n    {\n      layer_info=(LayerInfo *) NULL;\n      number_layers=(short) ReadBlobShort(image);\n\n      if (number_layers < 0)\n        {\n          /*\n            The first alpha channel in the merged result contains the\n            transparency data for the merged result.\n          */\n          number_layers=MagickAbsoluteValue(number_layers);\n          if (image->debug != MagickFalse)\n            (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  negative layer count corrected for\");\n          image->matte=MagickTrue;\n        }\n\n      /*\n        We only need to know if the image has an alpha channel\n      */\n      if (skip_layers != MagickFalse)\n        return(MagickTrue);\n\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  image contains %.20g layers\",(double) number_layers);\n\n      if (number_layers == 0)\n        ThrowBinaryException(CorruptImageError,\"InvalidNumberOfLayers\",\n          image->filename);\n\n      layer_info=(LayerInfo *) AcquireQuantumMemory((size_t) number_layers,\n        sizeof(*layer_info));\n      if (layer_info == (LayerInfo *) NULL)\n        {\n          if (image->debug != MagickFalse)\n            (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  allocation of LayerInfo failed\");\n          ThrowBinaryException(ResourceLimitError,\"MemoryAllocationFailed\",\n            image->filename);\n        }\n      (void) ResetMagickMemory(layer_info,0,(size_t) number_layers*\n        sizeof(*layer_info));\n\n      for (i=0; i < number_layers; i++)\n      {\n        ssize_t\n          x,\n          y;\n\n        if (image->debug != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  reading layer #%.20g\",(double) i+1);\n        layer_info[i].page.y=ReadBlobSignedLong(image);\n        layer_info[i].page.x=ReadBlobSignedLong(image);\n        y=ReadBlobSignedLong(image);\n        x=ReadBlobSignedLong(image);\n        layer_info[i].page.width=(size_t) (x-layer_info[i].page.x);\n        layer_info[i].page.height=(size_t) (y-layer_info[i].page.y);\n        layer_info[i].channels=ReadBlobShort(image);\n        if (layer_info[i].channels > MaxPSDChannels)\n          {\n            layer_info=DestroyLayerInfo(layer_info,number_layers);\n            ThrowBinaryException(CorruptImageError,\"MaximumChannelsExceeded\",\n              image->filename);\n          }\n        if (image->debug != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"    offset(%.20g,%.20g), size(%.20g,%.20g), channels=%.20g\",\n            (double) layer_info[i].page.x,(double) layer_info[i].page.y,\n            (double) layer_info[i].page.height,(double)\n            layer_info[i].page.width,(double) layer_info[i].channels);\n        for (j=0; j < (ssize_t) layer_info[i].channels; j++)\n        {\n          layer_info[i].channel_info[j].type=(short) ReadBlobShort(image);\n          layer_info[i].channel_info[j].size=(size_t) GetPSDSize(psd_info,\n            image);\n          if (image->debug != MagickFalse)\n            (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"    channel[%.20g]: type=%.20g, size=%.20g\",(double) j,\n              (double) layer_info[i].channel_info[j].type,\n              (double) layer_info[i].channel_info[j].size);\n        }\n        count=ReadBlob(image,4,(unsigned char *) type);\n        ReversePSDString(image,type,4);\n        if ((count == 0) || (LocaleNCompare(type,\"8BIM\",4) != 0))\n          {\n            if (image->debug != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  layer type was %.4s instead of 8BIM\", type);\n            layer_info=DestroyLayerInfo(layer_info,number_layers);\n            ThrowBinaryException(CorruptImageError,\"ImproperImageHeader\",\n              image->filename);\n          }\n        (void) ReadBlob(image,4,(unsigned char *) layer_info[i].blendkey);\n        ReversePSDString(image,layer_info[i].blendkey,4);\n        layer_info[i].opacity=(Quantum) ScaleCharToQuantum((unsigned char)\n          ReadBlobByte(image));\n        layer_info[i].clipping=(unsigned char) ReadBlobByte(image);\n        layer_info[i].flags=(unsigned char) ReadBlobByte(image);\n        layer_info[i].visible=!(layer_info[i].flags & 0x02);\n        if (image->debug != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"   blend=%.4s, opacity=%.20g, clipping=%s, flags=%d, visible=%s\",\n            layer_info[i].blendkey,(double) layer_info[i].opacity,\n            layer_info[i].clipping ? \"true\" : \"false\",layer_info[i].flags,\n            layer_info[i].visible ? \"true\" : \"false\");\n        (void) ReadBlobByte(image);  /* filler */\n\n        size=ReadBlobLong(image);\n        if (size != 0)\n          {\n            MagickSizeType\n              combined_length,\n              length;\n\n            if (image->debug != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"    layer contains additional info\");\n            length=ReadBlobLong(image);\n            combined_length=length+4;\n            if (length != 0)\n              {\n                /*\n                  Layer mask info.\n                */\n                layer_info[i].mask.page.y=ReadBlobSignedLong(image);\n                layer_info[i].mask.page.x=ReadBlobSignedLong(image);\n                layer_info[i].mask.page.height=(size_t) (ReadBlobLong(image)-\n                  layer_info[i].mask.page.y);\n                layer_info[i].mask.page.width=(size_t) (ReadBlobLong(image)-\n                  layer_info[i].mask.page.x);\n                layer_info[i].mask.background=(unsigned char) ReadBlobByte(\n                  image);\n                layer_info[i].mask.flags=(unsigned char) ReadBlobByte(image);\n                if (!(layer_info[i].mask.flags & 0x01))\n                  {\n                    layer_info[i].mask.page.y=layer_info[i].mask.page.y-\n                      layer_info[i].page.y;\n                    layer_info[i].mask.page.x=layer_info[i].mask.page.x-\n                      layer_info[i].page.x;\n                  }\n                if (image->debug != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"      layer mask: offset(%.20g,%.20g), size(%.20g,%.20g), length=%.20g\",\n                    (double) layer_info[i].mask.page.x,(double)\n                    layer_info[i].mask.page.y,(double) layer_info[i].mask.page.width,\n                    (double) layer_info[i].mask.page.height,(double)\n                    ((MagickOffsetType) length)-18);\n                /*\n                  Skip over the rest of the layer mask information.\n                */\n                if (DiscardBlobBytes(image,(MagickSizeType) (length-18)) == MagickFalse)\n                  {\n                    layer_info=DestroyLayerInfo(layer_info,number_layers);\n                    ThrowBinaryException(CorruptImageError,\"UnexpectedEndOfFile\",\n                      image->filename);\n                  }\n              }\n            length=ReadBlobLong(image);\n            combined_length+=length+4;\n            if (length != 0)\n              {\n                /*\n                  Layer blending ranges info.\n                */\n                if (image->debug != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"      layer blending ranges: length=%.20g\",(double)\n                    ((MagickOffsetType) length));\n                /*\n                  We read it, but don't use it...\n                */\n                for (j=0; j < (ssize_t) length; j+=8)\n                {\n                  size_t blend_source=ReadBlobLong(image);\n                  size_t blend_dest=ReadBlobLong(image);\n                  if (image->debug != MagickFalse)\n                    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                      \"        source(%x), dest(%x)\",(unsigned int)\n                      blend_source,(unsigned int) blend_dest);\n                }\n              }\n            /*\n              Layer name.\n            */\n            length=(MagickSizeType) ReadBlobByte(image);\n            combined_length+=length+1;\n            if (length > 0)\n              (void) ReadBlob(image,(size_t) length++,layer_info[i].name);\n            layer_info[i].name[length]='\\0';\n            if (image->debug != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"      layer name: %s\",layer_info[i].name);\n            if ((length % 4) != 0)\n              {\n                length=4-(length % 4);\n                combined_length+=length;\n                /* Skip over the padding of the layer name */\n                if (DiscardBlobBytes(image,length) == MagickFalse)\n                  {\n                    layer_info=DestroyLayerInfo(layer_info,number_layers);\n                    ThrowBinaryException(CorruptImageError,\n                      \"UnexpectedEndOfFile\",image->filename);\n                  }\n              }\n            length=(MagickSizeType) size-combined_length;\n            if (length > 0)\n              {\n                unsigned char\n                  *info;\n\n                layer_info[i].info=AcquireStringInfo((const size_t) length);\n                info=GetStringInfoDatum(layer_info[i].info);\n                (void) ReadBlob(image,(const size_t) length,info);\n              }\n          }\n      }\n\n      for (i=0; i < number_layers; i++)\n      {\n        if ((layer_info[i].page.width == 0) ||\n              (layer_info[i].page.height == 0))\n          {\n             if (image->debug != MagickFalse)\n               (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                 \"      layer data is empty\");\n            if (layer_info[i].info != (StringInfo *) NULL)\n              layer_info[i].info=DestroyStringInfo(layer_info[i].info);\n             continue;\n           }\n \n        /*\n          Allocate layered image.\n        */\n        layer_info[i].image=CloneImage(image,layer_info[i].page.width,\n          layer_info[i].page.height,MagickFalse,exception);\n        if (layer_info[i].image == (Image *) NULL)\n          {\n            layer_info=DestroyLayerInfo(layer_info,number_layers);\n            if (image->debug != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  allocation of image for layer %.20g failed\",(double) i);\n            ThrowBinaryException(ResourceLimitError,\"MemoryAllocationFailed\",\n              image->filename);\n          }\n\n        if (layer_info[i].info != (StringInfo *) NULL)\n          {\n            (void) SetImageProfile(layer_info[i].image,\"psd:additional-info\",\n              layer_info[i].info);\n            layer_info[i].info=DestroyStringInfo(layer_info[i].info);\n          }\n      }\n\n      if (image_info->ping == MagickFalse)\n        {\n          for (i=0; i < number_layers; i++)\n          {\n            if (layer_info[i].image == (Image *) NULL)\n              {\n                for (j=0; j < layer_info[i].channels; j++)\n                {\n                  if (DiscardBlobBytes(image,(MagickSizeType)\n                      layer_info[i].channel_info[j].size) == MagickFalse)\n                    {\n                      layer_info=DestroyLayerInfo(layer_info,number_layers);\n                      ThrowBinaryException(CorruptImageError,\n                        \"UnexpectedEndOfFile\",image->filename);\n                    }\n                }\n                continue;\n              }\n\n            if (image->debug != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  reading data for layer %.20g\",(double) i);\n            status=ReadPSDLayer(image,image_info,psd_info,&layer_info[i],\n              exception);\n            if (status == MagickFalse)\n              break;\n\n            status=SetImageProgress(image,LoadImagesTag,i,(MagickSizeType)\n              number_layers);\n            if (status == MagickFalse)\n              break;\n          }\n        }\n\n      if (status != MagickFalse)\n        {\n          for (i=0; i < number_layers; i++)\n          {\n            if (layer_info[i].image == (Image *) NULL)\n              {\n                for (j=i; j < number_layers - 1; j++)\n                  layer_info[j] = layer_info[j+1];\n                number_layers--;\n                i--;\n              }\n          }\n\n          if (number_layers > 0)\n            {\n              for (i=0; i < number_layers; i++)\n              {\n                if (i > 0)\n                  layer_info[i].image->previous=layer_info[i-1].image;\n                if (i < (number_layers-1))\n                  layer_info[i].image->next=layer_info[i+1].image;\n                layer_info[i].image->page=layer_info[i].page;\n              }\n              image->next=layer_info[0].image;\n              layer_info[0].image->previous=image;\n            }\n          layer_info=(LayerInfo *) RelinquishMagickMemory(layer_info);\n        }\n      else\n        layer_info=DestroyLayerInfo(layer_info,number_layers);\n    }\n\n  return(status);\n}\n",
        "vul_function": "ModuleExport MagickBooleanType ReadPSDLayers(Image *image,\n  const ImageInfo *image_info,const PSDInfo *psd_info,\n  const MagickBooleanType skip_layers,ExceptionInfo *exception)\n{\n  char\n    type[4];\n\n  LayerInfo\n    *layer_info;\n\n  MagickSizeType\n    size;\n\n  MagickBooleanType\n    status;\n\n  register ssize_t\n    i;\n\n  ssize_t\n    count,\n    j,\n    number_layers;\n\n  size=GetPSDSize(psd_info,image);\n  if (size == 0)\n    {\n      /*\n        Skip layers & masks.\n      */\n      (void) ReadBlobLong(image);\n      count=ReadBlob(image,4,(unsigned char *) type);\n      ReversePSDString(image,type,4);\n      status=MagickFalse;\n      if ((count == 0) || (LocaleNCompare(type,\"8BIM\",4) != 0))\n        return(MagickTrue);\n      else\n        {\n          count=ReadBlob(image,4,(unsigned char *) type);\n          ReversePSDString(image,type,4);\n          if ((count != 0) && (LocaleNCompare(type,\"Lr16\",4) == 0))\n            size=GetPSDSize(psd_info,image);\n          else\n            return(MagickTrue);\n        }\n    }\n  status=MagickTrue;\n  if (size != 0)\n    {\n      layer_info=(LayerInfo *) NULL;\n      number_layers=(short) ReadBlobShort(image);\n\n      if (number_layers < 0)\n        {\n          /*\n            The first alpha channel in the merged result contains the\n            transparency data for the merged result.\n          */\n          number_layers=MagickAbsoluteValue(number_layers);\n          if (image->debug != MagickFalse)\n            (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  negative layer count corrected for\");\n          image->matte=MagickTrue;\n        }\n\n      /*\n        We only need to know if the image has an alpha channel\n      */\n      if (skip_layers != MagickFalse)\n        return(MagickTrue);\n\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  image contains %.20g layers\",(double) number_layers);\n\n      if (number_layers == 0)\n        ThrowBinaryException(CorruptImageError,\"InvalidNumberOfLayers\",\n          image->filename);\n\n      layer_info=(LayerInfo *) AcquireQuantumMemory((size_t) number_layers,\n        sizeof(*layer_info));\n      if (layer_info == (LayerInfo *) NULL)\n        {\n          if (image->debug != MagickFalse)\n            (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  allocation of LayerInfo failed\");\n          ThrowBinaryException(ResourceLimitError,\"MemoryAllocationFailed\",\n            image->filename);\n        }\n      (void) ResetMagickMemory(layer_info,0,(size_t) number_layers*\n        sizeof(*layer_info));\n\n      for (i=0; i < number_layers; i++)\n      {\n        ssize_t\n          x,\n          y;\n\n        if (image->debug != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  reading layer #%.20g\",(double) i+1);\n        layer_info[i].page.y=ReadBlobSignedLong(image);\n        layer_info[i].page.x=ReadBlobSignedLong(image);\n        y=ReadBlobSignedLong(image);\n        x=ReadBlobSignedLong(image);\n        layer_info[i].page.width=(size_t) (x-layer_info[i].page.x);\n        layer_info[i].page.height=(size_t) (y-layer_info[i].page.y);\n        layer_info[i].channels=ReadBlobShort(image);\n        if (layer_info[i].channels > MaxPSDChannels)\n          {\n            layer_info=DestroyLayerInfo(layer_info,number_layers);\n            ThrowBinaryException(CorruptImageError,\"MaximumChannelsExceeded\",\n              image->filename);\n          }\n        if (image->debug != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"    offset(%.20g,%.20g), size(%.20g,%.20g), channels=%.20g\",\n            (double) layer_info[i].page.x,(double) layer_info[i].page.y,\n            (double) layer_info[i].page.height,(double)\n            layer_info[i].page.width,(double) layer_info[i].channels);\n        for (j=0; j < (ssize_t) layer_info[i].channels; j++)\n        {\n          layer_info[i].channel_info[j].type=(short) ReadBlobShort(image);\n          layer_info[i].channel_info[j].size=(size_t) GetPSDSize(psd_info,\n            image);\n          if (image->debug != MagickFalse)\n            (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"    channel[%.20g]: type=%.20g, size=%.20g\",(double) j,\n              (double) layer_info[i].channel_info[j].type,\n              (double) layer_info[i].channel_info[j].size);\n        }\n        count=ReadBlob(image,4,(unsigned char *) type);\n        ReversePSDString(image,type,4);\n        if ((count == 0) || (LocaleNCompare(type,\"8BIM\",4) != 0))\n          {\n            if (image->debug != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  layer type was %.4s instead of 8BIM\", type);\n            layer_info=DestroyLayerInfo(layer_info,number_layers);\n            ThrowBinaryException(CorruptImageError,\"ImproperImageHeader\",\n              image->filename);\n          }\n        (void) ReadBlob(image,4,(unsigned char *) layer_info[i].blendkey);\n        ReversePSDString(image,layer_info[i].blendkey,4);\n        layer_info[i].opacity=(Quantum) ScaleCharToQuantum((unsigned char)\n          ReadBlobByte(image));\n        layer_info[i].clipping=(unsigned char) ReadBlobByte(image);\n        layer_info[i].flags=(unsigned char) ReadBlobByte(image);\n        layer_info[i].visible=!(layer_info[i].flags & 0x02);\n        if (image->debug != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"   blend=%.4s, opacity=%.20g, clipping=%s, flags=%d, visible=%s\",\n            layer_info[i].blendkey,(double) layer_info[i].opacity,\n            layer_info[i].clipping ? \"true\" : \"false\",layer_info[i].flags,\n            layer_info[i].visible ? \"true\" : \"false\");\n        (void) ReadBlobByte(image);  /* filler */\n\n        size=ReadBlobLong(image);\n        if (size != 0)\n          {\n            MagickSizeType\n              combined_length,\n              length;\n\n            if (image->debug != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"    layer contains additional info\");\n            length=ReadBlobLong(image);\n            combined_length=length+4;\n            if (length != 0)\n              {\n                /*\n                  Layer mask info.\n                */\n                layer_info[i].mask.page.y=ReadBlobSignedLong(image);\n                layer_info[i].mask.page.x=ReadBlobSignedLong(image);\n                layer_info[i].mask.page.height=(size_t) (ReadBlobLong(image)-\n                  layer_info[i].mask.page.y);\n                layer_info[i].mask.page.width=(size_t) (ReadBlobLong(image)-\n                  layer_info[i].mask.page.x);\n                layer_info[i].mask.background=(unsigned char) ReadBlobByte(\n                  image);\n                layer_info[i].mask.flags=(unsigned char) ReadBlobByte(image);\n                if (!(layer_info[i].mask.flags & 0x01))\n                  {\n                    layer_info[i].mask.page.y=layer_info[i].mask.page.y-\n                      layer_info[i].page.y;\n                    layer_info[i].mask.page.x=layer_info[i].mask.page.x-\n                      layer_info[i].page.x;\n                  }\n                if (image->debug != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"      layer mask: offset(%.20g,%.20g), size(%.20g,%.20g), length=%.20g\",\n                    (double) layer_info[i].mask.page.x,(double)\n                    layer_info[i].mask.page.y,(double) layer_info[i].mask.page.width,\n                    (double) layer_info[i].mask.page.height,(double)\n                    ((MagickOffsetType) length)-18);\n                /*\n                  Skip over the rest of the layer mask information.\n                */\n                if (DiscardBlobBytes(image,(MagickSizeType) (length-18)) == MagickFalse)\n                  {\n                    layer_info=DestroyLayerInfo(layer_info,number_layers);\n                    ThrowBinaryException(CorruptImageError,\"UnexpectedEndOfFile\",\n                      image->filename);\n                  }\n              }\n            length=ReadBlobLong(image);\n            combined_length+=length+4;\n            if (length != 0)\n              {\n                /*\n                  Layer blending ranges info.\n                */\n                if (image->debug != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"      layer blending ranges: length=%.20g\",(double)\n                    ((MagickOffsetType) length));\n                /*\n                  We read it, but don't use it...\n                */\n                for (j=0; j < (ssize_t) length; j+=8)\n                {\n                  size_t blend_source=ReadBlobLong(image);\n                  size_t blend_dest=ReadBlobLong(image);\n                  if (image->debug != MagickFalse)\n                    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                      \"        source(%x), dest(%x)\",(unsigned int)\n                      blend_source,(unsigned int) blend_dest);\n                }\n              }\n            /*\n              Layer name.\n            */\n            length=(MagickSizeType) ReadBlobByte(image);\n            combined_length+=length+1;\n            if (length > 0)\n              (void) ReadBlob(image,(size_t) length++,layer_info[i].name);\n            layer_info[i].name[length]='\\0';\n            if (image->debug != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"      layer name: %s\",layer_info[i].name);\n            if ((length % 4) != 0)\n              {\n                length=4-(length % 4);\n                combined_length+=length;\n                /* Skip over the padding of the layer name */\n                if (DiscardBlobBytes(image,length) == MagickFalse)\n                  {\n                    layer_info=DestroyLayerInfo(layer_info,number_layers);\n                    ThrowBinaryException(CorruptImageError,\n                      \"UnexpectedEndOfFile\",image->filename);\n                  }\n              }\n            length=(MagickSizeType) size-combined_length;\n            if (length > 0)\n              {\n                unsigned char\n                  *info;\n\n                layer_info[i].info=AcquireStringInfo((const size_t) length);\n                info=GetStringInfoDatum(layer_info[i].info);\n                (void) ReadBlob(image,(const size_t) length,info);\n              }\n          }\n      }\n\n      for (i=0; i < number_layers; i++)\n      {\n        if ((layer_info[i].page.width == 0) ||\n              (layer_info[i].page.height == 0))\n          {\n             if (image->debug != MagickFalse)\n               (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                 \"      layer data is empty\");\n             continue;\n           }\n \n        /*\n          Allocate layered image.\n        */\n        layer_info[i].image=CloneImage(image,layer_info[i].page.width,\n          layer_info[i].page.height,MagickFalse,exception);\n        if (layer_info[i].image == (Image *) NULL)\n          {\n            layer_info=DestroyLayerInfo(layer_info,number_layers);\n            if (image->debug != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  allocation of image for layer %.20g failed\",(double) i);\n            ThrowBinaryException(ResourceLimitError,\"MemoryAllocationFailed\",\n              image->filename);\n          }\n\n        if (layer_info[i].info != (StringInfo *) NULL)\n          {\n            (void) SetImageProfile(layer_info[i].image,\"psd:additional-info\",\n              layer_info[i].info);\n            layer_info[i].info=DestroyStringInfo(layer_info[i].info);\n          }\n      }\n\n      if (image_info->ping == MagickFalse)\n        {\n          for (i=0; i < number_layers; i++)\n          {\n            if (layer_info[i].image == (Image *) NULL)\n              {\n                for (j=0; j < layer_info[i].channels; j++)\n                {\n                  if (DiscardBlobBytes(image,(MagickSizeType)\n                      layer_info[i].channel_info[j].size) == MagickFalse)\n                    {\n                      layer_info=DestroyLayerInfo(layer_info,number_layers);\n                      ThrowBinaryException(CorruptImageError,\n                        \"UnexpectedEndOfFile\",image->filename);\n                    }\n                }\n                continue;\n              }\n\n            if (image->debug != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"  reading data for layer %.20g\",(double) i);\n            status=ReadPSDLayer(image,image_info,psd_info,&layer_info[i],\n              exception);\n            if (status == MagickFalse)\n              break;\n\n            status=SetImageProgress(image,LoadImagesTag,i,(MagickSizeType)\n              number_layers);\n            if (status == MagickFalse)\n              break;\n          }\n        }\n\n      if (status != MagickFalse)\n        {\n          for (i=0; i < number_layers; i++)\n          {\n            if (layer_info[i].image == (Image *) NULL)\n              {\n                for (j=i; j < number_layers - 1; j++)\n                  layer_info[j] = layer_info[j+1];\n                number_layers--;\n                i--;\n              }\n          }\n\n          if (number_layers > 0)\n            {\n              for (i=0; i < number_layers; i++)\n              {\n                if (i > 0)\n                  layer_info[i].image->previous=layer_info[i-1].image;\n                if (i < (number_layers-1))\n                  layer_info[i].image->next=layer_info[i+1].image;\n                layer_info[i].image->page=layer_info[i].page;\n              }\n              image->next=layer_info[0].image;\n              layer_info[0].image->previous=image;\n            }\n          layer_info=(LayerInfo *) RelinquishMagickMemory(layer_info);\n        }\n      else\n        layer_info=DestroyLayerInfo(layer_info,number_layers);\n    }\n\n  return(status);\n}\n",
        "llama3.1 Summary": null,
        "llama3.1 CWE": null,
        "llama3.1 CVE": null,
        "llama3.1 BERT Score": {
            "BERTScore Precision": "0.3186",
            "BERTScore Recall": "0.2590",
            "BERTScore F1": "0.2857"
        },
        "llama3.1 Cosine_Similarity": 0.03397679328918457,
        "Mistral Summary": null,
        "Mistral CWE": null,
        "Mistral CVE": null,
        "Mistral Cosine_Similarity": 0.03397679328918457,
        "Mistral BERT Score": {
            "BERTScore Precision": "0.3186",
            "BERTScore Recall": "0.2590",
            "BERTScore F1": "0.2857"
        },
        "Tokens Used": ""
    },
    {
        "codeLink": "https://github.com/torvalds/linux/commit/6ef36ab967c71690ebe7e5ef997a8be4da3bc844",
        "CVE ID": "CVE-2019-17351",
        "CVE Details": "An issue was discovered in drivers/xen/balloon.c in the Linux kernel before 5.2.3, as used in Xen through 4.12.x, allowing guest OS users to cause a denial of service because of unrestricted resource consumption during the mapping of guest memory, aka CID-6ef36ab967c7.",
        "CWE ID": "CWE-400",
        "commit_message": "xen: let alloc_xenballooned_pages() fail if not enough memory free\n\ncommit a1078e821b605813b63bf6bca414a85f804d5c66 upstream.\n\nInstead of trying to allocate pages with GFP_USER in\nadd_ballooned_pages() check the available free memory via\nsi_mem_available(). GFP_USER is far less limiting memory exhaustion\nthan the test via si_mem_available().\n\nThis will avoid dom0 running out of memory due to excessive foreign\npage mappings especially on ARM and on x86 in PVH mode, as those don't\nhave a pre-ballooned area which can be used for foreign mappings.\n\nAs the normal ballooning suffers from the same problem don't balloon\ndown more than si_mem_available() pages in one iteration. At the same\ntime limit the default maximum number of retries.\n\nThis is part of XSA-300.\n\nSigned-off-by: Juergen Gross <jgross@suse.com>\nSigned-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>",
        "fixed_function": "static int add_ballooned_pages(int nr_pages)\n{\n\tenum bp_state st;\n\n\tif (xen_hotplug_unpopulated) {\n\t\tst = reserve_additional_memory();\n\t\tif (st != BP_ECANCELED) {\n\t\t\tmutex_unlock(&balloon_mutex);\n\t\t\twait_event(balloon_wq,\n\t\t\t\t   !list_empty(&ballooned_pages));\n\t\t\tmutex_lock(&balloon_mutex);\n\t\t\treturn 0;\n \t\t}\n \t}\n \n\tif (si_mem_available() < nr_pages)\n\t\treturn -ENOMEM;\n\n \tst = decrease_reservation(nr_pages, GFP_USER);\n \tif (st != BP_DONE)\n \t\treturn -ENOMEM;\n\n\treturn 0;\n}\n",
        "vul_function": "static int add_ballooned_pages(int nr_pages)\n{\n\tenum bp_state st;\n\n\tif (xen_hotplug_unpopulated) {\n\t\tst = reserve_additional_memory();\n\t\tif (st != BP_ECANCELED) {\n\t\t\tmutex_unlock(&balloon_mutex);\n\t\t\twait_event(balloon_wq,\n\t\t\t\t   !list_empty(&ballooned_pages));\n\t\t\tmutex_lock(&balloon_mutex);\n\t\t\treturn 0;\n \t\t}\n \t}\n \n \tst = decrease_reservation(nr_pages, GFP_USER);\n \tif (st != BP_DONE)\n \t\treturn -ENOMEM;\n\n\treturn 0;\n}\n",
        "llama3.1 Summary": "The patch changes the function add_ballooned_pages to check available free memory before attempting to allocate pages, preventing potential out-of-memory errors. This change was applied to prevent dom0 from running out of memory due to excessive foreign page mappings, particularly on ARM and x86 in PVH mode.",
        "llama3.1 CWE": "CWE-770",
        "llama3.1 CVE": "CVE-2019-14821",
        "llama3.1 BERT Score": {
            "BERTScore Precision": "0.6097",
            "BERTScore Recall": "0.5573",
            "BERTScore F1": "0.5824"
        },
        "llama3.1 Cosine_Similarity": 0.494449257850647,
        "Mistral Summary": "The patch changes the method for checking available memory before attempting to allocate pages in `add_ballooned_pages()`. Instead of using GFP_USER, it now uses `si_mem_available()`, which is less restrictive. This prevents excessive foreign page mappings and memory exhaustion on ARM and x86 in PVH mode, improving system stability. The limitation ensures that the normal ballooning does not suffer from the same problem, and reduces the number of retries to avoid potential infinite loops or excessive resource usage.",
        "Mistral CWE": "CWE-120 (Resource Exhaustion)",
        "Mistral CVE": "CVE-XXXX-XXXX (The specific CVE ID should be assigned by a recognized authority, such as MITRE)",
        "Mistral Cosine_Similarity": 0.45674824714660645,
        "Mistral BERT Score": {
            "BERTScore Precision": "0.5464",
            "BERTScore Recall": "0.5529",
            "BERTScore F1": "0.5496"
        },
        "Tokens Used": ""
    },
    {
        "codeLink": "https://git.qemu.org/?p=qemu.git;a=commit;h=4774718e5c194026ba5ee7a28d9be49be3080e42",
        "CVE ID": "CVE-2016-9913",
        "CVE Details": "Memory leak in the v9fs_device_unrealize_common function in hw/9pfs/9p.c in QEMU (aka Quick Emulator) allows local privileged guest OS users to cause a denial of service (host memory consumption and possibly QEMU process crash) via vectors involving the order of resource cleanup.",
        "CWE ID": "CWE-400",
        "commit_message": "None",
        "fixed_function": " void v9fs_device_unrealize_common(V9fsState *s, Error **errp)\n {\n     g_free(s->tag);\n    g_free(s->ctx.fs_root);\n }\n",
        "vul_function": " void v9fs_device_unrealize_common(V9fsState *s, Error **errp)\n {\n    g_free(s->ctx.fs_root);\n     g_free(s->tag);\n }\n",
        "llama3.1 Summary": "The patch changes the order of freeing memory for `s->ctx.fs_root` and `s->tag` to prevent a potential use-after-free vulnerability. This was applied because releasing `s->tag` before `s->ctx.fs_root` could result in attempting to access freed memory. Fixed version of function:  void v9fs_device_unrealize_common(V9fsState *s, Error **errp)\n {\n     g_free(s->tag);\n    g_free(s->ctx.fs_root);\n }",
        "llama3.1 CWE": "CWE-772",
        "llama3.1 CVE": "CVE-2023-1234",
        "llama3.1 BERT Score": {
            "BERTScore Precision": "0.4734",
            "BERTScore Recall": "0.5921",
            "BERTScore F1": "0.5262"
        },
        "llama3.1 Cosine_Similarity": 0.6010309457778931,
        "Mistral Summary": "The patch changes the order of g_free() calls in the function, ensuring that 's->tag' is freed before 's->ctx.fs_root'. This was applied to prevent use-after-free vulnerability where 's->tag' could be used after it has been freed.",
        "Mistral CWE": "CWE-416 (Use after free)",
        "Mistral CVE": "Not available (Commit message does not provide enough information to assign a specific CVE ID)",
        "Mistral Cosine_Similarity": 0.32162153720855713,
        "Mistral BERT Score": {
            "BERTScore Precision": "0.5501",
            "BERTScore Recall": "0.5427",
            "BERTScore F1": "0.5464"
        },
        "Tokens Used": ""
    },
    {
        "codeLink": "https://git.qemu.org/?p=qemu.git;a=commit;h=4774718e5c194026ba5ee7a28d9be49be3080e42",
        "CVE ID": "CVE-2016-9913",
        "CVE Details": "Memory leak in the v9fs_device_unrealize_common function in hw/9pfs/9p.c in QEMU (aka Quick Emulator) allows local privileged guest OS users to cause a denial of service (host memory consumption and possibly QEMU process crash) via vectors involving the order of resource cleanup.",
        "CWE ID": "CWE-400",
        "commit_message": "None",
        "fixed_function": "int v9fs_device_realize_common(V9fsState *s, Error **errp)\n{\n    V9fsVirtioState *v = container_of(s, V9fsVirtioState, state);\n    int i, len;\n    struct stat stat;\n    FsDriverEntry *fse;\n    V9fsPath path;\n    int rc = 1;\n\n    /* initialize pdu allocator */\n    QLIST_INIT(&s->free_list);\n    QLIST_INIT(&s->active_list);\n    for (i = 0; i < (MAX_REQ - 1); i++) {\n        QLIST_INSERT_HEAD(&s->free_list, &v->pdus[i], next);\n        v->pdus[i].s = s;\n        v->pdus[i].idx = i;\n    }\n\n    v9fs_path_init(&path);\n\n    fse = get_fsdev_fsentry(s->fsconf.fsdev_id);\n\n    if (!fse) {\n        /* We don't have a fsdev identified by fsdev_id */\n        error_setg(errp, \"9pfs device couldn't find fsdev with the \"\n                   \"id = %s\",\n                   s->fsconf.fsdev_id ? s->fsconf.fsdev_id : \"NULL\");\n        goto out;\n    }\n\n    if (!s->fsconf.tag) {\n        /* we haven't specified a mount_tag */\n        error_setg(errp, \"fsdev with id %s needs mount_tag arguments\",\n                   s->fsconf.fsdev_id);\n        goto out;\n    }\n\n    s->ctx.export_flags = fse->export_flags;\n    s->ctx.fs_root = g_strdup(fse->path);\n    s->ctx.exops.get_st_gen = NULL;\n    len = strlen(s->fsconf.tag);\n    if (len > MAX_TAG_LEN - 1) {\n        error_setg(errp, \"mount tag '%s' (%d bytes) is longer than \"\n                   \"maximum (%d bytes)\", s->fsconf.tag, len, MAX_TAG_LEN - 1);\n        goto out;\n    }\n\n    s->tag = g_strdup(s->fsconf.tag);\n    s->ctx.uid = -1;\n\n    s->ops = fse->ops;\n\n    s->fid_list = NULL;\n    qemu_co_rwlock_init(&s->rename_lock);\n\n    if (s->ops->init(&s->ctx) < 0) {\n        error_setg(errp, \"9pfs Failed to initialize fs-driver with id:%s\"\n                   \" and export path:%s\", s->fsconf.fsdev_id, s->ctx.fs_root);\n        goto out;\n    }\n\n    /*\n     * Check details of export path, We need to use fs driver\n     * call back to do that. Since we are in the init path, we don't\n     * use co-routines here.\n     */\n    if (s->ops->name_to_path(&s->ctx, NULL, \"/\", &path) < 0) {\n        error_setg(errp,\n                   \"error in converting name to path %s\", strerror(errno));\n        goto out;\n    }\n    if (s->ops->lstat(&s->ctx, &path, &stat)) {\n        error_setg(errp, \"share path %s does not exist\", fse->path);\n        goto out;\n    } else if (!S_ISDIR(stat.st_mode)) {\n        error_setg(errp, \"share path %s is not a directory\", fse->path);\n        goto out;\n    }\n    v9fs_path_free(&path);\n\n     rc = 0;\n out:\n     if (rc) {\n         g_free(s->tag);\n        g_free(s->ctx.fs_root);\n         v9fs_path_free(&path);\n     }\n     return rc;\n}\n",
        "vul_function": "int v9fs_device_realize_common(V9fsState *s, Error **errp)\n{\n    V9fsVirtioState *v = container_of(s, V9fsVirtioState, state);\n    int i, len;\n    struct stat stat;\n    FsDriverEntry *fse;\n    V9fsPath path;\n    int rc = 1;\n\n    /* initialize pdu allocator */\n    QLIST_INIT(&s->free_list);\n    QLIST_INIT(&s->active_list);\n    for (i = 0; i < (MAX_REQ - 1); i++) {\n        QLIST_INSERT_HEAD(&s->free_list, &v->pdus[i], next);\n        v->pdus[i].s = s;\n        v->pdus[i].idx = i;\n    }\n\n    v9fs_path_init(&path);\n\n    fse = get_fsdev_fsentry(s->fsconf.fsdev_id);\n\n    if (!fse) {\n        /* We don't have a fsdev identified by fsdev_id */\n        error_setg(errp, \"9pfs device couldn't find fsdev with the \"\n                   \"id = %s\",\n                   s->fsconf.fsdev_id ? s->fsconf.fsdev_id : \"NULL\");\n        goto out;\n    }\n\n    if (!s->fsconf.tag) {\n        /* we haven't specified a mount_tag */\n        error_setg(errp, \"fsdev with id %s needs mount_tag arguments\",\n                   s->fsconf.fsdev_id);\n        goto out;\n    }\n\n    s->ctx.export_flags = fse->export_flags;\n    s->ctx.fs_root = g_strdup(fse->path);\n    s->ctx.exops.get_st_gen = NULL;\n    len = strlen(s->fsconf.tag);\n    if (len > MAX_TAG_LEN - 1) {\n        error_setg(errp, \"mount tag '%s' (%d bytes) is longer than \"\n                   \"maximum (%d bytes)\", s->fsconf.tag, len, MAX_TAG_LEN - 1);\n        goto out;\n    }\n\n    s->tag = g_strdup(s->fsconf.tag);\n    s->ctx.uid = -1;\n\n    s->ops = fse->ops;\n\n    s->fid_list = NULL;\n    qemu_co_rwlock_init(&s->rename_lock);\n\n    if (s->ops->init(&s->ctx) < 0) {\n        error_setg(errp, \"9pfs Failed to initialize fs-driver with id:%s\"\n                   \" and export path:%s\", s->fsconf.fsdev_id, s->ctx.fs_root);\n        goto out;\n    }\n\n    /*\n     * Check details of export path, We need to use fs driver\n     * call back to do that. Since we are in the init path, we don't\n     * use co-routines here.\n     */\n    if (s->ops->name_to_path(&s->ctx, NULL, \"/\", &path) < 0) {\n        error_setg(errp,\n                   \"error in converting name to path %s\", strerror(errno));\n        goto out;\n    }\n    if (s->ops->lstat(&s->ctx, &path, &stat)) {\n        error_setg(errp, \"share path %s does not exist\", fse->path);\n        goto out;\n    } else if (!S_ISDIR(stat.st_mode)) {\n        error_setg(errp, \"share path %s is not a directory\", fse->path);\n        goto out;\n    }\n    v9fs_path_free(&path);\n\n     rc = 0;\n out:\n     if (rc) {\n        g_free(s->ctx.fs_root);\n         g_free(s->tag);\n         v9fs_path_free(&path);\n     }\n     return rc;\n}\n",
        "llama3.1 Summary": "The patch changes the order of memory deallocation, ensuring that memory is freed in the correct order to prevent a use-after-free vulnerability. This change prevents potential crashes and data corruption issues caused by incorrect handling of memory allocation and deallocation.",
        "llama3.1 CWE": "CWE-116",
        "llama3.1 CVE": "CVE-2023-1234",
        "llama3.1 BERT Score": {
            "BERTScore Precision": "0.5877",
            "BERTScore Recall": "0.5165",
            "BERTScore F1": "0.5498"
        },
        "llama3.1 Cosine_Similarity": 0.3988761901855469,
        "Mistral Summary": null,
        "Mistral CWE": null,
        "Mistral CVE": null,
        "Mistral Cosine_Similarity": 0.010018229484558105,
        "Mistral BERT Score": {
            "BERTScore Precision": "0.3123",
            "BERTScore Recall": "0.2230",
            "BERTScore F1": "0.2602"
        },
        "Tokens Used": ""
    }
]